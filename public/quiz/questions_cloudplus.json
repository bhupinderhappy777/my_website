{
  "1. Cloud Architecture": [
    {
      "q": "A retail company wants to run custom machine learning models on GPU-enabled servers in the cloud while maintaining full control over the OS and installed libraries. Which service model is most appropriate?",
      "options": [
        "SaaS",
        "PaaS",
        "IaaS",
        "FaaS"
      ],
      "answer": 2,
      "explanation": "IaaS gives full control over VMs including OS, GPU drivers, and installed libraries, which is required for custom ML workloads. Objective 1.1"
    },
    {
      "q": "A school district wants to provide email and document collaboration to 5,000 teachers without hiring IT staff to manage servers. Which cloud service model fits best?",
      "options": [
        "IaaS",
        "PaaS",
        "SaaS",
        "XaaS"
      ],
      "answer": 2,
      "explanation": "SaaS delivers fully managed applications like email and collaboration tools with no server management needed. Objective 1.1"
    },
    {
      "q": "A developer needs to deploy a Node.js API and wants automatic scaling and managed database connections without configuring virtual machines. Which model should they choose?",
      "options": [
        "IaaS",
        "PaaS",
        "SaaS",
        "Bare metal"
      ],
      "answer": 1,
      "explanation": "PaaS provides managed runtime environments with auto-scaling and managed services, letting developers focus on code. Objective 1.1"
    },
    {
      "q": "An image processing application needs to run a function only when a new file is uploaded to cloud storage, with billing based on execution time. Which model is best?",
      "options": [
        "IaaS",
        "PaaS",
        "SaaS",
        "FaaS"
      ],
      "answer": 3,
      "explanation": "FaaS (Function as a Service) runs code in response to events like file uploads and charges only for execution time. Objective 1.1"
    },
    {
      "q": "A company uses a CRM application, a PaaS database, IaaS virtual machines, and FaaS for event processing. Which term best describes this consumption pattern?",
      "options": [
        "Multi-cloud",
        "Hybrid cloud",
        "XaaS",
        "Community cloud"
      ],
      "answer": 2,
      "explanation": "XaaS (Everything as a Service) describes consuming multiple cloud service models together across the service spectrum. Objective 1.1"
    },
    {
      "q": "A government agency requires that its cloud infrastructure is shared only among other government organizations with similar compliance needs. Which deployment model should they use?",
      "options": [
        "Public cloud",
        "Private cloud",
        "Hybrid cloud",
        "Community cloud"
      ],
      "answer": 3,
      "explanation": "Community cloud is shared among organizations with common requirements like compliance, security, or regulatory needs. Objective 1.2"
    },
    {
      "q": "A hospital stores patient records on-premises but uses a public cloud for its patient portal website. Data syncs between both environments. Which deployment model is this?",
      "options": [
        "Public cloud",
        "Private cloud",
        "Hybrid cloud",
        "Multi-cloud"
      ],
      "answer": 2,
      "explanation": "Hybrid cloud combines on-premises or private cloud with public cloud, with data and applications shared between them. Objective 1.2"
    },
    {
      "q": "A startup with no data center wants the fastest time to deploy infrastructure with minimal upfront cost. Which deployment model is most suitable?",
      "options": [
        "Private cloud",
        "Public cloud",
        "Community cloud",
        "On-premises"
      ],
      "answer": 1,
      "explanation": "Public cloud offers immediate provisioning with pay-as-you-go pricing and no upfront capital expenditure. Objective 1.2"
    },
    {
      "q": "A bank runs workloads on both AWS and Azure to avoid vendor lock-in and improve resilience. Which deployment model describes this approach?",
      "options": [
        "Hybrid cloud",
        "Multi-cloud",
        "Private cloud",
        "Community cloud"
      ],
      "answer": 1,
      "explanation": "Multi-cloud uses two or more public cloud providers to reduce vendor dependency and increase availability. Objective 1.2"
    },
    {
      "q": "A defense contractor must keep all computing resources within its own secured facility due to classified data requirements. Which deployment model applies?",
      "options": [
        "Public cloud",
        "Private cloud",
        "Hybrid cloud",
        "Multi-cloud"
      ],
      "answer": 1,
      "explanation": "Private cloud is dedicated to a single organization, often on-premises, providing maximum control over security and data. Objective 1.2"
    },
    {
      "q": "A video streaming service stores media files that are accessed by unique URLs and served globally. Files range from 10MB to 5GB. Which storage type is most appropriate?",
      "options": [
        "Block storage",
        "File storage",
        "Object storage",
        "Database storage"
      ],
      "answer": 2,
      "explanation": "Object storage is ideal for large unstructured data accessed via URLs/APIs, with built-in metadata and global distribution. Objective 1.3"
    },
    {
      "q": "A database administrator needs high-performance, low-latency storage that can be attached to a single VM as a drive volume. Which storage type should be used?",
      "options": [
        "Object storage",
        "File storage",
        "Block storage",
        "Archival storage"
      ],
      "answer": 2,
      "explanation": "Block storage provides high-performance volumes that attach to VMs as disk drives, ideal for databases requiring low latency. Objective 1.3"
    },
    {
      "q": "A team of designers needs shared storage where multiple Linux and Windows machines can read and write files simultaneously using standard protocols. Which storage type fits?",
      "options": [
        "Block storage",
        "Object storage",
        "File storage",
        "Ephemeral storage"
      ],
      "answer": 2,
      "explanation": "File storage supports NFS/SMB protocols allowing multiple machines to share files concurrently across operating systems. Objective 1.3"
    },
    {
      "q": "An application needs to store millions of user session records with flexible schema and fast key-value lookups. Which database type is most suitable?",
      "options": [
        "Relational database",
        "NoSQL database",
        "Data warehouse",
        "Graph database"
      ],
      "answer": 1,
      "explanation": "NoSQL databases handle flexible schemas with fast key-value lookups, ideal for session data at scale. Objective 1.3"
    },
    {
      "q": "A company must store regulatory compliance documents for 7 years but rarely accesses them. Which storage approach minimizes cost?",
      "options": [
        "SSD-backed block storage",
        "Standard file shares",
        "Object storage with archive tier",
        "In-memory caching"
      ],
      "answer": 2,
      "explanation": "Object storage archive tiers provide the lowest cost for infrequently accessed data with long retention requirements. Objective 1.3"
    },
    {
      "q": "An engineer is designing a VPC for a three-tier web application. The web servers must be internet-accessible while database servers must not. How should subnets be configured?",
      "options": [
        "Place all tiers in a single public subnet",
        "Place web servers in a public subnet and databases in a private subnet",
        "Place all tiers in a private subnet with no internet access",
        "Use a single private subnet with NAT for all tiers"
      ],
      "answer": 1,
      "explanation": "Public subnets for internet-facing web servers and private subnets for databases isolates tiers and limits attack surface. Objective 1.4"
    },
    {
      "q": "Users worldwide report slow load times for a website hosted in a single US region. Which service would most improve global performance?",
      "options": [
        "VPN gateway",
        "Content Delivery Network",
        "Network load balancer",
        "VPC peering"
      ],
      "answer": 1,
      "explanation": "A CDN caches content at edge locations globally, reducing latency for users far from the origin server. Objective 1.4"
    },
    {
      "q": "A company needs to securely connect its on-premises data center to a cloud VPC over the public internet with encrypted traffic. Which solution is most appropriate?",
      "options": [
        "VPC peering",
        "Site-to-site VPN",
        "CDN",
        "Public subnet"
      ],
      "answer": 1,
      "explanation": "Site-to-site VPN creates an encrypted tunnel over the internet between on-premises and cloud VPC networks. Objective 1.4"
    },
    {
      "q": "Two VPCs in different AWS regions need to communicate directly without traffic traversing the public internet. Which networking feature enables this?",
      "options": [
        "Internet gateway",
        "NAT gateway",
        "VPC peering",
        "CDN"
      ],
      "answer": 2,
      "explanation": "VPC peering connects two VPCs privately, allowing direct communication without using the public internet. Objective 1.4"
    },
    {
      "q": "A web application receives uneven traffic across four backend servers. Which component distributes incoming requests evenly to ensure no single server is overwhelmed?",
      "options": [
        "DNS server",
        "Load balancer",
        "Firewall",
        "VPN gateway"
      ],
      "answer": 1,
      "explanation": "Load balancers distribute incoming traffic across multiple backend servers to ensure even utilization and availability. Objective 1.4"
    },
    {
      "q": "An architect needs a DNS configuration that routes users to the nearest healthy data center based on geographic location. Which DNS feature should be used?",
      "options": [
        "Round-robin DNS",
        "Geolocation-based routing",
        "Simple A record",
        "CNAME alias"
      ],
      "answer": 1,
      "explanation": "Geolocation-based DNS routing directs users to the nearest data center, reducing latency and improving availability. Objective 1.4"
    },
    {
      "q": "A company requires 99.99% uptime for its e-commerce platform. Which design principle is MOST important to achieve this availability target?",
      "options": [
        "Cost optimization",
        "High availability",
        "Data sovereignty",
        "Single-region deployment"
      ],
      "answer": 1,
      "explanation": "High availability design uses redundancy across zones and regions to meet strict uptime SLAs like 99.99%. Objective 1.5"
    },
    {
      "q": "An online ticketing system must handle 10x normal traffic during concert sale events, then scale back down afterward. Which design principle applies?",
      "options": [
        "Fault tolerance",
        "Elasticity",
        "Disaster recovery",
        "Data redundancy"
      ],
      "answer": 1,
      "explanation": "Elasticity automatically scales resources up during demand spikes and back down when demand decreases. Objective 1.5"
    },
    {
      "q": "A cloud architect is asked to ensure that if an entire availability zone fails, the application continues to operate without data loss. Which concept directly addresses this?",
      "options": [
        "Scalability",
        "Elasticity",
        "Fault tolerance",
        "Cost optimization"
      ],
      "answer": 2,
      "explanation": "Fault tolerance ensures continued operation despite component failures, including entire availability zone outages. Objective 1.5"
    },
    {
      "q": "After a disaster destroys the primary data center, a company needs to restore operations within 4 hours and lose no more than 1 hour of data. What do these targets represent?",
      "options": [
        "SLA and SLO",
        "RTO of 4 hours and RPO of 1 hour",
        "RPO of 4 hours and RTO of 1 hour",
        "Scalability and elasticity targets"
      ],
      "answer": 1,
      "explanation": "RTO (Recovery Time Objective) is maximum acceptable downtime; RPO (Recovery Point Objective) is maximum acceptable data loss. Objective 1.5"
    },
    {
      "q": "A SaaS provider guarantees 99.95% monthly uptime in its contract with customers. What is this commitment called?",
      "options": [
        "RPO",
        "RTO",
        "SLA",
        "DR plan"
      ],
      "answer": 2,
      "explanation": "An SLA (Service Level Agreement) is a contractual commitment defining guaranteed service levels like uptime. Objective 1.5"
    },
    {
      "q": "A database is replicated synchronously across three availability zones. If one zone goes offline, the other two continue serving requests. Which principle does this demonstrate?",
      "options": [
        "Elasticity",
        "Scalability",
        "Redundancy",
        "Cost optimization"
      ],
      "answer": 2,
      "explanation": "Redundancy duplicates critical components across zones so that failure of one does not cause service disruption. Objective 1.5"
    },
    {
      "q": "An application currently handles 1,000 users but the company expects 50,000 users within a year. The architect plans to add more server instances as demand grows. Which principle is this?",
      "options": [
        "Fault tolerance",
        "Elasticity",
        "Horizontal scalability",
        "Disaster recovery"
      ],
      "answer": 2,
      "explanation": "Horizontal scalability adds more instances to handle growing demand, as opposed to vertical scaling which upgrades existing servers. Objective 1.5"
    },
    {
      "q": "A company's DR plan specifies a warm standby site in another region with replicated data. If the primary fails, traffic is redirected within 15 minutes. Which DR strategy is this?",
      "options": [
        "Backup and restore",
        "Pilot light",
        "Warm standby",
        "Multi-site active-active"
      ],
      "answer": 2,
      "explanation": "Warm standby maintains a scaled-down but functional copy of the environment that can be scaled up quickly during failover. Objective 1.5"
    },
    {
      "q": "An architect must choose between upgrading existing servers to larger sizes or adding more servers of the same size. What are these two approaches called?",
      "options": [
        "Horizontal and diagonal scaling",
        "Vertical and horizontal scaling",
        "Elastic and static scaling",
        "Manual and automatic scaling"
      ],
      "answer": 1,
      "explanation": "Vertical scaling (scale up) increases server size; horizontal scaling (scale out) adds more servers. Both are scalability strategies. Objective 1.5"
    },
    {
      "q": "A cloud provider offers instances in multiple isolated locations within a single region. What are these locations called?",
      "options": [
        "Regions",
        "Availability zones",
        "Edge locations",
        "VPCs"
      ],
      "answer": 1,
      "explanation": "Availability zones are isolated locations within a region, each with independent power, cooling, and networking. Objective 1.5"
    },
    {
      "q": "A media company stores its video content as objects in S3. Each video has metadata like title, resolution, and upload date attached directly to the storage object. What is this feature of object storage called?",
      "options": [
        "Block tagging",
        "File attributes",
        "Object metadata",
        "Storage indexing"
      ],
      "answer": 2,
      "explanation": "Object storage natively supports custom metadata attached to each object, enabling rich categorization without external databases. Objective 1.3"
    },
    {
      "q": "A company operates a private cloud on-premises but wants to burst into public cloud during peak holiday sales. Which deployment model describes this pattern?",
      "options": [
        "Multi-cloud",
        "Community cloud",
        "Hybrid cloud with cloud bursting",
        "Public cloud only"
      ],
      "answer": 2,
      "explanation": "Hybrid cloud bursting extends private cloud capacity by temporarily using public cloud resources during peak demand. Objective 1.2"
    },
    {
      "q": "An organization runs its web app on AWS but uses Google Cloud for big data analytics. Both clouds operate independently. Which deployment model is this?",
      "options": [
        "Hybrid cloud",
        "Multi-cloud",
        "Private cloud",
        "Community cloud"
      ],
      "answer": 1,
      "explanation": "Multi-cloud uses multiple public cloud providers for different workloads, operating independently rather than interconnected. Objective 1.2"
    },
    {
      "q": "A financial services firm must keep all customer data processing within the country's borders due to regulations. Which cloud concept addresses this requirement?",
      "options": [
        "Data redundancy",
        "Data sovereignty",
        "Data tiering",
        "Data deduplication"
      ],
      "answer": 1,
      "explanation": "Data sovereignty requires that data is stored and processed within specific geographic or legal boundaries to comply with regulations. Objective 1.5"
    },
    {
      "q": "A social media platform needs a database that efficiently handles complex relationships between users, posts, likes, and followers. Which database type is most appropriate?",
      "options": [
        "Relational database",
        "Key-value store",
        "Graph database",
        "Document database"
      ],
      "answer": 2,
      "explanation": "Graph databases excel at storing and querying complex relationships between entities, ideal for social network data. Objective 1.3"
    },
    {
      "q": "A company wants to add a read-only copy of its production database in another region to serve reporting queries without impacting production performance. What is this called?",
      "options": [
        "Database sharding",
        "Read replica",
        "Database snapshot",
        "Write-ahead log"
      ],
      "answer": 1,
      "explanation": "Read replicas are read-only copies of databases in other regions that offload read traffic from the primary database. Objective 1.3"
    },
    {
      "q": "An application running in a private subnet needs to download software updates from the internet, but must not be directly accessible from the internet. Which component enables this?",
      "options": [
        "Internet gateway",
        "NAT gateway",
        "VPC peering",
        "Load balancer"
      ],
      "answer": 1,
      "explanation": "NAT gateway allows resources in private subnets to initiate outbound internet connections while blocking inbound access. Objective 1.4"
    },
    {
      "q": "A company needs dedicated, high-bandwidth, low-latency connectivity between its data center and AWS that does not traverse the public internet. Which service should they use?",
      "options": [
        "Site-to-site VPN",
        "AWS Direct Connect",
        "Internet gateway",
        "VPC peering"
      ],
      "answer": 1,
      "explanation": "Direct Connect provides a dedicated private network connection between on-premises and cloud, bypassing the public internet. Objective 1.4"
    },
    {
      "q": "A microservices application needs service-to-service communication within the same VPC. Traffic should stay within the cloud provider's network. Which approach is best?",
      "options": [
        "Route traffic through a public load balancer",
        "Use internal (private) load balancing",
        "Set up a site-to-site VPN",
        "Create a CDN distribution"
      ],
      "answer": 1,
      "explanation": "Internal load balancing keeps traffic within the private network, providing efficient service-to-service communication. Objective 1.4"
    },
    {
      "q": "A cloud architect is designing for a system where losing even a single transaction is unacceptable. The RPO must be zero. Which replication method achieves this?",
      "options": [
        "Asynchronous replication",
        "Synchronous replication",
        "Daily backups",
        "Weekly snapshots"
      ],
      "answer": 1,
      "explanation": "Synchronous replication writes data to both primary and replica simultaneously, ensuring zero data loss (RPO=0). Objective 1.5"
    },
    {
      "q": "A company operates a pilot light DR strategy. What does this mean?",
      "options": [
        "A full duplicate environment runs in active-active mode",
        "Only the most critical core elements are kept running in the DR region",
        "Backups are stored offsite and restored manually during a disaster",
        "A scaled-down but fully functional environment runs in the DR region"
      ],
      "answer": 1,
      "explanation": "Pilot light keeps minimal critical components (like database replicas) running in DR, with other resources provisioned on demand. Objective 1.5"
    },
    {
      "q": "A startup wants to host a static website with HTML, CSS, and images at the lowest possible cost. Which cloud storage type is most appropriate?",
      "options": [
        "Block storage volume",
        "File share",
        "Object storage with static hosting",
        "Managed database"
      ],
      "answer": 2,
      "explanation": "Object storage with static website hosting is the cheapest option for serving static web content like HTML, CSS, and images. Objective 1.3"
    },
    {
      "q": "An IoT platform ingests millions of sensor readings per second. Each reading is a small key-value pair with a timestamp. Which database type handles this best?",
      "options": [
        "Relational database",
        "Time-series database",
        "Graph database",
        "Data warehouse"
      ],
      "answer": 1,
      "explanation": "Time-series databases are optimized for timestamp-indexed data with high write throughput, ideal for IoT sensor readings. Objective 1.3"
    },
    {
      "q": "A company needs to replicate data across regions for disaster recovery but can tolerate up to 5 minutes of data loss. Which replication approach is most cost-effective?",
      "options": [
        "Synchronous replication",
        "Asynchronous replication",
        "Real-time mirroring",
        "Manual backup transfer"
      ],
      "answer": 1,
      "explanation": "Asynchronous replication is more cost-effective for cross-region DR when some data loss (RPO > 0) is acceptable. Objective 1.5"
    },
    {
      "q": "A legacy application requires a specific operating system version and custom kernel modules. In which cloud service model can these requirements be met?",
      "options": [
        "SaaS",
        "FaaS",
        "PaaS",
        "IaaS"
      ],
      "answer": 3,
      "explanation": "IaaS provides full control over the operating system, including specific versions and custom kernel modules. Objective 1.1"
    },
    {
      "q": "A multinational company needs to ensure application requests from Europe are served by European servers while Asian requests go to Asian servers. Which technology enables this?",
      "options": [
        "Round-robin load balancing",
        "Geographic DNS routing",
        "Single-region deployment",
        "VPN tunnel"
      ],
      "answer": 1,
      "explanation": "Geographic DNS routing directs users to the closest regional deployment based on their geographic location. Objective 1.4"
    },
    {
      "q": "An e-commerce site experiences a 300% traffic spike during Black Friday. After the event, traffic returns to normal within hours. Which architecture principle should the site implement?",
      "options": [
        "Manual scaling",
        "Elasticity with auto-scaling",
        "Fixed capacity planning",
        "Vertical scaling only"
      ],
      "answer": 1,
      "explanation": "Elasticity with auto-scaling automatically adjusts resources based on real-time demand, handling temporary traffic spikes efficiently. Objective 1.5"
    },
    {
      "q": "A company stores log data that is frequently queried for the first 30 days, then rarely accessed for the next 11 months before deletion. Which storage strategy minimizes cost?",
      "options": [
        "Keep all data in high-performance storage",
        "Use lifecycle policies to move data to cheaper tiers over time",
        "Delete data after 30 days",
        "Store all data in archive tier from day one"
      ],
      "answer": 1,
      "explanation": "Lifecycle policies automatically transition data between storage tiers based on age, optimizing cost while maintaining access. Objective 1.3"
    },
    {
      "q": "An architect plans to deploy identical infrastructure across two regions so if one region fails entirely, the other handles all traffic. What is this DR strategy?",
      "options": [
        "Backup and restore",
        "Pilot light",
        "Warm standby",
        "Multi-site active-active"
      ],
      "answer": 3,
      "explanation": "Multi-site active-active runs full capacity in multiple regions simultaneously, providing instant failover with zero downtime. Objective 1.5"
    },
    {
      "q": "A healthcare application needs a managed relational database with automated backups and patching, but the team wants control over query optimization and indexing. Which service model aligns best?",
      "options": [
        "IaaS with self-managed database",
        "PaaS managed database service",
        "SaaS database application",
        "FaaS with database triggers"
      ],
      "answer": 1,
      "explanation": "PaaS managed databases handle backups, patching, and infrastructure while giving developers control over queries and indexes. Objective 1.1"
    },
    {
      "q": "A consulting firm uses cloud-based project management, invoicing, HR, and CRM tools all accessed through web browsers. Which service model category are they primarily consuming?",
      "options": [
        "IaaS",
        "PaaS",
        "SaaS",
        "FaaS"
      ],
      "answer": 2,
      "explanation": "SaaS provides complete applications accessed via browsers with the vendor managing everything from infrastructure to application. Objective 1.1"
    },
    {
      "q": "A development team needs to run nightly batch processing jobs that execute for 2-3 minutes and process files dropped in storage. Which compute model is most cost-effective?",
      "options": [
        "Dedicated virtual machines",
        "PaaS web hosting",
        "FaaS serverless functions",
        "Bare metal servers"
      ],
      "answer": 2,
      "explanation": "FaaS charges only for execution time, making it ideal for short-lived batch jobs that run infrequently. Objective 1.1"
    },
    {
      "q": "A company runs SAP ERP in the cloud with full vendor management of the application, middleware, runtime, and infrastructure. When a bug is found in SAP, who is responsible for patching it?",
      "options": [
        "The customer's IT team",
        "The cloud infrastructure provider",
        "The SaaS application vendor",
        "A third-party contractor"
      ],
      "answer": 2,
      "explanation": "In SaaS, the application vendor (SAP) is responsible for patching application-level bugs and maintaining the software. Objective 1.1"
    },
    {
      "q": "A research university wants to share a high-performance computing cluster with five partner universities working on genomics research. Which deployment model is ideal?",
      "options": [
        "Public cloud",
        "Private cloud",
        "Community cloud",
        "Hybrid cloud"
      ],
      "answer": 2,
      "explanation": "Community cloud is shared by organizations with common goals, such as research universities collaborating on genomics projects. Objective 1.2"
    },
    {
      "q": "A company's security policy states that encryption keys must never leave the company's physical premises. They still want to use public cloud for compute. Which model supports this?",
      "options": [
        "Public cloud only",
        "Private cloud only",
        "Hybrid cloud",
        "Community cloud"
      ],
      "answer": 2,
      "explanation": "Hybrid cloud allows keys to remain on-premises in a private environment while compute workloads run in the public cloud. Objective 1.2"
    },
    {
      "q": "A company using Azure for production and AWS for disaster recovery wants to ensure both environments use identical infrastructure configurations. What challenge does this represent?",
      "options": [
        "Data sovereignty compliance",
        "Multi-cloud portability",
        "Single-cloud optimization",
        "Community cloud governance"
      ],
      "answer": 1,
      "explanation": "Multi-cloud portability is the challenge of maintaining consistent configurations across different cloud providers. Objective 1.2"
    },
    {
      "q": "An organization wants to build a private cloud within its own data center using OpenStack. Which deployment model is this?",
      "options": [
        "Public cloud",
        "On-premises private cloud",
        "Hosted private cloud",
        "Hybrid cloud"
      ],
      "answer": 1,
      "explanation": "An on-premises private cloud is built and operated within the organization's own data center using tools like OpenStack. Objective 1.2"
    },
    {
      "q": "A SaaS vendor hosts its application for all customers on a shared public cloud infrastructure. Each customer's data is isolated logically. What is this architecture called?",
      "options": [
        "Multi-cloud",
        "Single-tenant",
        "Multi-tenant",
        "Hybrid deployment"
      ],
      "answer": 2,
      "explanation": "Multi-tenant architecture hosts multiple customers on shared infrastructure with logical data isolation between tenants. Objective 1.2"
    },
    {
      "q": "A video surveillance company needs to store petabytes of footage. Files are written once, accessed occasionally for investigations, and retained for 5 years. Which storage is most cost-effective?",
      "options": [
        "SSD block storage",
        "High-performance file shares",
        "Object storage in a cold/archive tier",
        "In-memory cache storage"
      ],
      "answer": 2,
      "explanation": "Cold/archive tier object storage provides the lowest cost per GB for write-once, infrequently-accessed data with long retention. Objective 1.3"
    },
    {
      "q": "A VM needs a boot disk with an operating system. Which cloud storage type should be used for the boot volume?",
      "options": [
        "Object storage",
        "File storage",
        "Block storage",
        "Tape storage"
      ],
      "answer": 2,
      "explanation": "Block storage is used for VM boot disks and operating system volumes, providing the low-latency random I/O that OS operations require. Objective 1.3"
    },
    {
      "q": "A data analytics team needs to store structured sales data for complex SQL queries, joins, and aggregations across billions of rows. Which storage type is best?",
      "options": [
        "Object storage",
        "File storage",
        "NoSQL database",
        "Relational data warehouse"
      ],
      "answer": 3,
      "explanation": "Relational data warehouses are optimized for complex SQL queries, joins, and aggregations across large structured datasets. Objective 1.3"
    },
    {
      "q": "An application stores user profile documents with varying fields per user. Some users have addresses, others have social profiles, and fields change over time. Which database type fits?",
      "options": [
        "Relational database with fixed schema",
        "Document database",
        "Time-series database",
        "Block storage"
      ],
      "answer": 1,
      "explanation": "Document databases store semi-structured data with flexible schemas, handling varying fields per record naturally. Objective 1.3"
    },
    {
      "q": "A mobile gaming company needs sub-millisecond response times for leaderboard lookups. Scores are stored as simple key-value pairs. Which database type is best?",
      "options": [
        "Relational database",
        "Graph database",
        "Key-value store",
        "Data warehouse"
      ],
      "answer": 2,
      "explanation": "Key-value stores provide the fastest lookups with sub-millisecond latency, ideal for simple data like gaming leaderboards. Objective 1.3"
    },
    {
      "q": "A company's cloud VPC uses the CIDR block 10.0.0.0/16. How many IP addresses does this provide?",
      "options": [
        "256",
        "512",
        "32,768",
        "65,536"
      ],
      "answer": 3,
      "explanation": "A /16 CIDR block provides 65,536 IP addresses (2^16), which is the host portion of the VPC address space. Objective 1.4"
    },
    {
      "q": "An application needs DNS failover so that if the primary endpoint becomes unhealthy, traffic automatically routes to a secondary endpoint. Which DNS feature enables this?",
      "options": [
        "CNAME record",
        "DNS health check with failover routing",
        "MX record",
        "Reverse DNS lookup"
      ],
      "answer": 1,
      "explanation": "DNS health checks monitor endpoint status and failover routing automatically redirects traffic to healthy secondary endpoints. Objective 1.4"
    },
    {
      "q": "A company wants Layer 7 load balancing that can route requests based on URL path, such as /api to backend servers and /images to a CDN origin. Which load balancer type is needed?",
      "options": [
        "Network load balancer (Layer 4)",
        "Application load balancer (Layer 7)",
        "DNS-based load balancing",
        "Global traffic manager"
      ],
      "answer": 1,
      "explanation": "Application load balancers operate at Layer 7 (HTTP) and can route based on URL path, headers, and other request attributes. Objective 1.4"
    },
    {
      "q": "Two VPCs need to communicate, but their CIDR ranges overlap (both use 10.0.0.0/16). What problem does this cause?",
      "options": [
        "No problem; VPCs can always be peered",
        "VPC peering fails because overlapping CIDRs create routing conflicts",
        "Traffic is automatically load balanced between them",
        "Both VPCs are merged into one"
      ],
      "answer": 1,
      "explanation": "VPC peering requires non-overlapping CIDR ranges; overlapping address spaces create ambiguous routing that prevents peering. Objective 1.4"
    },
    {
      "q": "An application uses a Network Load Balancer for TCP traffic on port 443. What layer of the OSI model does this load balancer primarily operate at?",
      "options": [
        "Layer 3 (Network)",
        "Layer 4 (Transport)",
        "Layer 7 (Application)",
        "Layer 2 (Data Link)"
      ],
      "answer": 1,
      "explanation": "Network Load Balancers operate at Layer 4 (Transport), routing TCP/UDP connections based on IP and port information. Objective 1.4"
    },
    {
      "q": "A company has an SLA of 99.9% uptime. What is the maximum allowable downtime per month?",
      "options": [
        "43.8 minutes",
        "8.76 hours",
        "4.38 minutes",
        "26.3 minutes"
      ],
      "answer": 0,
      "explanation": "99.9% uptime allows 0.1% downtime, which is approximately 43.8 minutes per 30-day month (30*24*60*0.001). Objective 1.5"
    },
    {
      "q": "An architect is designing for a system that must survive the failure of an entire cloud region. Which approach achieves this?",
      "options": [
        "Deploy across multiple availability zones in one region",
        "Deploy across multiple regions with data replication",
        "Use larger instance sizes in a single zone",
        "Add more instances in the same availability zone"
      ],
      "answer": 1,
      "explanation": "Multi-region deployment with data replication ensures the system survives an entire region failure through geographic redundancy. Objective 1.5"
    },
    {
      "q": "A team measures their application's recovery performance: it took 2 hours to restore service and they lost 30 minutes of data. What are the actual RTO and RPO?",
      "options": [
        "RTO = 30 minutes, RPO = 2 hours",
        "RTO = 2 hours, RPO = 30 minutes",
        "RTO = 2.5 hours, RPO = 0",
        "RTO = 0, RPO = 2.5 hours"
      ],
      "answer": 1,
      "explanation": "RTO is the time to restore service (2 hours); RPO is the amount of data lost measured in time (30 minutes). Objective 1.5"
    },
    {
      "q": "A company needs to verify that its DR plan actually works. What is the recommended approach?",
      "options": [
        "Only review the DR documentation annually",
        "Conduct regular DR drills and failover testing",
        "Assume the plan works based on vendor guarantees",
        "Wait for an actual disaster to test the plan"
      ],
      "answer": 1,
      "explanation": "Regular DR drills and failover tests validate that recovery procedures work correctly before an actual disaster occurs. Objective 1.5"
    },
    {
      "q": "In a multi-tier application, the web tier is stateless and the database tier is stateful. During scaling, which tier can be scaled horizontally with the least complexity?",
      "options": [
        "Database tier",
        "Web tier",
        "Both equally",
        "Neither can scale horizontally"
      ],
      "answer": 1,
      "explanation": "Stateless web tiers scale horizontally easily since any instance can handle any request without shared state concerns. Objective 1.5"
    },
    {
      "q": "A company stores objects in S3 and enables versioning. An employee accidentally deletes an important file. How can the file be recovered?",
      "options": [
        "It cannot be recovered once deleted",
        "Restore from the previous version using S3 versioning",
        "Contact AWS support to undelete the file",
        "Recover from the recycle bin"
      ],
      "answer": 1,
      "explanation": "S3 versioning retains all versions of objects; deleted objects can be recovered by restoring a previous version. Objective 1.3"
    },
    {
      "q": "An application needs a fully managed message queue to decouple microservices asynchronously. Which cloud service type is this?",
      "options": [
        "IaaS compute",
        "PaaS messaging service",
        "SaaS application",
        "FaaS function"
      ],
      "answer": 1,
      "explanation": "Managed message queue services are PaaS offerings that handle infrastructure while providing messaging APIs for decoupling services. Objective 1.1"
    },
    {
      "q": "A company wants to run containers but does not want to manage the underlying Kubernetes control plane. Which service model best describes a managed Kubernetes service?",
      "options": [
        "IaaS",
        "PaaS",
        "SaaS",
        "FaaS"
      ],
      "answer": 1,
      "explanation": "Managed Kubernetes services are PaaS offerings where the provider manages the control plane while customers deploy containerized apps. Objective 1.1"
    },
    {
      "q": "A company's VPC has both public and private subnets. Instances in the private subnet need to resolve external domain names. Which service provides this?",
      "options": [
        "NAT gateway",
        "Internet gateway",
        "Cloud DNS resolver",
        "VPC peering"
      ],
      "answer": 2,
      "explanation": "Cloud DNS resolvers provide name resolution for instances in private subnets, translating domain names to IP addresses. Objective 1.4"
    },
    {
      "q": "An architect needs to expose a private API to a specific partner company's VPC without making it publicly accessible. Which networking approach is best?",
      "options": [
        "Make the API public with IP whitelisting",
        "Use a VPC endpoint or PrivateLink connection",
        "Set up a VPN to the partner's on-premises network",
        "Deploy the API in a public subnet"
      ],
      "answer": 1,
      "explanation": "VPC endpoints or PrivateLink provide private connectivity between VPCs without exposing services to the public internet. Objective 1.4"
    },
    {
      "q": "A latency-sensitive trading application needs the lowest possible network delay between two cloud services in the same cloud. Where should they be placed?",
      "options": [
        "In different regions for redundancy",
        "In the same availability zone",
        "In different availability zones in the same region",
        "In a CDN edge location"
      ],
      "answer": 1,
      "explanation": "Placing services in the same availability zone minimizes network latency since they share the same physical data center. Objective 1.4"
    },
    {
      "q": "A company wants to set up an alert that triggers when their monthly cloud bill exceeds $10,000. Which cloud feature supports this?",
      "options": [
        "SLA monitoring",
        "Budget alerts and billing alarms",
        "Performance monitoring",
        "Security alerting"
      ],
      "answer": 1,
      "explanation": "Budget alerts and billing alarms notify stakeholders when cloud spending exceeds defined thresholds. Objective 1.5"
    },
    {
      "q": "An application uses auto-scaling with a minimum of 2 instances, maximum of 10, and scales based on CPU utilization above 70%. What type of scaling policy is this?",
      "options": [
        "Scheduled scaling",
        "Target tracking scaling",
        "Step scaling",
        "Manual scaling"
      ],
      "answer": 1,
      "explanation": "Target tracking scaling automatically adjusts capacity to maintain a target metric value, such as 70% CPU utilization. Objective 1.5"
    },
    {
      "q": "A company deploys a web application in a single availability zone. A power outage takes down that zone. What single change would have prevented the outage from affecting users?",
      "options": [
        "Use larger instance sizes",
        "Deploy across multiple availability zones",
        "Increase storage capacity",
        "Add more CPU cores to existing instances"
      ],
      "answer": 1,
      "explanation": "Multi-AZ deployment provides fault tolerance against single availability zone failures by distributing resources across zones. Objective 1.5"
    },
    {
      "q": "A company uses cloud block storage that provides 3,000 IOPS. Their database needs 10,000 IOPS. What should they do?",
      "options": [
        "Switch to object storage",
        "Provision a higher-performance block storage tier",
        "Add file storage as a supplement",
        "Use a CDN to cache database queries"
      ],
      "answer": 1,
      "explanation": "Upgrading to a higher-performance block storage tier provides the additional IOPS needed for database workloads. Objective 1.3"
    },
    {
      "q": "A company has a private cloud with VMware infrastructure. They want to extend it to AWS while maintaining consistent networking and VM management. Which solution type helps?",
      "options": [
        "Use only public cloud services",
        "Deploy VMware Cloud on AWS as a hybrid extension",
        "Migrate everything to native AWS services",
        "Build a community cloud with partners"
      ],
      "answer": 1,
      "explanation": "VMware Cloud on AWS extends on-premises VMware environments to AWS, providing consistent hybrid cloud management. Objective 1.2"
    },
    {
      "q": "Which cloud design principle ensures that a system can handle increased load by adding resources without redesigning the architecture?",
      "options": [
        "Fault tolerance",
        "Elasticity",
        "Scalability",
        "High availability"
      ],
      "answer": 2,
      "explanation": "Scalability is the ability to handle increased load by adding resources while maintaining the same architecture. Objective 1.5"
    },
    {
      "q": "A company uses blob storage to store user-uploaded images. Each image can be accessed via a unique HTTP URL. Which storage type is this?",
      "options": [
        "Block storage",
        "File storage",
        "Object storage",
        "Ephemeral storage"
      ],
      "answer": 2,
      "explanation": "Object/blob storage stores unstructured data accessible via HTTP URLs, ideal for user-uploaded content like images. Objective 1.3"
    },
    {
      "q": "A company needs to analyze click-stream data from its website in real-time. Which type of database or service is most appropriate for streaming data ingestion?",
      "options": [
        "Relational database",
        "Stream processing service",
        "File storage",
        "Graph database"
      ],
      "answer": 1,
      "explanation": "Stream processing services are designed for real-time ingestion and analysis of continuously generated data like click-streams. Objective 1.3"
    },
    {
      "q": "An application running on IaaS VMs uses security groups to control network access. At which level do security groups typically operate?",
      "options": [
        "Subnet level",
        "Instance/NIC level",
        "VPC level",
        "Region level"
      ],
      "answer": 1,
      "explanation": "Security groups operate at the instance or network interface level, controlling traffic to and from individual resources. Objective 1.4"
    },
    {
      "q": "A company needs to transfer 100TB of data from on-premises to the cloud. Internet transfer would take weeks. Which approach accelerates this?",
      "options": [
        "Use a faster internet connection",
        "Use a physical data transfer appliance like AWS Snowball",
        "Compress all data before transfer",
        "Transfer during off-peak hours"
      ],
      "answer": 1,
      "explanation": "Physical transfer appliances ship data via secure devices, transferring petabytes much faster than internet-based methods. Objective 1.3"
    },
    {
      "q": "A global company places resources in US, Europe, and Asia regions. What is the primary benefit of multi-region deployment besides DR?",
      "options": [
        "Lower storage costs",
        "Reduced latency for global users",
        "Simpler architecture",
        "Fewer compliance requirements"
      ],
      "answer": 1,
      "explanation": "Multi-region deployment places resources closer to users worldwide, significantly reducing network latency. Objective 1.5"
    },
    {
      "q": "In the shared responsibility model for IaaS, which of the following is the cloud provider's responsibility?",
      "options": [
        "OS patching",
        "Application security",
        "Physical data center security",
        "Firewall rule configuration"
      ],
      "answer": 2,
      "explanation": "In IaaS, the cloud provider is responsible for physical security of data centers; customers manage OS, apps, and configurations. Objective 1.1"
    },
    {
      "q": "A company configured auto-scaling to add instances when latency exceeds 200ms and remove them when latency drops below 100ms. What type of scaling metric is latency in this case?",
      "options": [
        "Infrastructure metric",
        "Custom application metric",
        "Billing metric",
        "Compliance metric"
      ],
      "answer": 1,
      "explanation": "Latency is a custom application metric used for scaling decisions, as opposed to infrastructure metrics like CPU or memory. Objective 1.5"
    },
    {
      "q": "A company's cloud file storage is running out of space. They notice 60% of data hasn't been accessed in over a year. What is the best cost-optimization approach?",
      "options": [
        "Delete all data older than one year",
        "Move infrequently accessed data to a cheaper storage tier",
        "Purchase additional high-performance storage",
        "Compress all files on the current tier"
      ],
      "answer": 1,
      "explanation": "Moving cold data to cheaper storage tiers reduces costs while retaining the data for potential future access. Objective 1.3"
    },
    {
      "q": "A cloud VPC is configured with a route table entry: destination 0.0.0.0/0, target Internet Gateway. What does this route do?",
      "options": [
        "Blocks all traffic from the VPC",
        "Routes all non-local traffic to the internet via the gateway",
        "Routes traffic only within the VPC",
        "Creates a VPN connection to on-premises"
      ],
      "answer": 1,
      "explanation": "A 0.0.0.0/0 route to an Internet Gateway is a default route that sends all non-local traffic to the internet. Objective 1.4"
    },
    {
      "q": "A company's backup strategy creates full backups on Sunday and incremental backups Monday through Saturday. On Wednesday, they need to restore data. Which backups are needed?",
      "options": [
        "Only Wednesday's incremental backup",
        "Sunday's full backup plus Monday, Tuesday, and Wednesday incrementals",
        "Sunday's full backup only",
        "All seven days of backups"
      ],
      "answer": 1,
      "explanation": "Incremental backup restoration requires the last full backup plus all subsequent incremental backups up to the desired point. Objective 1.5"
    },
    {
      "q": "A cloud architect is designing a system where each component can fail independently without bringing down the entire application. Which design pattern achieves this?",
      "options": [
        "Monolithic architecture",
        "Loosely coupled microservices",
        "Single-server deployment",
        "Tightly coupled components"
      ],
      "answer": 1,
      "explanation": "Loosely coupled microservices isolate failures to individual components, preventing cascading failures across the application. Objective 1.5"
    },
    {
      "q": "A managed NoSQL database service automatically handles replication, patching, and backups. In the shared responsibility model, what remains the customer's responsibility?",
      "options": [
        "Database engine patching",
        "Hardware maintenance",
        "Data modeling and access control configuration",
        "Storage replication"
      ],
      "answer": 2,
      "explanation": "With managed database services, customers remain responsible for data modeling, access control, and how they use the service. Objective 1.1"
    },
    {
      "q": "A gaming company uses a CDN for distributing game patches to players worldwide. When a new patch is released, players receive the old version for several hours. What is the likely issue?",
      "options": [
        "The CDN is offline",
        "CDN cache has not expired or been invalidated for the updated content",
        "Players need to clear their browser cache",
        "The origin server is overloaded"
      ],
      "answer": 1,
      "explanation": "CDN edge caches serve stale content until the TTL expires or cache is explicitly invalidated after content updates. Objective 1.4"
    },
    {
      "q": "A startup is choosing between running their own Kubernetes cluster on IaaS VMs vs using a managed Kubernetes service. What is the main advantage of the managed service?",
      "options": [
        "Lower per-node compute costs",
        "The provider manages the control plane, reducing operational burden",
        "More customization of the Kubernetes API",
        "Better application performance"
      ],
      "answer": 1,
      "explanation": "Managed Kubernetes handles control plane management, upgrades, and availability, reducing operational overhead for the team. Objective 1.1"
    }
  ],
  "2. Deployment": [
    {
      "q": "A company is migrating physical servers running Windows Server 2016 to AWS EC2. The servers have custom drivers and legacy applications. Which migration strategy preserves the existing OS and configurations?",
      "options": [
        "Re-architect the application",
        "P2V (Physical to Virtual) migration",
        "Rebuild from scratch in the cloud",
        "Use a SaaS replacement"
      ],
      "answer": 1,
      "explanation": "P2V migration converts physical servers to virtual machines, preserving the OS, drivers, and application configurations. Objective 2.1"
    },
    {
      "q": "An organization running VMware VMs on-premises wants to move them to Azure while keeping the same VM format. Which migration approach is appropriate?",
      "options": [
        "P2V migration",
        "V2V (Virtual to Virtual) migration",
        "Database migration service",
        "Manual application reinstall"
      ],
      "answer": 1,
      "explanation": "V2V migration moves virtual machines between hypervisors or cloud platforms while maintaining the VM format and configuration. Objective 2.1"
    },
    {
      "q": "A company is migrating a 10TB Oracle database to Amazon RDS with minimal downtime and continuous replication during the transition. Which service helps?",
      "options": [
        "AWS Snowball",
        "AWS Database Migration Service",
        "Manual database export/import",
        "Storage Gateway"
      ],
      "answer": 1,
      "explanation": "Database Migration Service provides continuous replication with minimal downtime for database migrations to managed services. Objective 2.1"
    },
    {
      "q": "During a cloud migration, a company needs to move 50TB from on-premises NAS to cloud file storage but internet bandwidth is only 100Mbps. What is the fastest approach?",
      "options": [
        "Transfer over the internet directly",
        "Use a physical data transfer appliance",
        "Compress and transfer via FTP",
        "Split into smaller chunks and transfer nightly"
      ],
      "answer": 1,
      "explanation": "Physical transfer appliances can move large data volumes much faster than limited internet bandwidth allows. Objective 2.1"
    },
    {
      "q": "A company is migrating workloads from GCP to AWS. Which migration type describes moving between cloud providers?",
      "options": [
        "P2V migration",
        "V2V migration",
        "Cloud-to-cloud migration",
        "Lift and shift"
      ],
      "answer": 2,
      "explanation": "Cloud-to-cloud migration moves workloads between different cloud providers, potentially requiring format and API changes. Objective 2.1"
    },
    {
      "q": "After migrating VMs to the cloud, applications run slower than on-premises. VMs use general-purpose instance types. What should be done first?",
      "options": [
        "Migrate back to on-premises",
        "Right-size instances based on actual workload requirements",
        "Add more general-purpose instances",
        "Increase storage only"
      ],
      "answer": 1,
      "explanation": "Right-sizing matches instance types and sizes to actual workload needs, often resolving performance issues after migration. Objective 2.1"
    },
    {
      "q": "A company wants encrypted connectivity between their data center and AWS VPC over the public internet. Which service should they use?",
      "options": [
        "AWS Direct Connect",
        "Site-to-site VPN",
        "VPC peering",
        "Transit Gateway"
      ],
      "answer": 1,
      "explanation": "Site-to-site VPN creates an encrypted IPsec tunnel over the public internet between on-premises and cloud VPC. Objective 2.2"
    },
    {
      "q": "A company needs a dedicated 1Gbps private connection from their data center to AWS that avoids the public internet entirely. Which service provides this?",
      "options": [
        "Site-to-site VPN",
        "AWS Direct Connect",
        "Internet Gateway",
        "CloudFront"
      ],
      "answer": 1,
      "explanation": "Direct Connect provides dedicated private network connections between on-premises and AWS, bypassing the public internet. Objective 2.2"
    },
    {
      "q": "During a DNS cutover from on-premises to cloud, users still reach old servers 2 hours later. What is the most likely cause?",
      "options": [
        "Cloud servers are offline",
        "DNS TTL has not expired in client caches",
        "The firewall is blocking traffic",
        "Load balancer is misconfigured"
      ],
      "answer": 1,
      "explanation": "DNS TTL controls how long clients cache DNS records; until TTL expires, clients continue using cached old IP addresses. Objective 2.2"
    },
    {
      "q": "An architect configures security groups for web servers that need HTTP/HTTPS from the internet and database access on port 3306. Which rules are correct?",
      "options": [
        "Allow all traffic on all ports for both",
        "Web SG: inbound 80,443 from 0.0.0.0/0; DB SG: inbound 3306 from web SG only",
        "DB SG: inbound 80,443 from internet; Web SG: inbound 3306 from DB SG",
        "Allow outbound only on both security groups"
      ],
      "answer": 1,
      "explanation": "Web servers need internet access on 80/443; databases should only accept connections from web servers via security group reference. Objective 2.2"
    },
    {
      "q": "A Network ACL allows inbound HTTP on port 80 but web clients cannot access servers. Both inbound and outbound default to deny. What is the issue?",
      "options": [
        "NACLs cannot allow HTTP traffic",
        "NACLs are stateless; an outbound rule for return traffic is also needed",
        "Security groups are overriding the NACL",
        "The instance is in the wrong subnet"
      ],
      "answer": 1,
      "explanation": "NACLs are stateless, meaning both inbound and outbound rules must be explicitly configured for traffic to flow. Objective 2.2"
    },
    {
      "q": "A company has 50 VPCs across multiple AWS accounts that need intercommunication. What is the most scalable networking solution?",
      "options": [
        "Create VPC peering between all 50 VPCs",
        "Use a Transit Gateway as a central hub",
        "Configure VPN between each pair",
        "Put all resources in a single VPC"
      ],
      "answer": 1,
      "explanation": "Transit Gateway acts as a central hub connecting multiple VPCs and on-premises networks, scaling better than full-mesh peering. Objective 2.2"
    },
    {
      "q": "A production web application VM has 8 vCPUs and 32GB RAM but monitoring shows only 20% CPU and 40% RAM usage. What action should be taken?",
      "options": [
        "Add more identical VMs",
        "Right-size by moving to a smaller instance type",
        "Keep the current size for future growth",
        "Add more RAM to existing VMs"
      ],
      "answer": 1,
      "explanation": "Right-sizing reduces instance size to match actual usage, eliminating waste and reducing costs without impacting performance. Objective 2.3"
    },
    {
      "q": "Auto-scaling adds instances when CPU exceeds 70%, but new instances take 5 minutes to initialize during traffic spikes. What improvement should be made?",
      "options": [
        "Increase CPU threshold to 90%",
        "Use pre-warmed instances or custom AMIs to reduce boot time",
        "Disable auto-scaling during peak hours",
        "Use larger instances instead of scaling"
      ],
      "answer": 1,
      "explanation": "Custom AMIs and pre-warmed instances reduce initialization time, ensuring auto-scaled instances serve traffic faster. Objective 2.3"
    },
    {
      "q": "A company wants to run containerized microservices in production with automated scheduling, self-healing, and rolling updates. Which platform should they use?",
      "options": [
        "Docker Compose",
        "Kubernetes",
        "Virtual machines",
        "Bare metal servers"
      ],
      "answer": 1,
      "explanation": "Kubernetes provides container orchestration with scheduling, self-healing, rolling updates, and service discovery. Objective 2.3"
    },
    {
      "q": "A developer has a containerized app that runs locally with Docker. They want to deploy it to the cloud without managing servers or clusters. Which option is best?",
      "options": [
        "Deploy on EC2 instances manually",
        "Use a serverless container service like Fargate",
        "Set up a self-managed Kubernetes cluster",
        "Convert containers to VMs"
      ],
      "answer": 1,
      "explanation": "Serverless container services like Fargate run containers without managing underlying servers or clusters. Objective 2.3"
    },
    {
      "q": "An application processes uploaded images taking 10-30 seconds each with unpredictable workload. Which compute model minimizes cost?",
      "options": [
        "Reserved instances running 24/7",
        "Serverless functions triggered by upload events",
        "Dedicated host instances",
        "On-premises GPU servers"
      ],
      "answer": 1,
      "explanation": "Serverless functions are ideal for event-driven, unpredictable workloads as they charge only for execution time. Objective 2.3"
    },
    {
      "q": "A production database needs 500GB block storage with consistent 10,000 IOPS. Which storage deployment is correct?",
      "options": [
        "Use standard object storage",
        "Provision provisioned-IOPS SSD block storage",
        "Use general-purpose file shares",
        "Attach multiple low-performance volumes"
      ],
      "answer": 1,
      "explanation": "Provisioned-IOPS SSD storage guarantees consistent performance levels required for database workloads. Objective 2.4"
    },
    {
      "q": "Application logs are actively queried for 7 days, occasionally for 30 days, then stored for compliance for 1 year. Which approach minimizes storage cost?",
      "options": [
        "Keep all logs in high-performance storage",
        "Configure lifecycle policies to transition through tiers",
        "Delete logs after 30 days",
        "Store everything in archive tier immediately"
      ],
      "answer": 1,
      "explanation": "Lifecycle policies automatically move data through storage tiers based on age, optimizing costs. Objective 2.4"
    },
    {
      "q": "A database needs point-in-time recovery to any second within the last 35 days. Which feature enables this?",
      "options": [
        "Manual weekly backups",
        "Continuous automated backups with transaction log retention",
        "Daily snapshots only",
        "Block-level replication to another region"
      ],
      "answer": 1,
      "explanation": "Continuous automated backups with transaction log retention enable point-in-time recovery within the retention window. Objective 2.4"
    },
    {
      "q": "A company needs to replicate S3 bucket contents to another region for disaster recovery. Which feature should they enable?",
      "options": [
        "S3 versioning only",
        "S3 cross-region replication",
        "CloudFront distribution",
        "S3 lifecycle policy"
      ],
      "answer": 1,
      "explanation": "S3 cross-region replication automatically copies objects to a bucket in another region for disaster recovery. Objective 2.4"
    },
    {
      "q": "Before a major OS upgrade on a production VM, what should a sysadmin create as a recovery point?",
      "options": [
        "A storage lifecycle rule",
        "A snapshot of the VM's volumes",
        "Versioning on object storage",
        "Cross-region replication"
      ],
      "answer": 1,
      "explanation": "Volume snapshots capture a point-in-time copy of block storage, enabling quick rollback if an upgrade fails. Objective 2.4"
    },
    {
      "q": "A team wants to deploy updates with zero downtime by running the new version alongside the old and switching traffic instantly. Which deployment strategy is this?",
      "options": [
        "Rolling update",
        "Blue-green deployment",
        "Canary deployment",
        "In-place deployment"
      ],
      "answer": 1,
      "explanation": "Blue-green deployment runs two identical environments; traffic switches from old (blue) to new (green) instantly. Objective 2.5"
    },
    {
      "q": "A team wants to test a new feature with only 5% of production users before full rollout. Which deployment strategy supports this?",
      "options": [
        "Blue-green deployment",
        "Rolling update",
        "Canary deployment",
        "In-place upgrade"
      ],
      "answer": 2,
      "explanation": "Canary deployment gradually routes a small percentage of traffic to the new version for testing before full rollout. Objective 2.5"
    },
    {
      "q": "A company uses Terraform to define cloud infrastructure. What is the primary advantage of storing infrastructure definitions as code?",
      "options": [
        "It eliminates cloud resources",
        "Infrastructure can be version-controlled, reviewed, and reproduced consistently",
        "It makes changes instantaneous",
        "It removes cloud provider access needs"
      ],
      "answer": 1,
      "explanation": "Infrastructure as Code enables version control, peer review, and consistent reproducible deployments. Objective 2.5"
    },
    {
      "q": "A production deployment caused an error. The team needs to quickly return to the previous working version. Which practice makes this easiest?",
      "options": [
        "Manually fix code in production",
        "Automated rollback to the previous version",
        "Deploy a new app from scratch",
        "Shut down the application until fixed"
      ],
      "answer": 1,
      "explanation": "Automated rollback mechanisms instantly revert to the last known good deployment, minimizing downtime. Objective 2.5"
    },
    {
      "q": "A company needs identical configurations on 100 servers. An engineer configured one manually. Which IaC approach replicates this consistently?",
      "options": [
        "Manually configure each server",
        "Use Ansible to apply configurations",
        "Clone the VM 99 times",
        "Document steps in a wiki"
      ],
      "answer": 1,
      "explanation": "Configuration management tools like Ansible automate consistent configuration across many servers. Objective 2.5"
    },
    {
      "q": "A CI/CD pipeline has build, unit test, integration test, staging, and production stages. A unit test fails. What should happen?",
      "options": [
        "Skip the failed test and continue",
        "The pipeline stops and the team is notified",
        "Deploy to production with a warning",
        "Automatically fix the test"
      ],
      "answer": 1,
      "explanation": "CI/CD pipelines should halt on test failures to prevent broken code from reaching production. Objective 2.5"
    },
    {
      "q": "A Kubernetes deployment with 3 replicas uses rolling update with maxUnavailable=1. What is the minimum number of pods available during update?",
      "options": [
        "0",
        "1",
        "2",
        "3"
      ],
      "answer": 2,
      "explanation": "With 3 replicas and maxUnavailable=1, at least 2 pods remain available during the rolling update. Objective 2.3"
    },
    {
      "q": "A company wants development, staging, and production environments to be identical. Which practice best achieves this?",
      "options": [
        "Manual setup of each environment",
        "Infrastructure as Code with shared templates",
        "Different teams manage each independently",
        "Use different cloud providers per environment"
      ],
      "answer": 1,
      "explanation": "IaC templates ensure identical infrastructure across environments, reducing configuration drift. Objective 2.5"
    },
    {
      "q": "During migration planning, a company categorizes apps into rehost, replatform, refactor, retire, and retain groups. What is this classification called?",
      "options": [
        "Risk assessment",
        "The 6 Rs migration strategy framework",
        "Cost analysis",
        "Security audit"
      ],
      "answer": 1,
      "explanation": "The 6 Rs framework helps classify applications by migration approach during cloud migration planning. Objective 2.1"
    },
    {
      "q": "A company wants to move their legacy monolith to cloud VMs with zero code changes. Which migration strategy is this?",
      "options": [
        "Refactor",
        "Rehost (lift and shift)",
        "Repurchase",
        "Retire"
      ],
      "answer": 1,
      "explanation": "Rehost (lift and shift) moves applications to cloud VMs without modifications. Objective 2.1"
    },
    {
      "q": "A team decides to rebuild their app using cloud-native serverless and managed databases instead of migrating existing code. Which migration strategy is this?",
      "options": [
        "Rehost",
        "Replatform",
        "Refactor/re-architect",
        "Retain"
      ],
      "answer": 2,
      "explanation": "Refactoring/re-architecting redesigns applications to be cloud-native, leveraging managed services. Objective 2.1"
    },
    {
      "q": "A security team requires all traffic between on-premises and cloud to use encrypted tunnels with certificate-based authentication. Which VPN configuration provides this?",
      "options": [
        "Pre-shared key only",
        "IPsec with certificate-based authentication",
        "Unencrypted direct connection",
        "HTTP basic authentication"
      ],
      "answer": 1,
      "explanation": "IPsec with certificate-based authentication provides encrypted tunnels with strong mutual authentication. Objective 2.2"
    },
    {
      "q": "A microservice's security group allows inbound traffic from any IP on all ports. What security principle does this violate?",
      "options": [
        "Defense in depth",
        "Least privilege",
        "Separation of duties",
        "Non-repudiation"
      ],
      "answer": 1,
      "explanation": "Allowing all ports from any IP violates least privilege; only necessary traffic from specific sources should be allowed. Objective 2.2"
    },
    {
      "q": "During a rolling deployment of 10 servers updating 2 at a time, what is the update batch percentage?",
      "options": [
        "10%",
        "20%",
        "50%",
        "80%"
      ],
      "answer": 1,
      "explanation": "Updating 2 out of 10 servers at a time is a 20% batch size, balancing speed with availability. Objective 2.5"
    },
    {
      "q": "A company uses CloudFormation to provision infrastructure but an engineer makes a manual console change to a security group. What is this situation called?",
      "options": [
        "Configuration update",
        "Infrastructure drift",
        "Scaling event",
        "Failover"
      ],
      "answer": 1,
      "explanation": "Infrastructure drift occurs when actual resources differ from IaC definitions due to manual changes. Objective 2.5"
    },
    {
      "q": "A containerized app needs persistent storage that survives pod restarts in Kubernetes. Which resource provides this?",
      "options": [
        "ConfigMap",
        "PersistentVolumeClaim",
        "Secret",
        "Ingress"
      ],
      "answer": 1,
      "explanation": "PersistentVolumeClaims provide storage that persists across pod lifecycle events. Objective 2.3"
    },
    {
      "q": "An application needs more memory but less CPU than its current instance type. What action best addresses this?",
      "options": [
        "Add another identical VM",
        "Switch to a memory-optimized instance type",
        "Add more CPU cores",
        "Attach additional storage"
      ],
      "answer": 1,
      "explanation": "Memory-optimized instance types provide higher memory-to-CPU ratios for RAM-intensive workloads. Objective 2.3"
    },
    {
      "q": "A team uses A/B testing to compare two checkout page versions. How is traffic typically split?",
      "options": [
        "All traffic goes to version A first then B",
        "Traffic is split by user segments or percentages to compare metrics",
        "Version B replaces A entirely",
        "Both run on the same server"
      ],
      "answer": 1,
      "explanation": "A/B testing splits traffic between versions based on segments or percentages to measure performance differences. Objective 2.5"
    },
    {
      "q": "A company stores 1PB of video assets that are accessed frequently for the first month then rarely. Which provisioning approach minimizes cost?",
      "options": [
        "Provision all at premium tier",
        "Use automatic tiering based on access patterns",
        "Store in cheapest archival tier",
        "Delete content after first month"
      ],
      "answer": 1,
      "explanation": "Automatic tiering moves data between tiers based on access frequency, optimizing cost without manual effort. Objective 2.4"
    },
    {
      "q": "A CI/CD pipeline includes a manual approval gate before production. Why is this a best practice?",
      "options": [
        "It slows deployment intentionally",
        "It ensures human review before production changes",
        "It prevents automated testing",
        "It eliminates staging environments"
      ],
      "answer": 1,
      "explanation": "Manual approval gates provide a human checkpoint to validate changes before impacting production. Objective 2.5"
    },
    {
      "q": "A migration assessment finds an application nobody uses. Which migration strategy applies?",
      "options": [
        "Rehost",
        "Replatform",
        "Refactor",
        "Retire"
      ],
      "answer": 3,
      "explanation": "Retire decommissions unused applications, reducing migration scope and costs. Objective 2.1"
    },
    {
      "q": "An engineer configures storage replication rules to copy data to a bucket in another region automatically. What type of replication is this?",
      "options": [
        "Synchronous local replication",
        "Cross-region asynchronous replication",
        "Same-zone mirroring",
        "Tape backup replication"
      ],
      "answer": 1,
      "explanation": "Cross-region replication asynchronously copies objects to another region for DR and durability. Objective 2.4"
    },
    {
      "q": "A Kubernetes pod requests 256MB memory with a 512MB limit. What happens if it tries to use 600MB?",
      "options": [
        "Pod continues normally",
        "Pod is OOMKilled by Kubernetes",
        "Kubernetes adds more memory",
        "Pod migrates to a larger node"
      ],
      "answer": 1,
      "explanation": "Exceeding memory limits causes Kubernetes to terminate the pod with OOMKilled status. Objective 2.3"
    },
    {
      "q": "A firewall rule allows TCP port 22 from 10.0.0.0/8. What traffic does this permit?",
      "options": [
        "HTTP from the internet",
        "SSH from private 10.x.x.x addresses",
        "DNS from any source",
        "HTTPS from public addresses"
      ],
      "answer": 1,
      "explanation": "TCP port 22 is SSH; 10.0.0.0/8 represents private addresses, allowing SSH from internal networks. Objective 2.2"
    },
    {
      "q": "After a blue-green deployment, a critical bug is found in the green environment 30 minutes later. What should the team do?",
      "options": [
        "Debug in production on green",
        "Switch traffic back to blue immediately",
        "Deploy a hotfix to green",
        "Shut down both environments"
      ],
      "answer": 1,
      "explanation": "Blue-green enables instant rollback by switching traffic back to the stable blue environment. Objective 2.5"
    },
    {
      "q": "A Terraform state file contains database passwords. Where should it be stored securely?",
      "options": [
        "In the public Git repository",
        "In an encrypted remote backend with access controls",
        "On a developer's local machine only",
        "In an unencrypted shared drive"
      ],
      "answer": 1,
      "explanation": "Terraform state with sensitive data should use encrypted remote backends with access controls. Objective 2.5"
    },
    {
      "q": "A company wants rolling deployment that replaces instances one at a time with health checks before proceeding. Which strategy is this?",
      "options": [
        "Blue-green deployment",
        "Rolling deployment",
        "Canary deployment",
        "Big bang deployment"
      ],
      "answer": 1,
      "explanation": "Rolling deployment replaces instances one at a time (or in small batches), health-checking each before proceeding. Objective 2.5"
    },
    {
      "q": "During cloud migration, a company's on-premises DNS handles internal resolution. Cloud VMs need to resolve both internal and cloud names. Which solution works?",
      "options": [
        "Use only public DNS",
        "Configure hybrid DNS with forwarding rules",
        "Disable DNS resolution on cloud VMs",
        "Use IP addresses instead of hostnames"
      ],
      "answer": 1,
      "explanation": "Hybrid DNS with conditional forwarding enables resolution of both on-premises and cloud domain names. Objective 2.2"
    },
    {
      "q": "A company needs to migrate an on-premises MySQL 5.7 database to a cloud-managed MySQL service with schema conversion. Which tool category assists with this?",
      "options": [
        "Network migration tool",
        "Schema conversion tool",
        "VM imaging tool",
        "DNS migration service"
      ],
      "answer": 1,
      "explanation": "Schema conversion tools analyze and convert database schemas during migration to managed database services. Objective 2.1"
    },
    {
      "q": "A company's migration plan includes running applications in both on-premises and cloud simultaneously during a 6-month transition period. What is this approach called?",
      "options": [
        "Big bang migration",
        "Phased/parallel migration",
        "Lift and shift",
        "Cutover migration"
      ],
      "answer": 1,
      "explanation": "Phased migration runs workloads in both environments simultaneously, migrating gradually to reduce risk. Objective 2.1"
    },
    {
      "q": "An application currently uses an on-premises Oracle database. The team wants to migrate to a cloud-managed PostgreSQL database. Which migration strategy applies?",
      "options": [
        "Rehost",
        "Replatform",
        "Retain",
        "Retire"
      ],
      "answer": 1,
      "explanation": "Replatforming moves to a different platform (Oracle to PostgreSQL) while keeping the core application largely unchanged. Objective 2.1"
    },
    {
      "q": "A company's migration dependency mapping reveals that Application A depends on Application B's API. What must be considered during migration?",
      "options": [
        "Migrate both independently at different times",
        "Ensure Application B is accessible during and after A's migration",
        "Only migrate Application A",
        "Remove the dependency first"
      ],
      "answer": 1,
      "explanation": "Dependency mapping ensures dependent applications remain accessible during migration to avoid service disruptions. Objective 2.1"
    },
    {
      "q": "A company establishes a VPN tunnel to the cloud but needs higher bandwidth than the VPN can provide for production traffic. What solution provides more bandwidth with a private connection?",
      "options": [
        "Add another VPN tunnel",
        "Implement Direct Connect or ExpressRoute",
        "Use a CDN",
        "Increase instance sizes"
      ],
      "answer": 1,
      "explanation": "Direct Connect and ExpressRoute provide dedicated high-bandwidth private connections exceeding VPN capabilities. Objective 2.2"
    },
    {
      "q": "A network engineer needs to allow HTTPS traffic from the internet to a web server but block SSH access from outside the VPC. Which firewall rule set achieves this?",
      "options": [
        "Allow all inbound traffic",
        "Allow inbound TCP 443 from 0.0.0.0/0, allow TCP 22 from VPC CIDR only",
        "Block all inbound and outbound",
        "Allow inbound TCP 22 from 0.0.0.0/0"
      ],
      "answer": 1,
      "explanation": "Allowing HTTPS from anywhere and SSH only from the VPC CIDR restricts management access while enabling web traffic. Objective 2.2"
    },
    {
      "q": "After configuring VPC peering between two VPCs, resources still cannot communicate. What is a common missing step?",
      "options": [
        "Enable internet gateway",
        "Add route table entries pointing to the peering connection",
        "Create a VPN",
        "Restart all instances"
      ],
      "answer": 1,
      "explanation": "VPC peering requires route table entries in both VPCs directing traffic to the peering connection for communication. Objective 2.2"
    },
    {
      "q": "A company uses Route 53 weighted routing to send 90% of traffic to the old on-premises servers and 10% to new cloud servers during migration. What is this DNS approach called?",
      "options": [
        "Failover routing",
        "Weighted DNS routing for gradual traffic shifting",
        "Round-robin DNS",
        "Geolocation routing"
      ],
      "answer": 1,
      "explanation": "Weighted DNS routing distributes traffic by percentage, enabling gradual migration by shifting traffic incrementally. Objective 2.2"
    },
    {
      "q": "A company deploys GPU-accelerated instances for machine learning training. The training runs for 8 hours daily. Which pricing model is most cost-effective?",
      "options": [
        "On-demand instances running 24/7",
        "Spot/preemptible instances with checkpointing",
        "3-year reserved instances",
        "Dedicated hosts"
      ],
      "answer": 1,
      "explanation": "Spot instances with checkpointing provide significant discounts for interruptible workloads like batch ML training. Objective 2.3"
    },
    {
      "q": "A company deploys Docker containers to a Kubernetes cluster. How do containers communicate with each other within the same pod?",
      "options": [
        "Through a load balancer",
        "Via localhost since they share the same network namespace",
        "Through a VPN tunnel",
        "Using external DNS"
      ],
      "answer": 1,
      "explanation": "Containers in the same Kubernetes pod share a network namespace and communicate via localhost. Objective 2.3"
    },
    {
      "q": "An auto-scaling group has a minimum of 2, desired of 4, and maximum of 8 instances. Currently running 4. CPU drops to 10%. What will auto-scaling do?",
      "options": [
        "Scale to 0 instances",
        "Scale down toward the minimum of 2 instances",
        "Keep 4 instances running",
        "Scale to 8 instances"
      ],
      "answer": 1,
      "explanation": "With very low CPU, auto-scaling will scale in (reduce) instances toward the minimum count of 2 to save costs. Objective 2.3"
    },
    {
      "q": "A company needs to run a stateful legacy application that requires a fixed IP address and specific hostname. Which compute deployment is most appropriate?",
      "options": [
        "Serverless function",
        "Dedicated VM with static IP and DNS entry",
        "Container on shared Kubernetes cluster",
        "Lambda function"
      ],
      "answer": 1,
      "explanation": "A dedicated VM with static IP and DNS entry satisfies requirements for fixed addressing and hostnames for stateful apps. Objective 2.3"
    },
    {
      "q": "A company wants to deploy a new version of their container image. The Kubernetes Deployment is set to use the 'latest' tag. Why is this problematic?",
      "options": [
        "Latest tag always pulls the newest image",
        "The 'latest' tag is ambiguous and may not trigger updates or may cause unexpected versions",
        "Kubernetes doesn't support container tags",
        "It makes the deployment faster"
      ],
      "answer": 1,
      "explanation": "The 'latest' tag is ambiguous; Kubernetes may use cached images and it makes rollbacks unreliable. Use specific version tags. Objective 2.3"
    },
    {
      "q": "A storage administrator needs to configure storage for a database that requires consistent sub-millisecond latency. Which storage type and tier should they choose?",
      "options": [
        "Object storage standard tier",
        "Provisioned IOPS SSD block storage",
        "Archive tier storage",
        "Network file share"
      ],
      "answer": 1,
      "explanation": "Provisioned IOPS SSD delivers consistent sub-millisecond latency required for demanding database workloads. Objective 2.4"
    },
    {
      "q": "A company's storage lifecycle policy accidentally moved active production data to archive tier. Users experience 12-hour retrieval delays. What should be done?",
      "options": [
        "Wait for users to stop complaining",
        "Restore data to a standard tier and fix the lifecycle policy rules",
        "Delete the archived data",
        "Tell users to be patient"
      ],
      "answer": 1,
      "explanation": "Incorrect lifecycle policies should be corrected and affected data restored to appropriate tiers for access patterns. Objective 2.4"
    },
    {
      "q": "A company needs to create an identical copy of a production database for testing purposes without impacting production. Which storage operation should they use?",
      "options": [
        "Live database cloning during peak hours",
        "Create a snapshot and restore it to a new test database",
        "Copy the database files manually",
        "Point test application to production database"
      ],
      "answer": 1,
      "explanation": "Snapshots create point-in-time copies that can be restored as separate databases for testing without impacting production. Objective 2.4"
    },
    {
      "q": "Object storage versioning is enabled on a bucket. A developer uploads a file with the same key three times. How many versions exist?",
      "options": [
        "1 (only the latest)",
        "2 (first and last)",
        "3 (all versions are retained)",
        "0 (file is overwritten)"
      ],
      "answer": 2,
      "explanation": "With versioning enabled, each upload creates a new version, so all three versions are retained and retrievable. Objective 2.4"
    },
    {
      "q": "A company's Terraform configuration creates a VPC, 3 subnets, and 2 EC2 instances. An engineer runs 'terraform destroy'. What happens?",
      "options": [
        "Only EC2 instances are deleted",
        "All resources defined in the Terraform config are destroyed",
        "Nothing happens without confirmation",
        "Only the VPC is deleted"
      ],
      "answer": 1,
      "explanation": "Terraform destroy removes all resources managed by the configuration, including VPC, subnets, and instances. Objective 2.5"
    },
    {
      "q": "A company uses a GitOps workflow for deployment. What does this mean?",
      "options": [
        "Git is used only for code storage",
        "Git repository is the single source of truth for infrastructure and deployments",
        "Only Git commands are used for operations",
        "GitHub Actions is required"
      ],
      "answer": 1,
      "explanation": "GitOps uses Git as the single source of truth where changes to Git trigger automated infrastructure and application deployments. Objective 2.5"
    },
    {
      "q": "A CloudFormation stack update fails midway through. What is the default behavior?",
      "options": [
        "All resources are deleted",
        "The stack rolls back to the previous known good state",
        "The partially updated stack remains as-is",
        "AWS support is contacted automatically"
      ],
      "answer": 1,
      "explanation": "CloudFormation automatically rolls back failed stack updates to the last known good state to maintain consistency. Objective 2.5"
    },
    {
      "q": "A CI/CD pipeline builds a Docker image and needs to store it for deployment to Kubernetes. Where should the image be stored?",
      "options": [
        "Local disk of the build server",
        "A container registry (e.g., ECR, Docker Hub)",
        "Object storage bucket",
        "Git repository"
      ],
      "answer": 1,
      "explanation": "Container registries store and distribute Docker images, providing versioning and access control for deployment. Objective 2.5"
    },
    {
      "q": "A development team wants to ensure their application works correctly before each deployment by running automated tests. At which CI/CD stage should unit tests run?",
      "options": [
        "After production deployment",
        "During the build stage, before any deployment",
        "Only in the staging environment",
        "During manual testing"
      ],
      "answer": 1,
      "explanation": "Unit tests should run early in the pipeline during the build stage to catch issues before any deployment occurs. Objective 2.5"
    },
    {
      "q": "A company uses immutable infrastructure. What does this principle mean for server updates?",
      "options": [
        "Servers are patched in place",
        "Servers are never modified after creation; updates require replacement with new instances",
        "Servers cannot be accessed by anyone",
        "Infrastructure never changes"
      ],
      "answer": 1,
      "explanation": "Immutable infrastructure replaces servers entirely instead of modifying them, ensuring consistency and repeatability. Objective 2.5"
    },
    {
      "q": "A team needs to deploy the same application to AWS, Azure, and GCP. Which IaC tool provides multi-cloud support?",
      "options": [
        "AWS CloudFormation",
        "Azure ARM Templates",
        "Terraform",
        "Google Cloud Deployment Manager"
      ],
      "answer": 2,
      "explanation": "Terraform supports multiple cloud providers through its provider ecosystem, enabling multi-cloud infrastructure management. Objective 2.5"
    },
    {
      "q": "A Kubernetes service of type ClusterIP is created. From where can this service be accessed?",
      "options": [
        "From the internet directly",
        "Only from within the Kubernetes cluster",
        "From any VPC in the account",
        "From on-premises networks only"
      ],
      "answer": 1,
      "explanation": "ClusterIP services are only accessible within the Kubernetes cluster, providing internal service-to-service communication. Objective 2.3"
    },
    {
      "q": "A company migrating to the cloud discovers their legacy app uses hardcoded IP addresses for database connections. What must be changed for cloud deployment?",
      "options": [
        "Nothing, IPs remain the same in cloud",
        "Replace hardcoded IPs with DNS names or service discovery",
        "Use the same IP addresses in the cloud",
        "Remove database connectivity"
      ],
      "answer": 1,
      "explanation": "Cloud environments use dynamic IPs; replacing hardcoded IPs with DNS names enables flexible connectivity after migration. Objective 2.1"
    },
    {
      "q": "A company's deployment pipeline runs integration tests in a staging environment that mirrors production. What is the purpose of this staging environment?",
      "options": [
        "To serve end users during outages",
        "To validate changes in a production-like environment before actual deployment",
        "To store deployment artifacts",
        "To run development workloads"
      ],
      "answer": 1,
      "explanation": "Staging environments mirror production to catch issues before deployment, reducing the risk of production failures. Objective 2.5"
    },
    {
      "q": "During a Kubernetes deployment, a new pod continuously crashes with CrashLoopBackOff status. What does this indicate?",
      "options": [
        "The pod is scaling normally",
        "The container application is failing repeatedly and Kubernetes keeps restarting it",
        "The node is out of memory",
        "The deployment is successful"
      ],
      "answer": 1,
      "explanation": "CrashLoopBackOff indicates the container is crashing repeatedly; Kubernetes restarts it with increasing backoff delays. Objective 2.3"
    },
    {
      "q": "A company uses Ansible to configure servers. Ansible playbooks are idempotent. What does idempotent mean in this context?",
      "options": [
        "Playbooks can only run once",
        "Running the same playbook multiple times produces the same result without unintended changes",
        "Playbooks execute faster each time",
        "Changes cannot be reverted"
      ],
      "answer": 1,
      "explanation": "Idempotent means running the same configuration multiple times results in the same state without duplicate actions. Objective 2.5"
    },
    {
      "q": "A company needs to expose a Kubernetes application to the internet. Which Kubernetes resource type should they use?",
      "options": [
        "ClusterIP Service",
        "NodePort or LoadBalancer Service",
        "ConfigMap",
        "PersistentVolume"
      ],
      "answer": 1,
      "explanation": "NodePort and LoadBalancer service types expose applications externally, with LoadBalancer integrating with cloud load balancers. Objective 2.3"
    },
    {
      "q": "A storage administrator provisions 1TB of SSD block storage but the application only uses 200GB. The company is billed for the full 1TB. What should they do?",
      "options": [
        "Accept the cost as unavoidable",
        "Resize the volume to match actual usage or use elastic volumes",
        "Switch to object storage",
        "Add more data to fill the volume"
      ],
      "answer": 1,
      "explanation": "Right-sizing storage volumes to actual usage eliminates waste; elastic volumes can automatically adjust size. Objective 2.4"
    },
    {
      "q": "During a canary deployment, 2% of users report errors on the new version while the remaining 98% on the old version work fine. What should the team do?",
      "options": [
        "Continue rolling out to 100%",
        "Roll back the canary and investigate the errors before proceeding",
        "Increase canary to 50% for more data",
        "Ignore the errors since they affect few users"
      ],
      "answer": 1,
      "explanation": "Canary errors indicate issues; the team should roll back, investigate, and fix before proceeding with the rollout. Objective 2.5"
    },
    {
      "q": "A company wants to test infrastructure changes in a temporary environment before applying them to production. Which Terraform command creates a preview without making changes?",
      "options": [
        "terraform apply",
        "terraform plan",
        "terraform destroy",
        "terraform init"
      ],
      "answer": 1,
      "explanation": "Terraform plan shows what changes would be made without actually applying them, enabling review before execution. Objective 2.5"
    },
    {
      "q": "A company migrating storage discovers they have 500TB of data in NFS file shares. The cloud equivalent should support the same NFS protocol. Which cloud storage should they use?",
      "options": [
        "Object storage",
        "Block storage volumes",
        "Managed NFS file storage service",
        "Archive storage"
      ],
      "answer": 2,
      "explanation": "Managed NFS file storage services (like EFS, Azure Files) provide NFS protocol compatibility for migrating file shares. Objective 2.4"
    },
    {
      "q": "A deployment to production causes increased error rates. The team has deployment metrics showing the exact time of deployment. Which deployment practice would have caught this earlier?",
      "options": [
        "Deploy directly to all servers simultaneously",
        "Canary deployment with automated health monitoring",
        "Manual deployment without monitoring",
        "Weekend-only deployments"
      ],
      "answer": 1,
      "explanation": "Canary deployments with health monitoring detect issues with a small traffic percentage before full rollout. Objective 2.5"
    },
    {
      "q": "A company runs VM-based workloads and wants to containerize them. What is the first step in this modernization process?",
      "options": [
        "Deploy directly to Kubernetes",
        "Analyze the application to create Dockerfiles and container images",
        "Delete the existing VMs",
        "Purchase new hardware"
      ],
      "answer": 1,
      "explanation": "Containerization starts with analyzing the application structure and creating container images via Dockerfiles. Objective 2.3"
    },
    {
      "q": "A Kubernetes Horizontal Pod Autoscaler is configured to scale based on CPU utilization target of 50%. Current average is 80% with 3 pods. What will happen?",
      "options": [
        "Pods will be removed",
        "More pods will be added to bring average CPU closer to 50%",
        "Nothing changes",
        "The existing pods will get more CPU"
      ],
      "answer": 1,
      "explanation": "The HPA adds pods to distribute load, bringing the average CPU utilization down toward the 50% target. Objective 2.3"
    },
    {
      "q": "A block storage snapshot takes 30 minutes to create. During this time, can the production VM continue using the volume?",
      "options": [
        "No, the VM must be stopped",
        "Yes, snapshots are typically created asynchronously without stopping the VM",
        "Only read operations are allowed",
        "The VM automatically pauses"
      ],
      "answer": 1,
      "explanation": "Block storage snapshots are typically created asynchronously, allowing the VM to continue normal operations. Objective 2.4"
    },
    {
      "q": "A company's network team needs to verify that a VPN tunnel between on-premises and cloud is working correctly. Which troubleshooting step should they perform first?",
      "options": [
        "Delete and recreate the VPN",
        "Check VPN tunnel status, IKE phase 1/2 status, and test connectivity with ping",
        "Replace the VPN with Direct Connect",
        "Restart all on-premises servers"
      ],
      "answer": 1,
      "explanation": "Verifying VPN tunnel status and IKE negotiation phases helps identify specific connectivity issues. Objective 2.2"
    },
    {
      "q": "A company needs to deploy a new version of a Lambda function. If the new version has errors, they want automatic rollback. Which deployment feature supports this?",
      "options": [
        "Manual code editing",
        "Traffic shifting with automatic rollback on error metrics",
        "Deleting and recreating the function",
        "Version pinning without monitoring"
      ],
      "answer": 1,
      "explanation": "Traffic shifting with CloudWatch alarms enables automatic rollback if error metrics exceed thresholds during deployment. Objective 2.5"
    },
    {
      "q": "A company uses blue-green deployment for their database-backed application. What additional consideration is needed compared to stateless applications?",
      "options": [
        "No additional considerations needed",
        "Database schema compatibility between blue and green versions must be maintained",
        "Databases don't work with blue-green",
        "Always use separate databases for each environment"
      ],
      "answer": 1,
      "explanation": "Database schema changes must be backward-compatible to support both blue and green application versions simultaneously. Objective 2.5"
    },
    {
      "q": "A company runs a batch workload that can tolerate interruptions. Cloud provider offers 70% discount for interruptible compute instances. Which instance type should they use?",
      "options": [
        "On-demand instances",
        "Reserved instances",
        "Spot/Preemptible instances",
        "Dedicated hosts"
      ],
      "answer": 2,
      "explanation": "Spot/preemptible instances offer deep discounts for fault-tolerant workloads that can handle interruptions. Objective 2.3"
    },
    {
      "q": "A company needs to migrate their on-premises Active Directory to work with cloud resources. Which solution provides hybrid identity management?",
      "options": [
        "Create new cloud-only user accounts",
        "Extend AD to cloud with hybrid identity federation",
        "Eliminate all on-premises accounts",
        "Use local accounts on each cloud VM"
      ],
      "answer": 1,
      "explanation": "Hybrid identity federation extends on-premises AD to cloud, enabling single sign-on across both environments. Objective 2.1"
    },
    {
      "q": "A storage volume is configured with encryption at rest using a customer-managed key. What does this protect against?",
      "options": [
        "Network eavesdropping",
        "Unauthorized access to data on physical storage media",
        "DDoS attacks",
        "SQL injection"
      ],
      "answer": 1,
      "explanation": "Encryption at rest protects data on physical media from unauthorized access if storage hardware is compromised. Objective 2.4"
    },
    {
      "q": "A company's application uses environment variables for database connection strings that differ between dev, staging, and production. Which Kubernetes resource manages this?",
      "options": [
        "Deployment",
        "ConfigMap",
        "PersistentVolume",
        "Ingress"
      ],
      "answer": 1,
      "explanation": "ConfigMaps store configuration data as key-value pairs that can be injected as environment variables into pods. Objective 2.3"
    },
    {
      "q": "A Terraform module provisions a web application's infrastructure. A new team wants to reuse it for a different application. What Terraform feature supports this?",
      "options": [
        "Copy and paste the code",
        "Use Terraform modules with input variables",
        "Write the same code again from scratch",
        "Export the state file"
      ],
      "answer": 1,
      "explanation": "Terraform modules with input variables enable reusable infrastructure definitions that can be parameterized for different use cases. Objective 2.5"
    },
    {
      "q": "A company performs storage migration and discovers their on-premises storage uses 4KB block size while cloud storage uses 16KB. What potential issue should they be aware of?",
      "options": [
        "No impact on migration",
        "Block size mismatch may affect performance and storage efficiency for the application",
        "Migration is impossible",
        "Data will be corrupted"
      ],
      "answer": 1,
      "explanation": "Block size differences between source and target storage can impact application I/O performance and storage efficiency. Objective 2.4"
    },
    {
      "q": "During migration testing, a company runs the same transactions against both on-premises and cloud environments and compares results. What is this testing approach called?",
      "options": [
        "Load testing",
        "Parallel run testing",
        "Unit testing",
        "Penetration testing"
      ],
      "answer": 1,
      "explanation": "Parallel run testing compares outputs from old and new environments running identical workloads to validate migration correctness. Objective 2.1"
    },
    {
      "q": "A company uses Kubernetes namespaces to separate dev, staging, and prod environments on the same cluster. What is the primary benefit?",
      "options": [
        "Performance isolation",
        "Logical separation with independent resource quotas and access controls",
        "Network isolation by default",
        "Separate physical servers"
      ],
      "answer": 1,
      "explanation": "Namespaces provide logical separation with independent RBAC, resource quotas, and naming scopes within a shared cluster. Objective 2.3"
    },
    {
      "q": "An in-place deployment updates the application on existing servers directly. What is the main risk of this approach compared to blue-green?",
      "options": [
        "It's more expensive",
        "There is no easy rollback if the deployment fails",
        "It takes longer to deploy",
        "It requires more servers"
      ],
      "answer": 1,
      "explanation": "In-place deployments modify existing servers, making rollback difficult since there's no parallel old environment to switch back to. Objective 2.5"
    }
  ],
  "3. Security": [
    {
      "q": "A company stores customer data in the cloud. The security team wants to encrypt data at rest using keys they control and can rotate on their own schedule. Which approach should they use?",
      "options": [
        "Provider-managed default encryption",
        "Customer-managed keys (CMK) with a cloud KMS",
        "No encryption",
        "Application-level encoding only"
      ],
      "answer": 1,
      "explanation": "Customer-managed keys via cloud KMS provide full control over encryption keys including custom rotation schedules. Objective 3.1"
    },
    {
      "q": "A web application transmits credit card data between the browser and server. Which protocol ensures this data is encrypted in transit?",
      "options": [
        "HTTP",
        "FTP",
        "TLS/HTTPS",
        "SMTP"
      ],
      "answer": 2,
      "explanation": "TLS/HTTPS encrypts data in transit between client and server, protecting sensitive data like credit card numbers. Objective 3.1"
    },
    {
      "q": "A financial institution needs to store encryption keys in tamper-resistant hardware that meets FIPS 140-2 Level 3 compliance. Which solution provides this?",
      "options": [
        "Software-based key storage",
        "Hardware Security Module (HSM)",
        "Plain text file on a server",
        "Shared network drive"
      ],
      "answer": 1,
      "explanation": "HSMs provide tamper-resistant hardware-based key storage meeting FIPS 140-2 Level 3 for high-security requirements. Objective 3.1"
    },
    {
      "q": "A company's TLS certificate is expiring in 3 days. If not renewed, what will happen to users accessing the website?",
      "options": [
        "Nothing changes",
        "Browsers will show security warnings and may block access",
        "The server will crash",
        "Only mobile users are affected"
      ],
      "answer": 1,
      "explanation": "Expired TLS certificates trigger browser security warnings and may prevent users from accessing the site. Objective 3.1"
    },
    {
      "q": "An application encrypts data with AES-256 before storing it in a cloud database. Which encryption approach is this?",
      "options": [
        "Server-side encryption",
        "Client-side encryption",
        "Transport encryption",
        "Network encryption"
      ],
      "answer": 1,
      "explanation": "Client-side encryption encrypts data in the application before sending it to storage, providing end-to-end protection. Objective 3.1"
    },
    {
      "q": "A company's cloud KMS key policy allows a terminated employee's IAM user to decrypt production data. What should be done immediately?",
      "options": [
        "Nothing, the user is terminated",
        "Remove the IAM user's permissions from the KMS key policy",
        "Delete all encrypted data",
        "Rotate the KMS key only"
      ],
      "answer": 1,
      "explanation": "Terminated employee access must be revoked from key policies immediately to prevent unauthorized data access. Objective 3.1"
    },
    {
      "q": "A company wants to implement single sign-on so employees use one set of credentials for all cloud applications. Which technology enables this?",
      "options": [
        "Local user accounts per application",
        "SAML-based federation with an identity provider",
        "Shared passwords in a spreadsheet",
        "VPN access only"
      ],
      "answer": 1,
      "explanation": "SAML-based federation enables SSO by authenticating users through a central identity provider for all applications. Objective 3.2"
    },
    {
      "q": "A cloud administrator needs to grant a developer read-only access to production S3 buckets but full access to development buckets. Which access control model supports this?",
      "options": [
        "Give full admin access to everything",
        "Role-Based Access Control (RBAC) with environment-specific policies",
        "Share a single admin account",
        "Physical access to servers"
      ],
      "answer": 1,
      "explanation": "RBAC assigns permissions based on roles, enabling different access levels for different environments. Objective 3.2"
    },
    {
      "q": "A company requires that all API calls to their cloud infrastructure use multi-factor authentication. Which access control enhancement does this represent?",
      "options": [
        "Single-factor authentication",
        "Multi-factor authentication (MFA)",
        "Anonymous access",
        "API key only"
      ],
      "answer": 1,
      "explanation": "MFA requires two or more verification factors, adding a layer of security beyond just passwords for API access. Objective 3.2"
    },
    {
      "q": "An application running on an EC2 instance needs to access S3 buckets. Instead of using hardcoded access keys, what is the recommended approach?",
      "options": [
        "Embed access keys in source code",
        "Assign an IAM role to the EC2 instance",
        "Use the root account credentials",
        "Store keys in an environment variable file"
      ],
      "answer": 1,
      "explanation": "IAM roles provide temporary credentials to EC2 instances, eliminating the need for hardcoded access keys. Objective 3.2"
    },
    {
      "q": "A security audit reveals that 15 IAM users have full administrator access to the cloud account. Only 3 are actual administrators. What principle is being violated?",
      "options": [
        "Defense in depth",
        "Least privilege",
        "Separation of duties",
        "Data classification"
      ],
      "answer": 1,
      "explanation": "Least privilege requires granting only the minimum permissions needed; 12 users have excessive administrator access. Objective 3.2"
    },
    {
      "q": "A company uses OAuth 2.0 for third-party application access to their API. What does OAuth 2.0 primarily provide?",
      "options": [
        "User authentication",
        "Delegated authorization without sharing credentials",
        "Data encryption",
        "Network segmentation"
      ],
      "answer": 1,
      "explanation": "OAuth 2.0 provides delegated authorization, allowing third-party apps to access resources without seeing user credentials. Objective 3.2"
    },
    {
      "q": "A CI/CD pipeline needs to access cloud resources during deployments. The pipeline runs on external infrastructure. What is the most secure way to provide credentials?",
      "options": [
        "Hardcode credentials in pipeline scripts",
        "Use OIDC federation with short-lived tokens",
        "Store credentials in a public Git repository",
        "Use a shared service account password"
      ],
      "answer": 1,
      "explanation": "OIDC federation provides short-lived tokens for CI/CD pipelines without storing long-lived credentials. Objective 3.2"
    },
    {
      "q": "A cloud web application is being attacked with SQL injection and cross-site scripting. Which security service should be deployed to protect it?",
      "options": [
        "Network firewall",
        "Web Application Firewall (WAF)",
        "Anti-virus software",
        "VPN gateway"
      ],
      "answer": 1,
      "explanation": "WAF inspects HTTP traffic and blocks common web attacks like SQL injection and XSS at the application layer. Objective 3.3"
    },
    {
      "q": "A company wants to limit network traffic between microservices so that only authorized service-to-service communication is allowed. Which network security approach enables this?",
      "options": [
        "Open all ports between services",
        "Microsegmentation with service-level firewall rules",
        "Single flat network for all services",
        "Internet-facing load balancer"
      ],
      "answer": 1,
      "explanation": "Microsegmentation creates fine-grained security policies between individual services, limiting lateral movement. Objective 3.3"
    },
    {
      "q": "A company adopts zero trust security. Which principle BEST describes this model?",
      "options": [
        "Trust everything inside the network perimeter",
        "Never trust, always verify every request regardless of network location",
        "Only external traffic is verified",
        "Trust is based on IP address ranges"
      ],
      "answer": 1,
      "explanation": "Zero trust verifies every request regardless of source, assuming no implicit trust based on network location. Objective 3.3"
    },
    {
      "q": "A cloud IDS detects suspicious outbound traffic from a web server to an unknown IP address at 3 AM. What type of threat might this indicate?",
      "options": [
        "Normal backup operation",
        "Potential data exfiltration or command-and-control communication",
        "Auto-scaling event",
        "DNS resolution"
      ],
      "answer": 1,
      "explanation": "Unusual outbound traffic to unknown IPs at off-hours may indicate compromised servers communicating with attackers. Objective 3.3"
    },
    {
      "q": "A company's cloud-hosted e-commerce site is experiencing a volumetric DDoS attack with 100Gbps of traffic. Which mitigation service should they activate?",
      "options": [
        "Regular firewall rules",
        "Cloud-native DDoS protection service (e.g., AWS Shield, Azure DDoS Protection)",
        "Increase instance size",
        "Block all traffic"
      ],
      "answer": 1,
      "explanation": "Cloud DDoS protection services absorb and mitigate volumetric attacks using the provider's global network capacity. Objective 3.3"
    },
    {
      "q": "Network ACLs deny all traffic by default in a cloud VPC. An administrator wants to allow only HTTPS inbound and SSH from a specific IP. Which ACL configuration is correct?",
      "options": [
        "Allow all inbound traffic",
        "Allow inbound TCP 443 from 0.0.0.0/0 and TCP 22 from the specific IP CIDR",
        "Allow all outbound and inbound",
        "Block only ICMP"
      ],
      "answer": 1,
      "explanation": "Network ACLs should allow only necessary protocols and restrict management access (SSH) to specific trusted IPs. Objective 3.3"
    },
    {
      "q": "A company processes credit card payments in the cloud. Which compliance standard must they adhere to for cardholder data protection?",
      "options": [
        "HIPAA",
        "PCI-DSS",
        "FERPA",
        "SOX"
      ],
      "answer": 1,
      "explanation": "PCI-DSS is the compliance standard for organizations processing credit card payments, protecting cardholder data. Objective 3.4"
    },
    {
      "q": "A healthcare application stores patient records in the cloud. Which US regulation governs the protection of this health information?",
      "options": [
        "PCI-DSS",
        "GDPR",
        "HIPAA",
        "SOX"
      ],
      "answer": 2,
      "explanation": "HIPAA regulates the protection of patient health information (PHI) in the United States. Objective 3.4"
    },
    {
      "q": "A European customer requests that all their personal data be deleted from a cloud application. Which regulation gives them this right?",
      "options": [
        "HIPAA",
        "PCI-DSS",
        "GDPR (right to erasure)",
        "SOC 2"
      ],
      "answer": 2,
      "explanation": "GDPR's right to erasure (right to be forgotten) allows EU residents to request deletion of their personal data. Objective 3.4"
    },
    {
      "q": "A company classifies data into Public, Internal, Confidential, and Restricted categories. An employee emails a Restricted document to an external recipient. Which security control could have prevented this?",
      "options": [
        "Anti-virus",
        "Data Loss Prevention (DLP) policy",
        "Firewall rule",
        "Load balancer"
      ],
      "answer": 1,
      "explanation": "DLP policies detect and prevent unauthorized transmission of classified data like Restricted documents via email. Objective 3.4"
    },
    {
      "q": "A cloud provider undergoes a SOC 2 Type II audit. What does this audit verify?",
      "options": [
        "Physical building security only",
        "Effectiveness of security controls over a period of time",
        "Code quality of applications",
        "Network bandwidth capacity"
      ],
      "answer": 1,
      "explanation": "SOC 2 Type II audits verify that security controls are designed effectively and operated correctly over a sustained period. Objective 3.4"
    },
    {
      "q": "A multinational company stores EU customer data in a US-based cloud region. Which GDPR requirement does this potentially violate?",
      "options": [
        "Right to access",
        "Data residency and cross-border transfer restrictions",
        "Breach notification timeline",
        "Cookie consent"
      ],
      "answer": 1,
      "explanation": "GDPR restricts transfer of EU personal data to countries without adequate data protection, affecting data residency decisions. Objective 3.4"
    },
    {
      "q": "A security team runs weekly automated vulnerability scans on all cloud instances. What is the primary purpose of these scans?",
      "options": [
        "To improve application performance",
        "To identify known security weaknesses before attackers exploit them",
        "To optimize cloud costs",
        "To monitor network bandwidth"
      ],
      "answer": 1,
      "explanation": "Vulnerability scans proactively identify security weaknesses in systems before they can be exploited by attackers. Objective 3.5"
    },
    {
      "q": "A company hires an external firm to attempt to breach their cloud environment using real attack techniques. What is this engagement called?",
      "options": [
        "Vulnerability scan",
        "Penetration test",
        "Code review",
        "Risk assessment"
      ],
      "answer": 1,
      "explanation": "Penetration testing simulates real attacks to identify exploitable vulnerabilities that automated scans might miss. Objective 3.5"
    },
    {
      "q": "A SIEM system correlates logs from multiple cloud services and generates an alert about a possible brute-force attack. What triggered this alert?",
      "options": [
        "A single failed login",
        "Pattern of many failed authentication attempts from the same source in a short period",
        "A successful deployment",
        "A routine backup completion"
      ],
      "answer": 1,
      "explanation": "SIEM systems detect patterns like rapid repeated failed logins that indicate brute-force attacks through log correlation. Objective 3.5"
    },
    {
      "q": "After detecting a security breach, the incident response team's first step should be to:",
      "options": [
        "Delete all affected systems",
        "Contain the breach to prevent further damage",
        "Notify the press immediately",
        "Ignore it and wait for more evidence"
      ],
      "answer": 1,
      "explanation": "Containment is the first priority in incident response to limit the scope and impact of the breach. Objective 3.5"
    },
    {
      "q": "A company needs to retain cloud audit logs for forensic analysis in case of future security incidents. What is the minimum recommended retention period?",
      "options": [
        "24 hours",
        "7 days",
        "At least 90 days to 1 year per compliance requirements",
        "Logs should not be retained"
      ],
      "answer": 2,
      "explanation": "Audit logs should be retained for at least 90 days to a year for forensic analysis and compliance requirements. Objective 3.5"
    },
    {
      "q": "A company discovers that a developer accidentally pushed AWS access keys to a public GitHub repository. What should be done first?",
      "options": [
        "Delete the GitHub repository",
        "Immediately rotate/revoke the exposed credentials",
        "Monitor for suspicious activity first",
        "Ignore it since the repo is small"
      ],
      "answer": 1,
      "explanation": "Exposed credentials must be immediately revoked and rotated to prevent unauthorized access before any further investigation. Objective 3.5"
    },
    {
      "q": "In the shared responsibility model for IaaS, who is responsible for patching the guest operating system?",
      "options": [
        "Cloud provider",
        "The customer",
        "Shared equally",
        "Neither"
      ],
      "answer": 1,
      "explanation": "In IaaS, the customer is responsible for OS patching, configuration, and application security. Objective 3.6"
    },
    {
      "q": "A company uses a SaaS email service. A phishing email bypasses the provider's spam filter and compromises an employee account. Who is responsible for the account compromise?",
      "options": [
        "Entirely the SaaS provider",
        "Shared: provider should filter spam, customer should train employees and enable MFA",
        "Entirely the customer",
        "The email sender"
      ],
      "answer": 1,
      "explanation": "Security is shared: the provider maintains spam filters, but customers must implement MFA and user security training. Objective 3.6"
    },
    {
      "q": "For a PaaS database service, which security responsibility falls on the cloud provider?",
      "options": [
        "Customer's SQL queries",
        "Patching the underlying database engine",
        "Data classification",
        "Application-level access controls"
      ],
      "answer": 1,
      "explanation": "In PaaS, the provider manages and patches the underlying database engine while customers handle data and access controls. Objective 3.6"
    },
    {
      "q": "A company discovers unencrypted data in an S3 bucket that should be encrypted. In the shared responsibility model, who is accountable?",
      "options": [
        "AWS, because they own S3",
        "The customer, because they must enable and configure encryption",
        "Both equally",
        "The S3 service automatically encrypts everything"
      ],
      "answer": 1,
      "explanation": "Customers are responsible for enabling and configuring encryption on their S3 buckets in the shared responsibility model. Objective 3.6"
    },
    {
      "q": "A company's service account has been assigned an IAM policy with 'Action: *' and 'Resource: *'. What security risk does this create?",
      "options": [
        "No risk, this is standard",
        "The account has unrestricted access to all cloud resources, violating least privilege",
        "It only affects billing",
        "The account is read-only"
      ],
      "answer": 1,
      "explanation": "Wildcard permissions grant full access to everything, creating severe security risk if the service account is compromised. Objective 3.2"
    },
    {
      "q": "A company configures mutual TLS (mTLS) for service-to-service communication. What does mTLS verify that standard TLS does not?",
      "options": [
        "Only the server's identity",
        "Both the client's and server's identity through certificate exchange",
        "Only the data encryption algorithm",
        "Only the network path"
      ],
      "answer": 1,
      "explanation": "mTLS verifies both client and server identities through mutual certificate exchange, unlike standard TLS which only verifies the server. Objective 3.1"
    },
    {
      "q": "A cloud security team implements attribute-based access control (ABAC) instead of RBAC. What advantage does ABAC provide?",
      "options": [
        "Simpler to manage with fewer policies",
        "Fine-grained access decisions based on multiple attributes like department, time, location",
        "No need for an identity provider",
        "It eliminates all security risks"
      ],
      "answer": 1,
      "explanation": "ABAC makes access decisions based on multiple attributes (user, resource, environment), enabling more granular control than role-based approaches. Objective 3.2"
    },
    {
      "q": "A security scan reveals a cloud VM has an open port 3389 (RDP) accessible from the internet. Why is this a critical security finding?",
      "options": [
        "Port 3389 is never used",
        "Exposed RDP enables remote desktop brute-force attacks from anywhere on the internet",
        "It only affects Linux servers",
        "RDP is always encrypted so it's safe"
      ],
      "answer": 1,
      "explanation": "Internet-exposed RDP is frequently targeted by brute-force attacks and is a common entry point for ransomware. Objective 3.3"
    },
    {
      "q": "A company implements data retention policies that automatically delete customer data after 2 years. Which compliance principle does this support?",
      "options": [
        "Data maximization",
        "Data minimization and purpose limitation",
        "Unlimited data collection",
        "Data hoarding"
      ],
      "answer": 1,
      "explanation": "Data minimization keeps data only as long as needed, aligning with GDPR and other privacy regulations' principles. Objective 3.4"
    },
    {
      "q": "An IPS (Intrusion Prevention System) differs from an IDS (Intrusion Detection System) in which key way?",
      "options": [
        "IPS only monitors, IDS blocks",
        "IPS actively blocks malicious traffic while IDS only alerts",
        "They are identical",
        "IDS is more advanced"
      ],
      "answer": 1,
      "explanation": "IPS actively blocks detected threats in real-time, while IDS only detects and alerts on suspicious activity. Objective 3.3"
    },
    {
      "q": "A security team needs to ensure that encryption keys are automatically rotated every 90 days. Which service feature enables this?",
      "options": [
        "Manual key replacement",
        "Automatic key rotation policy in the cloud KMS",
        "Disabling encryption",
        "Using the same key indefinitely"
      ],
      "answer": 1,
      "explanation": "Cloud KMS automatic key rotation policies rotate encryption keys on a schedule without manual intervention. Objective 3.1"
    },
    {
      "q": "A company's data classification policy marks salary information as 'Confidential'. An application displays salary data in log files stored in CloudWatch. What security issue exists?",
      "options": [
        "No issue, logs are internal",
        "Confidential data in logs may be accessible to unauthorized personnel with log access",
        "CloudWatch automatically redacts sensitive data",
        "Logs are encrypted so it's fine"
      ],
      "answer": 1,
      "explanation": "Logging confidential data like salaries exposes it to anyone with log access, violating data classification policies. Objective 3.4"
    },
    {
      "q": "A security tool detects that an IAM access key hasn't been used in 90 days. What action should be taken?",
      "options": [
        "Leave it active for future use",
        "Disable or delete the unused access key to reduce attack surface",
        "Share it with another team",
        "Extend its validity period"
      ],
      "answer": 1,
      "explanation": "Unused credentials should be disabled or deleted to minimize the attack surface and follow security best practices. Objective 3.2"
    },
    {
      "q": "A company wants to implement network security that inspects east-west traffic between cloud workloads, not just north-south traffic. What approach enables this?",
      "options": [
        "Perimeter firewall only",
        "Microsegmentation with distributed firewall rules between workloads",
        "Internet gateway configuration",
        "DNS filtering"
      ],
      "answer": 1,
      "explanation": "Microsegmentation inspects and controls lateral (east-west) traffic between workloads within the cloud environment. Objective 3.3"
    },
    {
      "q": "During a security incident, the forensics team needs to analyze a compromised cloud VM. What should they do first before investigation?",
      "options": [
        "Delete the VM to prevent further damage",
        "Create a snapshot/image of the VM for forensic preservation",
        "Reboot the VM to clear the malware",
        "Ignore the VM and focus on logs only"
      ],
      "answer": 1,
      "explanation": "Forensic preservation through snapshots captures the current state of evidence before any remediation changes are made. Objective 3.5"
    },
    {
      "q": "A company uses cloud-based certificate management that automatically issues and renews TLS certificates for their web applications. Which service category is this?",
      "options": [
        "Key Management Service",
        "Certificate Manager / PKI service",
        "Identity and Access Management",
        "DNS service"
      ],
      "answer": 1,
      "explanation": "Certificate Manager services automate TLS certificate issuance, renewal, and deployment for web applications. Objective 3.1"
    },
    {
      "q": "A cloud environment has a security group allowing all outbound traffic. Why might a security team want to restrict outbound rules?",
      "options": [
        "Outbound traffic has no security impact",
        "Restricting outbound limits data exfiltration and command-and-control communication",
        "It improves application performance",
        "Outbound rules are never needed"
      ],
      "answer": 1,
      "explanation": "Restricting outbound traffic prevents compromised instances from exfiltrating data or communicating with attackers. Objective 3.3"
    },
    {
      "q": "A company uses SAML federation between their corporate Active Directory and AWS. When an employee is terminated in AD, what happens to their AWS access?",
      "options": [
        "AWS access remains active indefinitely",
        "Access is revoked because SAML tokens require valid AD authentication",
        "They keep access until AWS credentials expire in a year",
        "Nothing happens to cloud access"
      ],
      "answer": 1,
      "explanation": "SAML federation requires valid identity provider authentication; disabling the AD account prevents new AWS session creation. Objective 3.2"
    },
    {
      "q": "A cloud security assessment reveals that the root/owner account of the cloud environment doesn't have MFA enabled. Why is this the highest priority finding?",
      "options": [
        "Root accounts have limited access",
        "The root account has unrestricted access; compromising it without MFA means total environment takeover",
        "MFA is optional for root accounts",
        "Root accounts are never targeted"
      ],
      "answer": 1,
      "explanation": "Root accounts have unrestricted access; without MFA, a compromised password leads to complete environment control. Objective 3.2"
    },
    {
      "q": "A company stores database backups in S3 and wants server-side encryption applied automatically to every uploaded object. Which S3 feature should they enable?",
      "options": [
        "Bucket policy",
        "Default encryption on the bucket",
        "Object lock",
        "Cross-region replication"
      ],
      "answer": 1,
      "explanation": "Default bucket encryption automatically applies server-side encryption to all new objects. Objective 3.1"
    },
    {
      "q": "A company needs to encrypt data in transit between two cloud VPCs in different regions. Which approach ensures traffic is encrypted?",
      "options": [
        "VPC peering alone",
        "VPN or TLS between the VPCs",
        "Internet gateway",
        "No encryption needed"
      ],
      "answer": 1,
      "explanation": "VPN or TLS encryption protects data in transit between VPCs across regions. Objective 3.1"
    },
    {
      "q": "A team hardcodes database passwords in config files stored in Git. What is the recommended alternative?",
      "options": [
        "Use longer passwords",
        "Store secrets in a secrets management service",
        "Encrypt the Git repo",
        "Remove authentication"
      ],
      "answer": 1,
      "explanation": "Secrets management services securely store and rotate credentials, eliminating hardcoded secrets. Objective 3.1"
    },
    {
      "q": "Regulations require S3 objects to be immutable for 7 years. Which feature enforces this?",
      "options": [
        "Bucket versioning",
        "S3 Object Lock compliance mode",
        "Lifecycle policy",
        "Cross-region replication"
      ],
      "answer": 1,
      "explanation": "Object Lock compliance mode makes objects immutable for a defined retention period. Objective 3.1"
    },
    {
      "q": "IAM policies allow access only from the corporate IP range during business hours. Which access control model is this?",
      "options": [
        "RBAC",
        "ABAC",
        "Mandatory Access Control",
        "Discretionary Access Control"
      ],
      "answer": 1,
      "explanation": "ABAC uses attributes like IP address and time for access decisions beyond simple role assignments. Objective 3.2"
    },
    {
      "q": "A contractor needs temporary S3 bucket access for 24 hours. What is the most secure approach?",
      "options": [
        "Create a permanent IAM user",
        "Generate temporary credentials with 24-hour expiry",
        "Share root account",
        "Make bucket public"
      ],
      "answer": 1,
      "explanation": "Temporary credentials provide time-limited access that automatically expires. Objective 3.2"
    },
    {
      "q": "What is the purpose of break-glass procedures for cloud administration?",
      "options": [
        "Regular daily access",
        "Emergency elevated access when normal methods are unavailable",
        "Automated scaling",
        "Standard deployment"
      ],
      "answer": 1,
      "explanation": "Break-glass provides emergency elevated access when normal auth systems are unavailable. Objective 3.2"
    },
    {
      "q": "An explicit Deny on s3:DeleteObject exists. A user also has Allow on s3:*. Can the user delete objects?",
      "options": [
        "Yes, Allow overrides Deny",
        "No, explicit Deny always overrides Allow",
        "Depends on policy order",
        "Policies cancel out"
      ],
      "answer": 1,
      "explanation": "Explicit Deny always takes precedence over Allow in IAM policy evaluation. Objective 3.2"
    },
    {
      "q": "Which service protects a web app from OWASP Top 10 vulnerabilities like SQL injection and XSS?",
      "options": [
        "Network firewall",
        "Web Application Firewall with OWASP rules",
        "Anti-malware",
        "DDoS protection only"
      ],
      "answer": 1,
      "explanation": "WAF with OWASP rule sets detects and blocks common web application vulnerabilities. Objective 3.3"
    },
    {
      "q": "All traffic in a cloud environment routes through a central inspection point, even internal traffic. Which architecture is this?",
      "options": [
        "Flat network",
        "Hub-and-spoke with centralized inspection",
        "Peer-to-peer",
        "Direct VPC peering"
      ],
      "answer": 1,
      "explanation": "Hub-and-spoke routes all traffic through a central hub for consistent security inspection. Objective 3.3"
    },
    {
      "q": "How does microsegmentation with zero trust prevent lateral movement after one microservice is compromised?",
      "options": [
        "It doesn't prevent lateral movement",
        "It requires authentication between every service regardless of network",
        "It uses a single flat network",
        "It opens all internal ports"
      ],
      "answer": 1,
      "explanation": "Microsegmentation with zero trust requires auth between every service, limiting lateral movement. Objective 3.3"
    },
    {
      "q": "A SYN flood attack targets cloud web servers. Which OSI layer does this attack operate at?",
      "options": [
        "Application layer (L7)",
        "Transport layer (L4)",
        "Physical layer (L1)",
        "Data link layer (L2)"
      ],
      "answer": 1,
      "explanation": "SYN flood is a Layer 4 attack exhausting resources with incomplete TCP handshakes. Objective 3.3"
    },
    {
      "q": "AWS GuardDuty analyzes logs and detects threats using ML. What category of security service is this?",
      "options": [
        "Firewall",
        "Managed threat detection",
        "Encryption service",
        "Certificate authority"
      ],
      "answer": 1,
      "explanation": "GuardDuty is managed threat detection using machine learning to identify suspicious activity. Objective 3.5"
    },
    {
      "q": "How can a company ensure cloud provider employees cannot decrypt their stored data?",
      "options": [
        "Provider-managed encryption",
        "Customer-managed keys",
        "No encryption",
        "Transit encryption only"
      ],
      "answer": 1,
      "explanation": "Customer-managed keys ensure only the customer can decrypt data. Objective 3.1"
    },
    {
      "q": "Regulations require data from each country to stay within its borders. Which concept applies?",
      "options": [
        "Data deduplication",
        "Data sovereignty",
        "Data compression",
        "Data caching"
      ],
      "answer": 1,
      "explanation": "Data sovereignty requires storing data within geographic boundaries mandated by regulations. Objective 3.4"
    },
    {
      "q": "A security audit finds no cloud API access logs are being collected. Why is this significant?",
      "options": [
        "API logs aren't important",
        "No audit trail for investigating unauthorized access",
        "Logs only matter on-premises",
        "Logging hurts performance"
      ],
      "answer": 1,
      "explanation": "API logs provide the essential audit trail for detecting unauthorized access and compliance. Objective 3.5"
    },
    {
      "q": "A GDPR subject access request is received. What must be provided within 30 days?",
      "options": [
        "Delete all data",
        "A copy of all personal data held about the individual",
        "Ignore the request",
        "Transfer to another provider"
      ],
      "answer": 1,
      "explanation": "GDPR requires providing a copy of personal data within one month of request. Objective 3.4"
    },
    {
      "q": "Under GDPR, within how many hours must a data breach be reported to the supervisory authority?",
      "options": [
        "24 hours",
        "48 hours",
        "72 hours",
        "7 days"
      ],
      "answer": 2,
      "explanation": "GDPR requires breach notification within 72 hours of becoming aware. Objective 3.4"
    },
    {
      "q": "A pen test shows a VM can retrieve IAM credentials via the instance metadata service. What attack technique is this?",
      "options": [
        "SQL injection",
        "SSRF to instance metadata",
        "DDoS",
        "Phishing"
      ],
      "answer": 1,
      "explanation": "SSRF targeting instance metadata retrieves IAM credentials, enabling privilege escalation. Objective 3.5"
    },
    {
      "q": "AWS Config rules that automatically flag non-compliant resources are which type of security control?",
      "options": [
        "Preventive",
        "Detective",
        "Physical",
        "Corrective"
      ],
      "answer": 1,
      "explanation": "Detective controls identify and flag non-compliance after the fact. Objective 3.5"
    },
    {
      "q": "A tagging policy requires owner, project, and classification on all resources. Which service enforces this?",
      "options": [
        "Cost management",
        "Config rules checking required tags",
        "Load balancer",
        "CDN"
      ],
      "answer": 1,
      "explanation": "Config rules detect and report resources missing required tags. Objective 3.4"
    },
    {
      "q": "An attacker creates a new IAM admin user with stolen credentials. Which service logs this activity?",
      "options": [
        "Application logs",
        "CloudTrail audit logs",
        "Web server logs",
        "Database logs"
      ],
      "answer": 1,
      "explanation": "CloudTrail logs all IAM and API activities for detecting unauthorized changes. Objective 3.5"
    },
    {
      "q": "How can a company prevent any S3 bucket in their account from being made public?",
      "options": [
        "Monitor and alert",
        "S3 Block Public Access at account level",
        "Delete public buckets",
        "Rely on developers"
      ],
      "answer": 1,
      "explanation": "Account-level Block Public Access prevents any bucket from being made public. Objective 3.4"
    },
    {
      "q": "In managed Kubernetes (EKS), who secures the worker nodes' OS in the shared responsibility model?",
      "options": [
        "AWS manages everything",
        "The customer",
        "No clear owner",
        "Kubernetes community"
      ],
      "answer": 1,
      "explanation": "Customers are responsible for worker node OS security; provider manages the control plane. Objective 3.6"
    },
    {
      "q": "For AWS Lambda, which security aspect is the customer's responsibility?",
      "options": [
        "Runtime OS patching",
        "Physical servers",
        "Function code and IAM permissions",
        "Hypervisor maintenance"
      ],
      "answer": 2,
      "explanation": "In serverless, customers own code, dependencies, and IAM permissions. Objective 3.6"
    },
    {
      "q": "A SaaS provider's infrastructure is breached due to unpatched servers. Who bears responsibility?",
      "options": [
        "Customer",
        "SaaS provider",
        "Both equally",
        "No one"
      ],
      "answer": 1,
      "explanation": "In SaaS, the provider is responsible for all infrastructure and application security. Objective 3.6"
    },
    {
      "q": "A company migrates to IaaS but forgets host-based firewalls on VMs. Whose responsibility?",
      "options": [
        "Cloud provider",
        "Customer",
        "Managed service team",
        "Not needed in cloud"
      ],
      "answer": 1,
      "explanation": "In IaaS, customers own OS-level security including host firewalls. Objective 3.6"
    },
    {
      "q": "What does just-in-time (JIT) access for cloud admin provide?",
      "options": [
        "Permanent admin access",
        "Temporary elevated access that auto-revokes",
        "Business hours only",
        "Read-only always"
      ],
      "answer": 1,
      "explanation": "JIT grants temporary elevated privileges only when needed, automatically revoking after expiry. Objective 3.2"
    },
    {
      "q": "Which tool category scans Terraform templates for security misconfigurations before deployment?",
      "options": [
        "Runtime monitoring",
        "Static IaC security scanning",
        "Load testing",
        "Performance monitoring"
      ],
      "answer": 1,
      "explanation": "Static IaC scanners analyze templates for misconfigurations before deployment. Objective 3.5"
    },
    {
      "q": "A compromised VM needs forensic analysis while stopping the attack. What is the correct approach?",
      "options": [
        "Delete VM",
        "Isolate via security groups then analyze",
        "Reboot VM",
        "Continue running normally"
      ],
      "answer": 1,
      "explanation": "Isolating preserves evidence while preventing further damage. Objective 3.5"
    },
    {
      "q": "How can encrypted EBS snapshots be shared with another AWS account?",
      "options": [
        "Default AWS keys",
        "Customer-managed KMS key with cross-account sharing",
        "Remove encryption",
        "S3-managed keys"
      ],
      "answer": 1,
      "explanation": "Customer-managed KMS keys can be shared via key policies for cross-account snapshot sharing. Objective 3.1"
    },
    {
      "q": "What security benefit does a service mesh like Istio provide for inter-service communication?",
      "options": [
        "Faster speeds",
        "Automatic mTLS encryption and mutual authentication",
        "Free SSL certs",
        "DNS management"
      ],
      "answer": 1,
      "explanation": "Service meshes implement mTLS for automatic encryption and mutual authentication between services. Objective 3.3"
    },
    {
      "q": "What is unique to cloud incident response versus traditional on-premises response?",
      "options": [
        "Contacting law enforcement",
        "API-based evidence collection with cloud-native tools",
        "Interviewing witnesses",
        "Physical evidence"
      ],
      "answer": 1,
      "explanation": "Cloud IR uses API-based evidence collection and provider-specific forensic tools. Objective 3.5"
    },
    {
      "q": "Why is S3 object lock important for CloudTrail audit logs?",
      "options": [
        "Read performance",
        "Prevents log tampering ensuring audit integrity",
        "Reduces costs",
        "Compresses files"
      ],
      "answer": 1,
      "explanation": "Object lock makes logs immutable, preventing attackers from deleting evidence. Objective 3.5"
    },
    {
      "q": "What does Cloud Security Posture Management (CSPM) continuously monitor?",
      "options": [
        "Code quality",
        "Cloud configs for security best practices and compliance",
        "Network bandwidth",
        "User browsing"
      ],
      "answer": 1,
      "explanation": "CSPM assesses cloud configurations against security best practices and compliance frameworks. Objective 3.5"
    },
    {
      "q": "How can a company minimize PCI-DSS compliance scope in their cloud environment?",
      "options": [
        "Store card data everywhere",
        "Isolate cardholder data in a dedicated segment",
        "Use shared environments",
        "Disable encryption"
      ],
      "answer": 1,
      "explanation": "Network segmentation isolates cardholder data, reducing PCI-DSS scope. Objective 3.4"
    },
    {
      "q": "A cloud Secrets Manager service primarily does what?",
      "options": [
        "Manages encryption at rest",
        "Stores, rotates, and retrieves application secrets",
        "Manages IAM roles",
        "DNS management"
      ],
      "answer": 1,
      "explanation": "Secrets Manager provides centralized secure storage with automatic rotation for credentials. Objective 3.1"
    },
    {
      "q": "How should malicious file uploads to a web application be prevented?",
      "options": [
        "Accept all files",
        "Validate types, scan for malware, isolate storage",
        "Only accept large files",
        "Disable uploads"
      ],
      "answer": 1,
      "explanation": "Validating, scanning, and isolating uploads prevents malicious content execution. Objective 3.3"
    },
    {
      "q": "A cloud database accepts connections from 0.0.0.0/0. Why is this critical?",
      "options": [
        "Normal configuration",
        "Entire internet can access it, enabling attacks",
        "Internal only",
        "Cloud firewalls protect it"
      ],
      "answer": 1,
      "explanation": "0.0.0.0/0 exposes the database to the internet; restrict to known sources. Objective 3.3"
    },
    {
      "q": "What do cloud workload protection platforms (CWPP) protect?",
      "options": [
        "Network devices only",
        "VMs, containers, serverless against runtime threats",
        "SaaS apps only",
        "Physical servers only"
      ],
      "answer": 1,
      "explanation": "CWPPs protect workloads at runtime across VMs, containers, and serverless. Objective 3.5"
    },
    {
      "q": "When is a GDPR Data Protection Impact Assessment required?",
      "options": [
        "For all processing",
        "When processing is likely to result in high risk to individuals",
        "Paper records only",
        "Never for cloud"
      ],
      "answer": 1,
      "explanation": "DPIAs are required for high-risk processing affecting individuals' rights. Objective 3.4"
    },
    {
      "q": "Security groups allowing only specific ports between designated microservices implement which concept?",
      "options": [
        "Open network",
        "Microsegmentation with least privilege",
        "Flat architecture",
        "Default allow"
      ],
      "answer": 1,
      "explanation": "Microsegmentation with least privilege allows only necessary traffic between specific services. Objective 3.3"
    },
    {
      "q": "IAM password policy requires 14 chars, special characters, and 90-day rotation. What principle does this enforce?",
      "options": [
        "Availability",
        "Strong authentication requirements",
        "Encryption",
        "Network segmentation"
      ],
      "answer": 1,
      "explanation": "Password complexity and rotation requirements strengthen authentication. Objective 3.2"
    },
    {
      "q": "Which service monitors all IAM policy changes across a multi-account cloud environment?",
      "options": [
        "CloudFront",
        "Centralized CloudTrail with AWS Organizations",
        "Route 53",
        "ElastiCache"
      ],
      "answer": 1,
      "explanation": "Centralized CloudTrail captures all IAM policy changes across accounts. Objective 3.5"
    },
    {
      "q": "An application encrypts only sensitive fields within a database record. What is this called?",
      "options": [
        "Full disk encryption",
        "Field-level encryption",
        "Network encryption",
        "Transport encryption"
      ],
      "answer": 1,
      "explanation": "Field-level encryption encrypts specific sensitive fields while leaving others readable. Objective 3.1"
    },
    {
      "q": "What should an annual cloud risk assessment include?",
      "options": [
        "Network diagrams only",
        "Threats, vulnerabilities, impact analysis, and mitigations",
        "Password checks only",
        "Billing review only"
      ],
      "answer": 1,
      "explanation": "Risk assessments evaluate threats, vulnerabilities, impact, and define mitigations. Objective 3.4"
    },
    {
      "q": "An employee enters cloud credentials on a phishing page. Which control would have prevented the compromise?",
      "options": [
        "Firewall rules",
        "MFA on the cloud account",
        "Encryption at rest",
        "VPN"
      ],
      "answer": 1,
      "explanation": "MFA prevents compromised credentials from being sufficient for account access. Objective 3.2"
    },
    {
      "q": "Cloud secrets rotation changes database passwords every 30 days. How should the application handle this?",
      "options": [
        "Hardcode passwords",
        "Retrieve current credentials from Secrets Manager at runtime",
        "Ask DBA monthly",
        "Store in env vars"
      ],
      "answer": 1,
      "explanation": "Applications should retrieve credentials at runtime to always use current rotated values. Objective 3.1"
    },
    {
      "q": "Web server logs contain session tokens in query parameters. What security issue exists?",
      "options": [
        "No issue",
        "Tokens in logs enable session hijacking by anyone with log access",
        "Logging is safe",
        "Parameters are encrypted"
      ],
      "answer": 1,
      "explanation": "Logging session tokens exposes them to anyone with log access, enabling hijacking. Objective 3.5"
    },
    {
      "q": "AWS WAF can block traffic from specific countries known for attacks. Which rule type enables geographic blocking?",
      "options": [
        "Rate-based rule",
        "Geographic match rule",
        "String match rule",
        "IP set rule"
      ],
      "answer": 1,
      "explanation": "Geographic match rules block or allow traffic based on the originating country. Objective 3.3"
    }
  ],
  "4. Operations": [
    {
      "q": "What is the primary purpose of log collection in cloud environments?",
      "options": [
        "Increase costs",
        "Centralize data for analysis, troubleshooting, and security monitoring",
        "Slow down systems",
        "No purpose"
      ],
      "answer": 1,
      "explanation": "Log collection aggregates logs from distributed resources into centralized storage, enabling comprehensive analysis, troubleshooting, security investigation, and compliance. Objective 3.1"
    },
    {
      "q": "Log aggregation combines logs from:",
      "options": [
        "Single source only",
        "Multiple sources into unified view",
        "No sources",
        "Only errors"
      ],
      "answer": 1,
      "explanation": "Log aggregation collects logs from applications, infrastructure, network devices, and security tools into single platform, enabling correlation and comprehensive monitoring. Objective 3.1"
    },
    {
      "q": "What should log retention policies consider?",
      "options": [
        "Only cost",
        "Compliance requirements, storage costs, and analysis needs",
        "Keep forever",
        "Delete immediately"
      ],
      "answer": 1,
      "explanation": "Retention policies balance compliance mandates (30-90 days minimum), security investigation needs, storage costs, and data lifecycle requirements. Objective 3.1"
    },
    {
      "q": "Application tracing helps identify:",
      "options": [
        "Only errors",
        "Request flow, latency bottlenecks, and dependencies across services",
        "Storage usage",
        "Costs only"
      ],
      "answer": 1,
      "explanation": "Distributed tracing tracks requests across microservices, identifying performance bottlenecks, latency issues, failed calls, and service dependencies. Objective 3.1"
    },
    {
      "q": "Which metric type measures system performance?",
      "options": [
        "Logs only",
        "CPU, memory, disk I/O, network throughput",
        "Only errors",
        "Cost only"
      ],
      "answer": 1,
      "explanation": "Performance metrics track CPU utilization, memory consumption, disk IOPS/throughput, network bandwidth, and latency for capacity planning and troubleshooting. Objective 3.1"
    },
    {
      "q": "Custom application metrics should track:",
      "options": [
        "Nothing",
        "Business KPIs, user actions, and application-specific performance",
        "Only infrastructure",
        "Random data"
      ],
      "answer": 1,
      "explanation": "Custom metrics measure business outcomes (transactions, conversions), user experience, application errors, and domain-specific performance indicators. Objective 3.1"
    },
    {
      "q": "Alerting should be configured to:",
      "options": [
        "Alert on everything",
        "Notify appropriate teams when thresholds exceed acceptable limits",
        "Never alert",
        "Only email"
      ],
      "answer": 1,
      "explanation": "Effective alerting notifies relevant teams when metrics exceed thresholds, with appropriate severity, context, and actionable information to reduce noise. Objective 3.1"
    },
    {
      "q": "Alert triage involves:",
      "options": [
        "Ignoring alerts",
        "Prioritizing and assessing severity, impact, and required response",
        "Deleting all alerts",
        "No action"
      ],
      "answer": 1,
      "explanation": "Triage evaluates alert severity, business impact, affected users, and urgency to prioritize response efforts and allocate appropriate resources. Objective 3.1"
    },
    {
      "q": "Alert response procedures should include:",
      "options": [
        "No procedures",
        "Escalation paths, runbooks, and clear responsibilities",
        "Random actions",
        "Ignore problems"
      ],
      "answer": 1,
      "explanation": "Response procedures define responsibilities, escalation paths, investigation steps, communication plans, and remediation actions for different alert types. Objective 3.1"
    },
    {
      "q": "What is the purpose of structured logging?",
      "options": [
        "Random text",
        "Consistent format enabling automated parsing and analysis",
        "Human-only readability",
        "No structure"
      ],
      "answer": 1,
      "explanation": "Structured logs (JSON, key-value pairs) enable automated parsing, filtering, aggregation, and correlation, improving analysis efficiency and accuracy. Objective 3.1"
    },
    {
      "q": "Log levels typically include:",
      "options": [
        "Only errors",
        "DEBUG, INFO, WARN, ERROR, FATAL",
        "Random levels",
        "No levels"
      ],
      "answer": 1,
      "explanation": "Log levels categorize message severity: DEBUG (detailed), INFO (general), WARN (potential issues), ERROR (failures), FATAL (critical), enabling filtering and prioritization. Objective 3.1"
    },
    {
      "q": "Centralized logging platforms provide:",
      "options": [
        "Local storage only",
        "Search, analysis, visualization, and alerting across all logs",
        "No benefits",
        "Only storage"
      ],
      "answer": 1,
      "explanation": "Platforms like ELK, Splunk, CloudWatch Logs enable searching, filtering, correlation, visualization, alerting, and long-term retention of distributed logs. Objective 3.1"
    },
    {
      "q": "What should be logged for security purposes?",
      "options": [
        "Nothing",
        "Authentication attempts, access to sensitive data, and administrative actions",
        "Only successes",
        "Random events"
      ],
      "answer": 1,
      "explanation": "Security logs capture authentication (success/failure), authorization decisions, data access, config changes, and admin actions for investigation and compliance. Objective 3.1"
    },
    {
      "q": "Application Performance Monitoring (APM) tracks:",
      "options": [
        "Only errors",
        "Response times, throughput, error rates, and resource usage",
        "Only logs",
        "Cost only"
      ],
      "answer": 1,
      "explanation": "APM monitors application performance metrics including response times, transaction volumes, error rates, database queries, and external service calls. Objective 3.1"
    },
    {
      "q": "Synthetic monitoring involves:",
      "options": [
        "Real user monitoring only",
        "Simulated transactions testing availability and performance",
        "No monitoring",
        "Manual testing only"
      ],
      "answer": 1,
      "explanation": "Synthetic monitoring executes scripted transactions from multiple locations, proactively testing availability, functionality, and performance before users are affected. Objective 3.1"
    },
    {
      "q": "Real User Monitoring (RUM) captures:",
      "options": [
        "Simulated data",
        "Actual end-user experience, page load times, and interactions",
        "Only server metrics",
        "No data"
      ],
      "answer": 1,
      "explanation": "RUM collects actual user experience data including page load times, JavaScript errors, user flows, and geographic performance variations. Objective 3.1"
    },
    {
      "q": "Metric aggregation enables:",
      "options": [
        "No benefits",
        "Summarizing data points into meaningful statistics over time",
        "Raw data only",
        "Data deletion"
      ],
      "answer": 1,
      "explanation": "Aggregation calculates averages, percentiles, min/max, and sums over time intervals, reducing storage while maintaining statistical significance. Objective 3.1"
    },
    {
      "q": "What is the difference between metrics and logs?",
      "options": [
        "They are identical",
        "Metrics are numeric time-series; logs are event records with context",
        "No difference",
        "Only format"
      ],
      "answer": 1,
      "explanation": "Metrics are numeric measurements over time (CPU 45%); logs are timestamped event records with detailed context (error messages, stack traces). Objective 3.1"
    },
    {
      "q": "Distributed tracing requires:",
      "options": [
        "Nothing",
        "Correlation IDs propagated across service calls",
        "Single service only",
        "No requirements"
      ],
      "answer": 1,
      "explanation": "Tracing uses correlation/trace IDs passed between services, tracking request flow through distributed systems and identifying latency sources. Objective 3.1"
    },
    {
      "q": "Alert fatigue occurs when:",
      "options": [
        "No alerts exist",
        "Excessive or poorly configured alerts cause teams to ignore them",
        "Alerts work perfectly",
        "Only one alert"
      ],
      "answer": 1,
      "explanation": "Alert fatigue results from too many alerts, false positives, or unclear severity, causing teams to ignore/dismiss important notifications. Objective 3.1"
    },
    {
      "q": "Reducing alert fatigue requires:",
      "options": [
        "More alerts",
        "Proper thresholds, aggregation, and actionable alerts only",
        "Disabling monitoring",
        "Random changes"
      ],
      "answer": 1,
      "explanation": "Reduce fatigue by setting appropriate thresholds, aggregating related alerts, eliminating false positives, and ensuring alerts are actionable. Objective 3.1"
    },
    {
      "q": "Log sampling involves:",
      "options": [
        "Logging everything",
        "Collecting subset of logs to reduce volume and cost",
        "No logging",
        "Deleting all logs"
      ],
      "answer": 1,
      "explanation": "Sampling collects representative log subset (e.g., 10% of requests) for high-volume applications, balancing cost and visibility for analysis. Objective 3.1"
    },
    {
      "q": "What are Service Level Indicators (SLIs)?",
      "options": [
        "Random metrics",
        "Quantitative measures of service level (latency, availability, error rate)",
        "Cost metrics only",
        "No indicators"
      ],
      "answer": 1,
      "explanation": "SLIs are specific metrics measuring service quality: request latency percentiles, availability percentage, error rate, throughput. Objective 3.1"
    },
    {
      "q": "Service Level Objectives (SLOs) define:",
      "options": [
        "No targets",
        "Target values for SLIs (e.g., 99.9% availability)",
        "Cost goals only",
        "Random numbers"
      ],
      "answer": 1,
      "explanation": "SLOs set target values for SLIs: 99.9% availability, p95 latency <200ms, error rate <0.1%, providing measurable service quality goals. Objective 3.1"
    },
    {
      "q": "Error budgets are:",
      "options": [
        "Unlimited errors",
        "Acceptable amount of downtime/errors before SLO violation",
        "Zero tolerance",
        "No concept"
      ],
      "answer": 1,
      "explanation": "Error budgets (100% - SLO) define acceptable failure: 99.9% SLO = 0.1% error budget, balancing innovation velocity with reliability. Objective 3.1"
    },
    {
      "q": "Dashboard design should prioritize:",
      "options": [
        "All possible metrics",
        "Most important metrics for specific audience and use case",
        "Random data",
        "Pretty colors only"
      ],
      "answer": 1,
      "explanation": "Effective dashboards display relevant metrics for specific roles (executives, operations, developers) with clear visualizations and actionable insights. Objective 3.1"
    },
    {
      "q": "Anomaly detection identifies:",
      "options": [
        "Normal behavior",
        "Deviations from expected patterns indicating potential issues",
        "All data",
        "Nothing"
      ],
      "answer": 1,
      "explanation": "Anomaly detection uses machine learning or statistical methods to identify unusual patterns deviating from baselines, flagging potential problems. Objective 3.1"
    },
    {
      "q": "Log correlation enables:",
      "options": [
        "No benefits",
        "Connecting related events across systems for root cause analysis",
        "Random linking",
        "Data deletion"
      ],
      "answer": 1,
      "explanation": "Correlation links related log events using request IDs, sessions, or timestamps across services, enabling comprehensive incident investigation. Objective 3.1"
    },
    {
      "q": "What information should alerts include?",
      "options": [
        "Just error message",
        "Severity, affected resources, impact, and remediation guidance",
        "No information",
        "Only timestamp"
      ],
      "answer": 1,
      "explanation": "Actionable alerts include severity, impacted services/users, current vs threshold values, runbook links, and context for rapid response. Objective 3.1"
    },
    {
      "q": "Observability differs from monitoring by:",
      "options": [
        "They are identical",
        "Observability infers internal state from external outputs",
        "No difference",
        "Only terminology"
      ],
      "answer": 1,
      "explanation": "Observability enables understanding system internal state through logs, metrics, and traces without predefined dashboards, answering unexpected questions. Objective 3.1"
    },
    {
      "q": "Horizontal scaling involves:",
      "options": [
        "Increasing instance size",
        "Adding more instances to distribute load",
        "Removing instances",
        "No changes"
      ],
      "answer": 1,
      "explanation": "Horizontal scaling (scale out) adds more instances of same size, distributing load across multiple servers, providing better fault tolerance than vertical. Objective 3.2"
    },
    {
      "q": "Vertical scaling involves:",
      "options": [
        "Adding more instances",
        "Increasing size/capacity of existing instances",
        "Removing resources",
        "No changes"
      ],
      "answer": 1,
      "explanation": "Vertical scaling (scale up) increases CPU, memory, or other resources of existing instance, simpler but limited by maximum instance size. Objective 3.2"
    },
    {
      "q": "Which scaling type provides better fault tolerance?",
      "options": [
        "Vertical only",
        "Horizontal scaling across multiple instances",
        "Neither",
        "Both equal"
      ],
      "answer": 1,
      "explanation": "Horizontal scaling improves fault tolerance as failure of one instance affects smaller percentage of capacity, while vertical scaling creates single point of failure. Objective 3.2"
    },
    {
      "q": "Auto-scaling based on trending means:",
      "options": [
        "Random scaling",
        "Scaling based on predicted demand patterns",
        "No scaling",
        "Manual only"
      ],
      "answer": 1,
      "explanation": "Trend-based scaling analyzes historical patterns to predict future demand, scaling proactively before load increases to prevent performance degradation. Objective 3.2"
    },
    {
      "q": "Load-based auto-scaling triggers when:",
      "options": [
        "Scheduled time",
        "Metrics like CPU or requests exceed thresholds",
        "Never",
        "Random"
      ],
      "answer": 1,
      "explanation": "Load-based scaling monitors metrics (CPU, memory, requests/second) and adds/removes instances when thresholds are crossed, responding to actual demand. Objective 3.2"
    },
    {
      "q": "Event-driven scaling responds to:",
      "options": [
        "No events",
        "Specific events or conditions triggering scale actions",
        "Only time",
        "Manual requests only"
      ],
      "answer": 1,
      "explanation": "Event-driven scaling reacts to specific events (queue depth, message rate, custom metrics), scaling in response to actual workload conditions. Objective 3.2"
    },
    {
      "q": "Scheduled scaling is BEST for:",
      "options": [
        "Unpredictable load",
        "Predictable, time-based demand patterns",
        "Steady load",
        "Random patterns"
      ],
      "answer": 1,
      "explanation": "Scheduled scaling pre-scales resources for known patterns (business hours, end-of-month processing), avoiding reactive delays during predictable demand. Objective 3.2"
    },
    {
      "q": "Manual scaling involves:",
      "options": [
        "Automatic adjustments",
        "Operator-initiated resource adjustments",
        "No scaling",
        "System decides only"
      ],
      "answer": 1,
      "explanation": "Manual scaling requires human intervention to add/remove resources, suitable for planned events or when automatic scaling isn't appropriate. Objective 3.2"
    },
    {
      "q": "Scale-in (reducing instances) should consider:",
      "options": [
        "Immediate termination",
        "Connection draining and graceful shutdown",
        "No consideration",
        "Force stop"
      ],
      "answer": 1,
      "explanation": "Safe scale-in drains existing connections, completes in-flight requests, and ensures no data loss before terminating instances. Objective 3.2"
    },
    {
      "q": "Scaling cooldown periods prevent:",
      "options": [
        "All scaling",
        "Rapid, unstable scaling oscillations",
        "Manual scaling",
        "No purpose"
      ],
      "answer": 1,
      "explanation": "Cooldown periods delay subsequent scaling actions after scale event, preventing instability from rapid oscillations while new resources stabilize. Objective 3.2"
    },
    {
      "q": "Minimum instance count ensures:",
      "options": [
        "No instances",
        "Baseline capacity always available",
        "Maximum cost",
        "No scaling"
      ],
      "answer": 1,
      "explanation": "Minimum instance count maintains baseline capacity for availability and performance, preventing scale-to-zero scenarios affecting service. Objective 3.2"
    },
    {
      "q": "Maximum instance count prevents:",
      "options": [
        "Scaling up",
        "Uncontrolled costs and resource exhaustion",
        "All instances",
        "Availability"
      ],
      "answer": 1,
      "explanation": "Maximum limits protect against runaway scaling costs, misconfigurations, or DDoS attacks causing excessive resource consumption. Objective 3.2"
    },
    {
      "q": "Desired capacity in auto-scaling represents:",
      "options": [
        "Random number",
        "Target number of instances system aims to maintain",
        "Minimum only",
        "Maximum only"
      ],
      "answer": 1,
      "explanation": "Desired capacity is target instance count auto-scaling maintains, adjusted dynamically within min/max bounds based on scaling policies. Objective 3.2"
    },
    {
      "q": "Target tracking scaling maintains:",
      "options": [
        "Random values",
        "Specific metric value (e.g., 70% CPU utilization)",
        "No target",
        "Maximum always"
      ],
      "answer": 1,
      "explanation": "Target tracking automatically adjusts capacity to maintain specified metric target (CPU 70%, request count), simplifying configuration. Objective 3.2"
    },
    {
      "q": "Step scaling adjusts capacity by:",
      "options": [
        "Fixed amount always",
        "Different amounts based on alarm breach magnitude",
        "No adjustment",
        "Random amounts"
      ],
      "answer": 1,
      "explanation": "Step scaling uses multiple thresholds with different scaling adjustments (e.g., +1 instance at 70% CPU, +3 at 90%), responding proportionally. Objective 3.2"
    },
    {
      "q": "Predictive scaling uses:",
      "options": [
        "No data",
        "Machine learning to forecast demand and pre-scale",
        "Random guesses",
        "Manual input only"
      ],
      "answer": 1,
      "explanation": "Predictive scaling analyzes historical patterns with ML to forecast demand, scaling proactively before load increases improve performance. Objective 3.2"
    },
    {
      "q": "What metric is commonly used for web application auto-scaling?",
      "options": [
        "Disk space only",
        "CPU utilization, requests per second, or response time",
        "Color schemes",
        "No metrics"
      ],
      "answer": 1,
      "explanation": "Web apps typically scale on CPU, requests/second, active connections, or response latency, selecting metrics that reflect actual user impact. Objective 3.2"
    },
    {
      "q": "Queue-based scaling triggers when:",
      "options": [
        "No messages",
        "Queue depth or message age exceeds thresholds",
        "Random times",
        "Never"
      ],
      "answer": 1,
      "explanation": "Queue-based scaling monitors message queue depth or age, adding workers when backlog grows to maintain processing throughput. Objective 3.2"
    },
    {
      "q": "Health checks in auto-scaling determine:",
      "options": [
        "Nothing",
        "Whether instances are healthy and should receive traffic",
        "Only startup",
        "Cost only"
      ],
      "answer": 1,
      "explanation": "Health checks verify instance health; unhealthy instances are replaced automatically, maintaining fleet health and availability. Objective 3.2"
    },
    {
      "q": "What happens when an instance fails health checks?",
      "options": [
        "Nothing",
        "Removed from load balancer and replaced with new instance",
        "Continues serving",
        "Manual intervention required"
      ],
      "answer": 1,
      "explanation": "Failed instances are automatically removed from load balancer rotation and terminated, with auto-scaling launching replacements to maintain desired capacity. Objective 3.2"
    },
    {
      "q": "Scaling policies should be tested during:",
      "options": [
        "Never",
        "Load testing and chaos engineering exercises",
        "Production only",
        "No testing needed"
      ],
      "answer": 1,
      "explanation": "Testing scaling under load validates thresholds, response times, and stability before production traffic, identifying tuning needs. Objective 3.2"
    },
    {
      "q": "Blue-green deployment facilitates scaling by:",
      "options": [
        "No impact",
        "Allowing instant traffic shifts to pre-scaled environment",
        "Slowing scaling",
        "Preventing scaling"
      ],
      "answer": 1,
      "explanation": "Blue-green enables pre-scaling green environment to required capacity before cutover, avoiding performance issues during traffic migration. Objective 3.2"
    },
    {
      "q": "Stateful applications present scaling challenges because:",
      "options": [
        "No challenges",
        "Session data must be preserved or shared across instances",
        "They scale easily",
        "No impact"
      ],
      "answer": 1,
      "explanation": "Stateful apps require session persistence, shared storage, or session replication, complicating horizontal scaling compared to stateless apps. Objective 3.2"
    },
    {
      "q": "Stateless application design enables:",
      "options": [
        "No scaling",
        "Easy horizontal scaling with any instance handling requests",
        "Only vertical scaling",
        "Complexity"
      ],
      "answer": 1,
      "explanation": "Stateless apps store session data externally, allowing any instance to handle requests, simplifying horizontal scaling and load balancing. Objective 3.2"
    },
    {
      "q": "Database scaling typically uses:",
      "options": [
        "Only horizontal",
        "Read replicas for reads, vertical scaling for writes",
        "No scaling",
        "Random approach"
      ],
      "answer": 1,
      "explanation": "Databases commonly scale reads horizontally with replicas while scaling writes vertically, though some use sharding for horizontal write scaling. Objective 3.2"
    },
    {
      "q": "Full backups capture:",
      "options": [
        "Only changed data",
        "Complete copy of all data",
        "No data",
        "Metadata only"
      ],
      "answer": 1,
      "explanation": "Full backups copy all data regardless of previous backups, providing complete standalone backup but consuming most storage and time. Objective 3.3"
    },
    {
      "q": "Incremental backups capture:",
      "options": [
        "All data",
        "Only changes since last backup (full or incremental)",
        "No data",
        "Random data"
      ],
      "answer": 1,
      "explanation": "Incremental backups save only data changed since previous backup (any type), minimizing backup time and storage but requiring all backups for restoration. Objective 3.3"
    },
    {
      "q": "Differential backups capture:",
      "options": [
        "Only changed today",
        "All changes since last full backup",
        "All data",
        "No data"
      ],
      "answer": 1,
      "explanation": "Differential backups save all changes since last full backup, balancing backup size/time against restoration complexity (need full + latest differential). Objective 3.3"
    },
    {
      "q": "Which backup type requires the LEAST time to restore?",
      "options": [
        "Incremental",
        "Differential",
        "Full backup",
        "All equal"
      ],
      "answer": 2,
      "explanation": "Full backups restore fastest as they contain all data in single backup, while incremental requires full + all incremental backups. Objective 3.3"
    },
    {
      "q": "Which backup type consumes LEAST storage space?",
      "options": [
        "Full",
        "Differential",
        "Incremental",
        "All equal"
      ],
      "answer": 2,
      "explanation": "Incremental backups use least storage by capturing only changes since previous backup, though requiring more backups for full restoration. Objective 3.3"
    },
    {
      "q": "On-site backup provides:",
      "options": [
        "Geographic redundancy",
        "Fast restoration but no disaster recovery",
        "Slow restoration",
        "No benefits"
      ],
      "answer": 1,
      "explanation": "On-site backups enable fast restoration due to proximity but don't protect against site-wide disasters (fire, flood, ransomware). Objective 3.3"
    },
    {
      "q": "Off-site backup provides:",
      "options": [
        "No benefits",
        "Geographic redundancy for disaster recovery",
        "Fastest restoration",
        "Local access only"
      ],
      "answer": 1,
      "explanation": "Off-site backups protect against site disasters by storing data in different geographic location, essential for comprehensive DR strategy. Objective 3.3"
    },
    {
      "q": "The 3-2-1 backup rule recommends:",
      "options": [
        "One backup only",
        "3 copies, 2 media types, 1 off-site",
        "Random approach",
        "No backups"
      ],
      "answer": 1,
      "explanation": "3-2-1 rule ensures resilience: 3 data copies, on 2 different media types, with 1 copy off-site protecting against various failure scenarios. Objective 3.3"
    },
    {
      "q": "Backup scheduling should consider:",
      "options": [
        "Random times",
        "RPO requirements, system load, and change frequency",
        "Only weekends",
        "No schedule"
      ],
      "answer": 1,
      "explanation": "Schedule frequency must meet RPO (acceptable data loss), balance system impact, and align with change patterns (more frequent for critical data). Objective 3.3"
    },
    {
      "q": "Backup retention policies define:",
      "options": [
        "No limits",
        "How long backups are kept based on requirements",
        "Keep forever",
        "Delete immediately"
      ],
      "answer": 1,
      "explanation": "Retention balances compliance requirements, recovery needs, and storage costs (daily: 30 days, weekly: 12 weeks, monthly: 12 months). Objective 3.3"
    },
    {
      "q": "Backup replication provides:",
      "options": [
        "No benefits",
        "Multiple copies in different locations for redundancy",
        "Single copy only",
        "Slower backups"
      ],
      "answer": 1,
      "explanation": "Replication creates copies across regions/clouds, protecting against regional failures and improving disaster recovery capabilities. Objective 3.3"
    },
    {
      "q": "Why should backups be encrypted?",
      "options": [
        "Not necessary",
        "Protect data confidentiality if backup media is compromised",
        "Slows backups",
        "No benefit"
      ],
      "answer": 1,
      "explanation": "Encryption protects backup data from unauthorized access if storage is compromised, lost, or stolen, meeting compliance and security requirements. Objective 3.3"
    },
    {
      "q": "Backup testing should verify:",
      "options": [
        "Nothing",
        "Recoverability and data integrity through regular restoration tests",
        "Only size",
        "Cost only"
      ],
      "answer": 1,
      "explanation": "Regular restoration testing validates backups are complete, uncorrupted, and restorable, ensuring they'll work during actual recovery. Objective 3.3"
    },
    {
      "q": "How often should backup restoration be tested?",
      "options": [
        "Never",
        "Regularly (monthly/quarterly) and after major changes",
        "Once only",
        "During disaster only"
      ],
      "answer": 1,
      "explanation": "Regular testing (quarterly minimum) plus event-driven testing validates backup integrity and team preparedness, identifying issues before emergencies. Objective 3.3"
    },
    {
      "q": "Backup integrity checks verify:",
      "options": [
        "Nothing",
        "Backup files are complete and not corrupted",
        "Only size",
        "Cost only"
      ],
      "answer": 1,
      "explanation": "Integrity checks use checksums, hashes, or test restores to verify backups are complete and uncorrupted, ensuring reliable recovery. Objective 3.3"
    },
    {
      "q": "In-place recovery restores data to:",
      "options": [
        "Different location",
        "Original location overwriting existing data",
        "No location",
        "Random location"
      ],
      "answer": 1,
      "explanation": "In-place recovery restores data to original location/system, replacing current state with backup version, typical for disaster recovery. Objective 3.3"
    },
    {
      "q": "Parallel recovery restores data to:",
      "options": [
        "Original location only",
        "Alternate location while production continues",
        "No location",
        "Random location"
      ],
      "answer": 1,
      "explanation": "Parallel recovery restores to alternate environment, enabling validation before cutover and supporting legal discovery without disrupting production. Objective 3.3"
    },
    {
      "q": "Bulk recovery restores:",
      "options": [
        "Single file",
        "Entire system or large data set",
        "No data",
        "Metadata only"
      ],
      "answer": 1,
      "explanation": "Bulk recovery restores complete systems, volumes, or databases, used for disaster recovery or major failures requiring comprehensive restoration. Objective 3.3"
    },
    {
      "q": "Granular recovery enables:",
      "options": [
        "Only full restoration",
        "Restoring individual files, emails, or database records",
        "No recovery",
        "System restoration only"
      ],
      "answer": 1,
      "explanation": "Granular recovery restores specific items (single file, email, database table) without full restoration, enabling targeted recovery faster. Objective 3.3"
    },
    {
      "q": "Backup windows should:",
      "options": [
        "Run during peak hours",
        "Complete within maintenance window with minimal impact",
        "Never complete",
        "Take weeks"
      ],
      "answer": 1,
      "explanation": "Backups should complete within available maintenance window, minimizing production impact while ensuring adequate data protection. Objective 3.3"
    },
    {
      "q": "Immutable backups prevent:",
      "options": [
        "Recovery",
        "Deletion or modification, protecting against ransomware",
        "All access",
        "Nothing"
      ],
      "answer": 1,
      "explanation": "Immutable backups cannot be deleted or modified after creation, protecting against ransomware and insider threats for specified retention period. Objective 3.3"
    },
    {
      "q": "Application-consistent backups ensure:",
      "options": [
        "No consistency",
        "All application components backed up in consistent state",
        "Random data",
        "File-level only"
      ],
      "answer": 1,
      "explanation": "Application-consistent backups coordinate with applications to quiesce I/O and capture all components in synchronized state for clean recovery. Objective 3.3"
    },
    {
      "q": "Crash-consistent backups:",
      "options": [
        "Are never useful",
        "Capture point-in-time snapshot similar to crash recovery",
        "Are always best",
        "Have no data"
      ],
      "answer": 1,
      "explanation": "Crash-consistent backups capture snapshot without coordinating with applications, like recovery after crash; applications must replay logs during restoration. Objective 3.3"
    },
    {
      "q": "Backup deduplication reduces:",
      "options": [
        "Backup quality",
        "Storage requirements by eliminating duplicate data",
        "Recovery speed",
        "Retention"
      ],
      "answer": 1,
      "explanation": "Deduplication identifies and eliminates duplicate data blocks across backups, significantly reducing storage consumption especially for incremental backups. Objective 3.3"
    },
    {
      "q": "Cloud-to-cloud backup protects against:",
      "options": [
        "All disasters",
        "Accidental deletion, corruption, and provider issues",
        "Physical disasters only",
        "Nothing"
      ],
      "answer": 1,
      "explanation": "Cloud-to-cloud backup protects SaaS data (Office 365, Salesforce) from accidental deletion, ransomware, retention gaps, and provider issues. Objective 3.3"
    },
    {
      "q": "Major version updates typically include:",
      "options": [
        "Only bug fixes",
        "Significant changes, new features, potential breaking changes",
        "No changes",
        "Minor fixes only"
      ],
      "answer": 1,
      "explanation": "Major updates (2.0, 3.0) include significant functionality changes, architectural updates, and potentially breaking changes requiring testing and planning. Objective 3.4"
    },
    {
      "q": "Minor version updates typically include:",
      "options": [
        "Breaking changes",
        "New features, improvements, backward-compatible changes",
        "No changes",
        "Major redesign"
      ],
      "answer": 1,
      "explanation": "Minor updates (2.1, 2.2) add features and improvements while maintaining backward compatibility, lower risk than major updates. Objective 3.4"
    },
    {
      "q": "Patch updates primarily address:",
      "options": [
        "New features",
        "Security vulnerabilities and bug fixes",
        "Major redesign",
        "No changes"
      ],
      "answer": 1,
      "explanation": "Patches (2.1.1, 2.1.2) fix security vulnerabilities, bugs, and stability issues without adding features, requiring prompt deployment. Objective 3.4"
    },
    {
      "q": "Before applying updates in production, you should:",
      "options": [
        "Apply immediately",
        "Test in non-production environment",
        "Skip testing",
        "Hope for best"
      ],
      "answer": 1,
      "explanation": "Updates must be tested in dev/test environments to identify compatibility issues, performance impacts, or regressions before production deployment. Objective 3.4"
    },
    {
      "q": "Ephemeral data is:",
      "options": [
        "Permanent storage",
        "Temporary data deleted when resource terminates",
        "Backed up daily",
        "Long-term retention"
      ],
      "answer": 1,
      "explanation": "Ephemeral data exists only during resource lifetime (container, instance session), deleted upon termination, suitable for caches and temporary processing. Objective 3.4"
    },
    {
      "q": "Persistent data requires:",
      "options": [
        "No storage",
        "Durable storage independent of compute resources",
        "Deletion on shutdown",
        "Temporary storage only"
      ],
      "answer": 1,
      "explanation": "Persistent data survives resource termination using volumes, object storage, or databases that exist independently of compute instances. Objective 3.4"
    },
    {
      "q": "End of Life (EOL) for software means:",
      "options": [
        "Just beginning",
        "Vendor discontinues product, no further updates",
        "New version released",
        "Peak support"
      ],
      "answer": 1,
      "explanation": "EOL means vendor ceases all updates, patches, and support; continued use creates security and compliance risks requiring migration planning. Objective 3.4"
    },
    {
      "q": "End of Support (EOS) means:",
      "options": [
        "Full support continues",
        "Vendor stops technical support, may continue security patches",
        "New features added",
        "No impact"
      ],
      "answer": 1,
      "explanation": "EOS discontinues technical support and feature updates; critical security patches may continue temporarily before full EOL, signaling migration need. Objective 3.4"
    },
    {
      "q": "When software reaches EOL, you should:",
      "options": [
        "Continue using indefinitely",
        "Plan migration to supported version or alternative",
        "Ignore it",
        "No action needed"
      ],
      "answer": 1,
      "explanation": "EOL requires migration planning to supported versions or alternatives, as continued use without patches creates security vulnerabilities and compliance issues. Objective 3.4"
    },
    {
      "q": "Decommissioning process should include:",
      "options": [
        "Immediate deletion",
        "Data backup, dependency checks, documentation, and gradual shutdown",
        "No process",
        "Random deletion"
      ],
      "answer": 1,
      "explanation": "Proper decommissioning backs up data, verifies no dependencies, updates documentation, archives configurations, and gradually removes resources. Objective 3.4"
    },
    {
      "q": "Before decommissioning a resource, verify:",
      "options": [
        "Nothing",
        "No dependencies exist and data is backed up or migrated",
        "Delete immediately",
        "Random check"
      ],
      "answer": 1,
      "explanation": "Pre-decommissioning checks identify dependencies, ensure data preservation/migration, document reason, and coordinate with stakeholders. Objective 3.4"
    },
    {
      "q": "Resource tagging for lifecycle management enables:",
      "options": [
        "No benefits",
        "Automated policies for updates, archiving, and decommissioning",
        "Manual only",
        "Random management"
      ],
      "answer": 1,
      "explanation": "Lifecycle tags (environment, owner, expiration date) enable automated policies for updates, cost allocation, retention, and decommissioning. Objective 3.4"
    },
    {
      "q": "Automated patch management provides:",
      "options": [
        "No automation",
        "Consistent, timely patching across resources",
        "Manual intervention always",
        "Random updates"
      ],
      "answer": 1,
      "explanation": "Automated patching (AWS Systems Manager, Azure Update Management) ensures consistent, timely updates across fleet reducing manual effort and exposure. Objective 3.4"
    },
    {
      "q": "Patch compliance reporting shows:",
      "options": [
        "Nothing",
        "Which resources need patches and compliance status",
        "Random data",
        "Cost only"
      ],
      "answer": 1,
      "explanation": "Compliance reporting identifies unpatched systems, missing security updates, and policy violations, enabling targeted remediation and audit evidence. Objective 3.4"
    },
    {
      "q": "Change windows for updates should be:",
      "options": [
        "Any time",
        "Scheduled during low-traffic periods with approval",
        "Random",
        "Peak hours"
      ],
      "answer": 1,
      "explanation": "Change windows schedule updates during maintenance periods, require approvals, communicate to stakeholders, and prepare rollback plans. Objective 3.4"
    },
    {
      "q": "Rollback procedures for failed updates should:",
      "options": [
        "Not exist",
        "Be documented and tested before deployment",
        "Improvise",
        "No planning"
      ],
      "answer": 1,
      "explanation": "Rollback procedures define steps to revert failed updates, should be tested beforehand, and include data restoration if necessary. Objective 3.4"
    },
    {
      "q": "Configuration management tools help with lifecycle by:",
      "options": [
        "No help",
        "Automating consistent configuration across resource lifecycle",
        "Manual work only",
        "Random changes"
      ],
      "answer": 1,
      "explanation": "Tools like Ansible, Puppet, Chef automate configuration, ensure consistency, manage updates, and enforce desired state throughout lifecycle. Objective 3.4"
    },
    {
      "q": "Version pinning in deployments:",
      "options": [
        "Uses latest always",
        "Locks to specific versions for stability and testing",
        "Random versions",
        "No versions"
      ],
      "answer": 1,
      "explanation": "Pinning dependencies to specific versions prevents unexpected breaking changes from automatic updates, ensuring stability and predictable behavior. Objective 3.4"
    },
    {
      "q": "Blue-green deployment facilitates updates by:",
      "options": [
        "No benefit",
        "Enabling testing and instant rollback of new versions",
        "Slowing updates",
        "Complicating process"
      ],
      "answer": 1,
      "explanation": "Blue-green allows testing new version in green environment before traffic switch, with instant rollback to blue if issues arise. Objective 3.4"
    },
    {
      "q": "Sunset process for applications includes:",
      "options": [
        "Immediate shutdown",
        "User notification, data migration, gradual shutdown, and documentation",
        "No process",
        "Random deletion"
      ],
      "answer": 1,
      "explanation": "Application sunset notifies users, migrates data, provides alternatives, maintains access temporarily, documents process, and archives data. Objective 3.4"
    }
  ],
  "5. DevOps Fundamentals": [
    {
      "q": "What is the primary purpose of version control systems?",
      "options": [
        "Slow down development",
        "Track changes, enable collaboration, and maintain code history",
        "Delete code",
        "No purpose"
      ],
      "answer": 1,
      "explanation": "Version control systems (Git, SVN) track every change to code, enable team collaboration, maintain complete history, and support rollback to previous versions. Objective 5.1"
    },
    {
      "q": "Git branching allows developers to:",
      "options": [
        "Delete all code",
        "Work on features independently without affecting main codebase",
        "Only view code",
        "No changes allowed"
      ],
      "answer": 1,
      "explanation": "Branches enable parallel development, allowing multiple developers to work on different features/fixes simultaneously without interfering with each other. Objective 5.1"
    },
    {
      "q": "The main/master branch typically contains:",
      "options": [
        "Experimental code",
        "Stable, production-ready code",
        "Deleted code",
        "Random files"
      ],
      "answer": 1,
      "explanation": "Main/master branch maintains stable, tested, production-ready code; all deployments typically come from this branch to ensure reliability. Objective 5.1"
    },
    {
      "q": "Feature branches are used for:",
      "options": [
        "Production deployments",
        "Developing new features in isolation",
        "Deleting features",
        "No purpose"
      ],
      "answer": 1,
      "explanation": "Feature branches isolate new feature development from main branch, enabling testing and review before merging into production code. Objective 5.1"
    },
    {
      "q": "A pull request (PR) enables:",
      "options": [
        "Automatic deployment",
        "Code review before merging changes",
        "Deleting branches",
        "No review"
      ],
      "answer": 1,
      "explanation": "Pull requests facilitate code review, discussion, automated testing, and approval before merging changes, ensuring code quality and knowledge sharing. Objective 5.1"
    },
    {
      "q": "Git merge combines:",
      "options": [
        "Nothing",
        "Changes from one branch into another",
        "Deletes branches",
        "Only conflicts"
      ],
      "answer": 1,
      "explanation": "Merge integrates changes from source branch into target branch, combining commit histories and code changes into unified codebase. Objective 5.1"
    },
    {
      "q": "Merge conflicts occur when:",
      "options": [
        "No issues",
        "Same code lines modified in different branches",
        "Successful merge",
        "No changes made"
      ],
      "answer": 1,
      "explanation": "Conflicts arise when same code sections are modified differently in branches being merged, requiring manual resolution to determine final version. Objective 5.1"
    },
    {
      "q": "Git commit creates:",
      "options": [
        "Branch",
        "Snapshot of changes with descriptive message",
        "Repository",
        "Conflict"
      ],
      "answer": 1,
      "explanation": "Commits save snapshots of code changes with messages describing what changed and why, building complete history of project evolution. Objective 5.1"
    },
    {
      "q": "Git push sends:",
      "options": [
        "Nothing",
        "Local commits to remote repository",
        "Deletes remote code",
        "Only conflicts"
      ],
      "answer": 1,
      "explanation": "Push uploads local commits to remote repository (GitHub, GitLab), sharing changes with team and backing up work to central location. Objective 5.1"
    },
    {
      "q": "Git pull retrieves:",
      "options": [
        "Nothing",
        "Latest changes from remote repository to local",
        "Deletes local code",
        "Only conflicts"
      ],
      "answer": 1,
      "explanation": "Pull fetches and merges latest changes from remote repository into local branch, keeping local copy synchronized with team changes. Objective 5.1"
    },
    {
      "q": "A Git tag is used to:",
      "options": [
        "Delete commits",
        "Mark specific points in history like releases",
        "Create branches",
        "Cause conflicts"
      ],
      "answer": 1,
      "explanation": "Tags create immutable references to specific commits, typically marking release versions (v1.0, v2.0) for easy identification and deployment. Objective 5.1"
    },
    {
      "q": "Git clone creates:",
      "options": [
        "New branch",
        "Complete local copy of remote repository",
        "Tag",
        "Conflict"
      ],
      "answer": 1,
      "explanation": "Clone downloads entire repository including all history, branches, and files to local machine, enabling independent work on copy. Objective 5.1"
    },
    {
      "q": ".gitignore file specifies:",
      "options": [
        "Required files",
        "Files to exclude from version control",
        "Merge strategy",
        "Branch names"
      ],
      "answer": 1,
      "explanation": ".gitignore lists files/patterns to exclude from Git (build artifacts, credentials, IDE files), preventing unnecessary or sensitive files from being tracked. Objective 5.1"
    },
    {
      "q": "Git rebase differs from merge by:",
      "options": [
        "No difference",
        "Rewriting commit history to create linear progression",
        "Deleting commits",
        "Only creating conflicts"
      ],
      "answer": 1,
      "explanation": "Rebase moves/combines commits to create linear history without merge commits, resulting in cleaner history but rewriting commit chronology. Objective 5.1"
    },
    {
      "q": "Code review best practices include:",
      "options": [
        "Skip all reviews",
        "Reviewing for logic, security, style, and maintainability",
        "Only syntax check",
        "Auto-approve everything"
      ],
      "answer": 1,
      "explanation": "Effective reviews check correctness, security vulnerabilities, code style, test coverage, documentation, and maintainability before approval. Objective 5.1"
    },
    {
      "q": "What should commit messages include?",
      "options": [
        "Nothing",
        "Clear description of what changed and why",
        "Random text",
        "Only emoji"
      ],
      "answer": 1,
      "explanation": "Good commit messages clearly explain what changed, why it changed, and any relevant context, making history understandable and useful. Objective 5.1"
    },
    {
      "q": "Branch protection rules can enforce:",
      "options": [
        "No restrictions",
        "Required reviews, status checks, and merge restrictions",
        "Anyone can delete",
        "No rules"
      ],
      "answer": 1,
      "explanation": "Protection rules require PR approvals, passing tests, up-to-date branches, and prevent force pushes/deletions, ensuring code quality. Objective 5.1"
    },
    {
      "q": "Git stash temporarily:",
      "options": [
        "Deletes changes",
        "Saves uncommitted changes for later retrieval",
        "Creates branch",
        "Pushes to remote"
      ],
      "answer": 1,
      "explanation": "Stash saves current uncommitted changes without committing, allowing branch switching or pulling updates, then reapplying changes later. Objective 5.1"
    },
    {
      "q": "Forking a repository creates:",
      "options": [
        "Branch",
        "Independent copy under your account",
        "Tag",
        "Merge"
      ],
      "answer": 1,
      "explanation": "Fork creates personal copy of repository where you can freely experiment, then submit changes back via pull request to original. Objective 5.1"
    },
    {
      "q": "Git cherry-pick allows:",
      "options": [
        "Deleting commits",
        "Applying specific commits from one branch to another",
        "Creating repository",
        "No action"
      ],
      "answer": 1,
      "explanation": "Cherry-pick selectively applies specific commits to current branch without merging entire branch history, useful for hotfixes. Objective 5.1"
    },
    {
      "q": "Git diff shows:",
      "options": [
        "Nothing",
        "Differences between commits, branches, or working directory",
        "Merge commits only",
        "Tags"
      ],
      "answer": 1,
      "explanation": "Diff displays line-by-line changes between versions, helping review modifications before committing or understanding what changed. Objective 5.1"
    },
    {
      "q": "Release branches are used for:",
      "options": [
        "Feature development",
        "Preparing and stabilizing code for production release",
        "Experimentation",
        "Deleting code"
      ],
      "answer": 1,
      "explanation": "Release branches isolate release preparation (bug fixes, documentation, version bumps) while allowing continued feature development on main. Objective 5.1"
    },
    {
      "q": "Hotfix branches address:",
      "options": [
        "New features",
        "Critical production bugs requiring immediate fixes",
        "Regular updates",
        "Experiments"
      ],
      "answer": 1,
      "explanation": "Hotfix branches branch from production, fix critical bugs, and merge back to production and development, bypassing normal release cycle. Objective 5.1"
    },
    {
      "q": "Git workflow strategies include:",
      "options": [
        "No strategy",
        "GitFlow, GitHub Flow, trunk-based development",
        "Random commits",
        "No branching"
      ],
      "answer": 1,
      "explanation": "Workflows define branching strategies: GitFlow (multiple long-lived branches), GitHub Flow (feature branches), trunk-based (frequent main commits). Objective 5.1"
    },
    {
      "q": "Trunk-based development emphasizes:",
      "options": [
        "Long-lived branches",
        "Frequent small commits directly to main branch",
        "No commits",
        "Annual merges"
      ],
      "answer": 1,
      "explanation": "Trunk-based development commits small changes frequently to main, reducing merge conflicts and enabling continuous integration/deployment. Objective 5.1"
    },
    {
      "q": "Configuration management tools ensure:",
      "options": [
        "Manual configuration",
        "Consistent, automated infrastructure and application configuration",
        "Random settings",
        "No management"
      ],
      "answer": 1,
      "explanation": "CM tools (Ansible, Puppet, Chef) automate configuration deployment, ensure consistency across environments, and enforce desired state. Objective 5.2"
    },
    {
      "q": "Ansible playbooks are written in:",
      "options": [
        "Binary",
        "YAML format describing desired state",
        "Assembly",
        "No format"
      ],
      "answer": 1,
      "explanation": "Ansible playbooks use human-readable YAML to define tasks, configurations, and orchestration steps for automated infrastructure management. Objective 5.2"
    },
    {
      "q": "Idempotency in configuration management means:",
      "options": [
        "Different results each run",
        "Running multiple times produces same result",
        "Always fails",
        "Random outcomes"
      ],
      "answer": 1,
      "explanation": "Idempotent operations produce consistent results regardless of repetition - applying same configuration multiple times achieves same state safely. Objective 5.2"
    },
    {
      "q": "Infrastructure as Code (IaC) treats infrastructure as:",
      "options": [
        "Physical only",
        "Code that can be versioned, tested, and automated",
        "Manual documentation",
        "Random hardware"
      ],
      "answer": 1,
      "explanation": "IaC defines infrastructure in code files enabling version control, automated deployment, testing, and consistent reproducible environments. Objective 5.2"
    },
    {
      "q": "Configuration drift occurs when:",
      "options": [
        "Desired state maintained",
        "Actual configuration diverges from defined state",
        "Perfect alignment",
        "No configuration"
      ],
      "answer": 1,
      "explanation": "Drift happens when manual changes or errors cause actual state to differ from defined configuration, causing inconsistencies and issues. Objective 5.2"
    },
    {
      "q": "Desired state configuration defines:",
      "options": [
        "Current state",
        "Target configuration systems should maintain",
        "Historical state",
        "Random state"
      ],
      "answer": 1,
      "explanation": "Desired state specifies target configuration; CM tools continuously enforce this state, automatically correcting deviations. Objective 5.2"
    },
    {
      "q": "Ansible is agentless, meaning:",
      "options": [
        "No functionality",
        "No software required on managed nodes, uses SSH",
        "Requires agents everywhere",
        "Manual only"
      ],
      "answer": 1,
      "explanation": "Ansible doesn't require agent installation on managed nodes; it uses SSH (Linux) or WinRM (Windows) for communication, simplifying deployment. Objective 5.2"
    },
    {
      "q": "Puppet uses agent-based architecture where:",
      "options": [
        "No agents",
        "Agents on managed nodes communicate with Puppet master",
        "Manual only",
        "No master"
      ],
      "answer": 1,
      "explanation": "Puppet agents run on managed nodes, periodically checking with Puppet master for configuration updates and reporting status. Objective 5.2"
    },
    {
      "q": "Configuration management advantages include:",
      "options": [
        "More manual work",
        "Consistency, repeatability, faster deployment, reduced errors",
        "Slower processes",
        "Random results"
      ],
      "answer": 1,
      "explanation": "CM provides consistent configurations, eliminates manual errors, enables rapid deployment, ensures compliance, and documents infrastructure as code. Objective 5.2"
    },
    {
      "q": "Ansible inventory files define:",
      "options": [
        "Nothing",
        "Managed hosts and their groupings",
        "Only local machine",
        "Random servers"
      ],
      "answer": 1,
      "explanation": "Inventory lists managed hosts, organizes them into groups (web, database), and defines connection parameters for automation. Objective 5.2"
    },
    {
      "q": "Ansible roles provide:",
      "options": [
        "No structure",
        "Reusable, organized collections of tasks and configurations",
        "Random code",
        "Single use only"
      ],
      "answer": 1,
      "explanation": "Roles organize playbooks into reusable components with standardized directory structure (tasks, handlers, templates, files) for modularity. Objective 5.2"
    },
    {
      "q": "Variables in configuration management enable:",
      "options": [
        "No flexibility",
        "Parameterizing configurations for different environments",
        "Hardcoded values only",
        "No reuse"
      ],
      "answer": 1,
      "explanation": "Variables allow same code to deploy different configurations (dev/prod) by changing values, improving reusability and maintainability. Objective 5.2"
    },
    {
      "q": "Templates in CM tools allow:",
      "options": [
        "Static files only",
        "Dynamic file generation using variables and logic",
        "No customization",
        "Manual editing only"
      ],
      "answer": 1,
      "explanation": "Templates (Jinja2 in Ansible) generate configuration files dynamically, inserting variables and applying logic for environment-specific configs. Objective 5.2"
    },
    {
      "q": "Handlers in Ansible execute:",
      "options": [
        "Always",
        "Only when notified by tasks that make changes",
        "Never",
        "Randomly"
      ],
      "answer": 1,
      "explanation": "Handlers run only when triggered by task notifications (e.g., restart service only if config changed), avoiding unnecessary actions. Objective 5.2"
    },
    {
      "q": "Configuration management testing should verify:",
      "options": [
        "Nothing",
        "Configurations apply correctly and achieve desired state",
        "Only syntax",
        "Manual only"
      ],
      "answer": 1,
      "explanation": "Testing validates syntax, idempotency, desired state achievement, and absence of unintended side effects before production deployment. Objective 5.2"
    },
    {
      "q": "Chef cookbooks contain:",
      "options": [
        "Food recipes",
        "Reusable configuration code and resources",
        "Random files",
        "No content"
      ],
      "answer": 1,
      "explanation": "Chef cookbooks package related recipes, resources, templates, and files into reusable units for infrastructure configuration management. Objective 5.2"
    },
    {
      "q": "Configuration management supports compliance by:",
      "options": [
        "No support",
        "Enforcing security policies and audit requirements consistently",
        "Random configs",
        "Manual tracking"
      ],
      "answer": 1,
      "explanation": "CM enforces security baselines, compliance policies, and audit requirements consistently across infrastructure with documented, versioned configurations. Objective 5.2"
    },
    {
      "q": "Secrets management in configuration code should:",
      "options": [
        "Hardcode passwords",
        "Use encrypted vaults or external secret stores",
        "Plain text files",
        "No secrets"
      ],
      "answer": 1,
      "explanation": "Secrets require encryption (Ansible Vault, HashiCorp Vault) or external stores, never hardcoded in configuration code or version control. Objective 5.2"
    },
    {
      "q": "Configuration as Code benefits from:",
      "options": [
        "No version control",
        "Version control, peer review, and automated testing",
        "Manual only",
        "Random changes"
      ],
      "answer": 1,
      "explanation": "Treating configuration as code enables version control, change tracking, code review, automated testing, and rollback capabilities. Objective 5.2"
    },
    {
      "q": "Ansible check mode:",
      "options": [
        "Makes changes",
        "Simulates execution without making actual changes",
        "Deletes configuration",
        "No function"
      ],
      "answer": 1,
      "explanation": "Check mode (dry run) shows what would change without applying modifications, enabling safe testing before actual execution. Objective 5.2"
    },
    {
      "q": "Configuration management scales by:",
      "options": [
        "Manual work only",
        "Applying same configurations consistently across thousands of nodes",
        "Single server only",
        "No scaling"
      ],
      "answer": 1,
      "explanation": "CM tools efficiently manage configurations across thousands of systems simultaneously, maintaining consistency at scale impossible manually. Objective 5.2"
    },
    {
      "q": "Orchestration in configuration management:",
      "options": [
        "Single task only",
        "Coordinates complex workflows across multiple systems",
        "No coordination",
        "Random execution"
      ],
      "answer": 1,
      "explanation": "Orchestration sequences tasks across multiple systems in specific order (deploy DB first, then app), managing complex multi-tier deployments. Objective 5.2"
    },
    {
      "q": "Configuration management documentation should include:",
      "options": [
        "Nothing",
        "Purpose, variables, dependencies, and usage examples",
        "Only code",
        "No documentation"
      ],
      "answer": 1,
      "explanation": "Documentation explains configuration purpose, required variables, system dependencies, usage examples, and expected outcomes for team understanding. Objective 5.2"
    },
    {
      "q": "Continuous configuration management:",
      "options": [
        "One-time setup",
        "Regularly enforces desired state and corrects drift",
        "Manual checks only",
        "No monitoring"
      ],
      "answer": 1,
      "explanation": "Continuous enforcement regularly checks and corrects configuration drift, maintaining desired state automatically without manual intervention. Objective 5.2"
    },
    {
      "q": "Configuration baselines define:",
      "options": [
        "Random settings",
        "Standard, approved configurations for systems",
        "Maximum settings",
        "No standards"
      ],
      "answer": 1,
      "explanation": "Baselines establish approved standard configurations ensuring security, compliance, and consistency across similar systems and environments. Objective 5.2"
    },
    {
      "q": "Continuous Integration (CI) involves:",
      "options": [
        "Monthly code merges",
        "Frequently merging code changes with automated testing",
        "Manual testing only",
        "No integration"
      ],
      "answer": 1,
      "explanation": "CI automatically builds and tests code when developers commit changes, detecting integration issues early through frequent merging and automated validation. Objective 5.3"
    },
    {
      "q": "Continuous Delivery (CD) ensures:",
      "options": [
        "Manual deployment",
        "Code is always in deployable state, ready for production",
        "No deployments",
        "Annual releases"
      ],
      "answer": 1,
      "explanation": "Continuous Delivery automates testing and staging so code is always production-ready; deployment to production requires manual approval. Objective 5.3"
    },
    {
      "q": "Continuous Deployment differs from Continuous Delivery by:",
      "options": [
        "No difference",
        "Automatically deploying to production without manual approval",
        "Manual only",
        "No automation"
      ],
      "answer": 1,
      "explanation": "Continuous Deployment automatically releases all passing changes to production without human intervention, while Delivery requires manual approval. Objective 5.3"
    },
    {
      "q": "CI/CD pipelines automate:",
      "options": [
        "Nothing",
        "Build, test, and deployment processes",
        "Manual work only",
        "Random tasks"
      ],
      "answer": 1,
      "explanation": "Pipelines automate entire software delivery workflow: code checkout, building, testing, security scanning, and deployment to various environments. Objective 5.3"
    },
    {
      "q": "Build automation compiles:",
      "options": [
        "Nothing",
        "Source code into executable artifacts automatically",
        "Manual compilation",
        "Documentation only"
      ],
      "answer": 1,
      "explanation": "Build automation compiles code, resolves dependencies, packages artifacts, and ensures consistent, repeatable builds without manual steps. Objective 5.3"
    },
    {
      "q": "Unit tests verify:",
      "options": [
        "Entire application",
        "Individual code units/functions work correctly in isolation",
        "Infrastructure",
        "Nothing"
      ],
      "answer": 1,
      "explanation": "Unit tests validate individual functions/methods in isolation, running quickly and frequently to catch logic errors early in development. Objective 5.3"
    },
    {
      "q": "Integration tests verify:",
      "options": [
        "Single functions",
        "Multiple components work together correctly",
        "Infrastructure only",
        "Nothing"
      ],
      "answer": 1,
      "explanation": "Integration tests validate interactions between components (application and database), ensuring modules integrate correctly. Objective 5.3"
    },
    {
      "q": "End-to-end tests validate:",
      "options": [
        "Single function",
        "Complete user workflows through entire application",
        "Code syntax",
        "Nothing"
      ],
      "answer": 1,
      "explanation": "E2E tests simulate real user scenarios testing entire application stack from UI to database, validating complete functionality. Objective 5.3"
    },
    {
      "q": "Smoke tests provide:",
      "options": [
        "Comprehensive testing",
        "Quick validation that basic functionality works after deployment",
        "No testing",
        "Only security"
      ],
      "answer": 1,
      "explanation": "Smoke tests quickly verify critical functionality works after deployment (app starts, key endpoints respond), catching major issues immediately. Objective 5.3"
    },
    {
      "q": "Code coverage measures:",
      "options": [
        "Code size",
        "Percentage of code executed by tests",
        "Only errors",
        "Deployment frequency"
      ],
      "answer": 1,
      "explanation": "Code coverage shows what percentage of code is tested, identifying untested paths that may contain undetected bugs. Objective 5.3"
    },
    {
      "q": "Static code analysis checks:",
      "options": [
        "Runtime behavior",
        "Code quality, style, and potential bugs without execution",
        "Performance only",
        "Nothing"
      ],
      "answer": 1,
      "explanation": "Static analysis examines code without running it, identifying style violations, potential bugs, security issues, and code smells. Objective 5.3"
    },
    {
      "q": "Security scanning in CI/CD should detect:",
      "options": [
        "Nothing",
        "Vulnerabilities, dependency issues, and security misconfigurations",
        "Only performance",
        "Code style"
      ],
      "answer": 1,
      "explanation": "Security scanning identifies vulnerable dependencies, security misconfigurations, secrets in code, and OWASP vulnerabilities before production. Objective 5.3"
    },
    {
      "q": "Artifact repositories store:",
      "options": [
        "Nothing",
        "Built packages, containers, and dependencies",
        "Source code only",
        "Logs only"
      ],
      "answer": 1,
      "explanation": "Artifact repositories (Artifactory, Nexus, ECR) store built artifacts, container images, libraries, and packages for versioning and deployment. Objective 5.3"
    },
    {
      "q": "Pipeline stages typically execute in:",
      "options": [
        "Random order",
        "Sequential order with gates between stages",
        "Parallel always",
        "No order"
      ],
      "answer": 1,
      "explanation": "Pipeline stages run sequentially (build \u2192 test \u2192 deploy), with each stage gating next; failures stop progression preventing bad code deployment. Objective 5.3"
    },
    {
      "q": "Deployment environments typically include:",
      "options": [
        "Production only",
        "Development, testing, staging, and production",
        "One environment",
        "No environments"
      ],
      "answer": 1,
      "explanation": "Multiple environments enable progressive testing: dev (rapid iteration), test (integration), staging (production-like validation), production (live users). Objective 5.3"
    },
    {
      "q": "Staging environment should:",
      "options": [
        "Differ from production",
        "Mirror production configuration as closely as possible",
        "Be much smaller",
        "Not exist"
      ],
      "answer": 1,
      "explanation": "Staging mirrors production (infrastructure, data, configuration) enabling realistic testing and catching environment-specific issues before production. Objective 5.3"
    },
    {
      "q": "Pipeline failure should:",
      "options": [
        "Continue anyway",
        "Stop progression and notify team for investigation",
        "Deploy automatically",
        "Be ignored"
      ],
      "answer": 1,
      "explanation": "Failed pipelines halt deployment, notify responsible teams, and provide failure details, preventing defective code from reaching production. Objective 5.3"
    },
    {
      "q": "Rollback automation enables:",
      "options": [
        "No rollback",
        "Quick reversion to previous version if issues arise",
        "Manual only",
        "Random versions"
      ],
      "answer": 1,
      "explanation": "Automated rollback quickly restores previous working version when deployment issues occur, minimizing downtime and user impact. Objective 5.3"
    },
    {
      "q": "Blue-green deployment maintains:",
      "options": [
        "Single environment",
        "Two identical environments for zero-downtime switching",
        "No environments",
        "Random setup"
      ],
      "answer": 1,
      "explanation": "Blue-green keeps two production environments; deploy to inactive, test, then switch traffic instantly with immediate rollback capability. Objective 5.3"
    },
    {
      "q": "Canary deployment gradually:",
      "options": [
        "Deploys to all at once",
        "Routes small traffic percentage to new version",
        "No deployment",
        "Deletes old version"
      ],
      "answer": 1,
      "explanation": "Canary releases new version to small user subset (5-10%), monitoring metrics before full rollout, limiting impact of issues. Objective 5.3"
    },
    {
      "q": "Feature flags allow:",
      "options": [
        "No features",
        "Enabling/disabling features without redeployment",
        "Only deletions",
        "Random behavior"
      ],
      "answer": 1,
      "explanation": "Feature flags toggle features at runtime, enabling gradual rollout, A/B testing, and instant disabling without code deployment. Objective 5.3"
    },
    {
      "q": "Deployment approval gates require:",
      "options": [
        "No approvals",
        "Manual authorization before critical stage progression",
        "Automatic always",
        "Random decision"
      ],
      "answer": 1,
      "explanation": "Approval gates require designated approvers to authorize progression to sensitive stages (production), adding human oversight. Objective 5.3"
    },
    {
      "q": "Pipeline notifications should inform:",
      "options": [
        "No one",
        "Relevant teams of build status, failures, and deployments",
        "Everyone always",
        "Random people"
      ],
      "answer": 1,
      "explanation": "Notifications alert appropriate teams (Slack, email, SMS) of pipeline status, failures, and deployment completions for rapid response. Objective 5.3"
    },
    {
      "q": "Build triggers can be:",
      "options": [
        "Nothing",
        "Code commits, schedules, manual starts, or other events",
        "Random only",
        "Never trigger"
      ],
      "answer": 1,
      "explanation": "Pipelines trigger on git commits, pull requests, schedules (nightly builds), manual requests, or external events (image updates). Objective 5.3"
    },
    {
      "q": "Pipeline as Code defines:",
      "options": [
        "No code",
        "Pipeline configuration in version-controlled files",
        "Manual GUI only",
        "Random setup"
      ],
      "answer": 1,
      "explanation": "Pipeline as Code (Jenkinsfile, GitLab CI YAML) version-controls pipeline definitions, enabling review, testing, and rollback of pipeline changes. Objective 5.3"
    },
    {
      "q": "Parallel execution in pipelines:",
      "options": [
        "Always sequential",
        "Runs independent stages simultaneously to reduce time",
        "Never parallel",
        "Random execution"
      ],
      "answer": 1,
      "explanation": "Parallelization runs independent tasks simultaneously (multiple test suites, different environments), significantly reducing total pipeline duration. Objective 5.3"
    },
    {
      "q": "Container images in CI/CD provide:",
      "options": [
        "No benefits",
        "Consistent runtime environment across pipeline stages",
        "Random environments",
        "No consistency"
      ],
      "answer": 1,
      "explanation": "Container images ensure identical runtime environment from build through production, eliminating works-on-my-machine issues. Objective 5.3"
    },
    {
      "q": "Deployment frequency in mature DevOps organizations is:",
      "options": [
        "Annually",
        "Multiple times per day",
        "Never",
        "Decades"
      ],
      "answer": 1,
      "explanation": "High-performing teams deploy multiple times daily through automated pipelines, small changes, and strong testing, reducing risk and improving velocity. Objective 5.3"
    },
    {
      "q": "Lead time for changes measures:",
      "options": [
        "Nothing",
        "Time from code commit to production deployment",
        "Only development time",
        "Random duration"
      ],
      "answer": 1,
      "explanation": "Lead time tracks duration from commit to production, indicating efficiency of delivery process and automation maturity. Objective 5.3"
    },
    {
      "q": "Mean time to recovery (MTTR) measures:",
      "options": [
        "Development speed",
        "Time to restore service after failure",
        "Build time only",
        "No measurement"
      ],
      "answer": 1,
      "explanation": "MTTR measures how quickly teams detect, respond to, and recover from failures, indicating incident response effectiveness. Objective 5.3"
    },
    {
      "q": "Change failure rate tracks:",
      "options": [
        "All changes",
        "Percentage of deployments causing failures",
        "No failures",
        "Random events"
      ],
      "answer": 1,
      "explanation": "Change failure rate measures deployment quality by tracking percentage requiring remediation (hotfix, rollback, patch), indicating testing effectiveness. Objective 5.3"
    },
    {
      "q": "Infrastructure testing in pipelines validates:",
      "options": [
        "Only code",
        "Infrastructure configuration and provisioning",
        "Nothing",
        "Manual only"
      ],
      "answer": 1,
      "explanation": "Infrastructure testing validates IaC provisions correctly, configurations are secure, and compliance requirements are met before deployment. Objective 5.3"
    },
    {
      "q": "Database migration in CI/CD should:",
      "options": [
        "Manual only",
        "Be automated, versioned, and tested with rollback capability",
        "Never migrate",
        "Random changes"
      ],
      "answer": 1,
      "explanation": "Database migrations are versioned, tested in pipeline, applied automatically during deployment with rollback scripts for failures. Objective 5.3"
    },
    {
      "q": "Pipeline caching improves:",
      "options": [
        "Nothing",
        "Build speed by reusing dependencies and artifacts",
        "Slows builds",
        "No impact"
      ],
      "answer": 1,
      "explanation": "Caching stores dependencies, build artifacts, and intermediate results, avoiding redundant downloads/builds and significantly speeding pipelines. Objective 5.3"
    },
    {
      "q": "GitOps manages infrastructure by:",
      "options": [
        "Manual changes",
        "Using Git as single source of truth for declarative infrastructure",
        "Random changes",
        "No version control"
      ],
      "answer": 1,
      "explanation": "GitOps stores desired infrastructure state in Git; automated systems continuously reconcile actual state with Git, enabling auditable infrastructure changes. Objective 5.3"
    },
    {
      "q": "Orchestration differs from automation by:",
      "options": [
        "No difference",
        "Coordinating multiple automated tasks into workflows",
        "Single task focus",
        "Manual only"
      ],
      "answer": 1,
      "explanation": "Automation handles individual tasks; orchestration coordinates multiple automated tasks across systems in specific sequence for complex workflows. Objective 5.4"
    },
    {
      "q": "Workflow automation sequences:",
      "options": [
        "Nothing",
        "Multiple tasks in defined order with dependencies",
        "Single task only",
        "Random execution"
      ],
      "answer": 1,
      "explanation": "Workflows define task sequences, dependencies, conditions, and error handling, automating complex multi-step processes across systems. Objective 5.4"
    },
    {
      "q": "Event-driven automation triggers when:",
      "options": [
        "Never",
        "Specific events occur in infrastructure or applications",
        "Scheduled only",
        "Manual only"
      ],
      "answer": 1,
      "explanation": "Event-driven automation responds to events (alerts, resource changes, log patterns), executing responses automatically without human intervention. Objective 5.4"
    },
    {
      "q": "Runbooks provide:",
      "options": [
        "Nothing",
        "Documented procedures for operational tasks",
        "Random instructions",
        "No documentation"
      ],
      "answer": 1,
      "explanation": "Runbooks document step-by-step procedures for routine operations, troubleshooting, and incident response, enabling consistent execution and automation. Objective 5.4"
    },
    {
      "q": "Automated remediation responds to:",
      "options": [
        "Nothing",
        "Known issues by executing predefined corrective actions",
        "Random events",
        "Manual intervention only"
      ],
      "answer": 1,
      "explanation": "Auto-remediation detects issues (service down, high CPU) and automatically executes fixes (restart service, scale resources) without human involvement. Objective 5.4"
    },
    {
      "q": "Self-healing infrastructure automatically:",
      "options": [
        "Breaks systems",
        "Detects and recovers from failures without intervention",
        "Requires manual fixes",
        "No recovery"
      ],
      "answer": 1,
      "explanation": "Self-healing systems detect failures, automatically replace failed components, and restore service without human intervention, improving reliability. Objective 5.4"
    },
    {
      "q": "Chaos engineering intentionally:",
      "options": [
        "Fixes everything",
        "Introduces failures to test system resilience",
        "Avoids all issues",
        "Manual testing only"
      ],
      "answer": 1,
      "explanation": "Chaos engineering deliberately injects failures (instance termination, network latency) to validate resilience, identify weaknesses, and improve recovery. Objective 5.4"
    },
    {
      "q": "API-driven automation enables:",
      "options": [
        "Manual work only",
        "Programmatic control of infrastructure and services",
        "No automation",
        "Random actions"
      ],
      "answer": 1,
      "explanation": "APIs enable programmatic infrastructure management, integration between systems, and building custom automation tools and workflows. Objective 5.4"
    },
    {
      "q": "Scheduled automation executes tasks:",
      "options": [
        "Randomly",
        "At predefined times or intervals",
        "Never",
        "Only manually"
      ],
      "answer": 1,
      "explanation": "Scheduled automation runs tasks at specific times (cron jobs, scheduled scaling) for maintenance, backups, reports, and predictable operations. Objective 5.4"
    },
    {
      "q": "Automation testing validates:",
      "options": [
        "Nothing",
        "Automation scripts work correctly and handle errors",
        "Manual steps only",
        "No validation"
      ],
      "answer": 1,
      "explanation": "Automation scripts require testing for correctness, idempotency, error handling, and edge cases before production use to prevent automated failures. Objective 5.4"
    },
    {
      "q": "Monitoring-driven automation uses:",
      "options": [
        "No data",
        "Metrics and alerts to trigger automated responses",
        "Manual decisions only",
        "Random triggers"
      ],
      "answer": 1,
      "explanation": "Monitoring data triggers automation (high CPU scales out, failed health check replaces instance), creating feedback loops for optimization. Objective 5.4"
    },
    {
      "q": "Automation scope should be:",
      "options": [
        "Automate everything immediately",
        "Gradually expanded based on value and risk",
        "Never automate",
        "Random selection"
      ],
      "answer": 1,
      "explanation": "Start automating high-value, low-risk tasks; gradually expand to complex operations after gaining confidence and refining processes. Objective 5.4"
    },
    {
      "q": "Automation documentation should include:",
      "options": [
        "Nothing",
        "Purpose, triggers, actions, error handling, and dependencies",
        "Only code",
        "No documentation"
      ],
      "answer": 1,
      "explanation": "Document automation purpose, trigger conditions, executed actions, error handling, dependencies, and runbook references for team understanding. Objective 5.4"
    },
    {
      "q": "Exception handling in automation should:",
      "options": [
        "Crash scripts",
        "Gracefully handle errors and notify appropriate teams",
        "Ignore errors",
        "Delete everything"
      ],
      "answer": 1,
      "explanation": "Robust automation includes error handling, logging, notifications, and graceful degradation preventing cascading failures from automation errors. Objective 5.4"
    },
    {
      "q": "Immutable infrastructure automation:",
      "options": [
        "Updates servers in place",
        "Replaces entire servers rather than updating them",
        "Manual updates",
        "Never changes"
      ],
      "answer": 1,
      "explanation": "Immutable infrastructure automation deploys new servers with updated configuration rather than modifying existing ones, ensuring consistency and enabling rollback. Objective 5.4"
    }
  ],
  "6. Troubleshooting": [
    {
      "q": "The first step in troubleshooting methodology is:",
      "options": [
        "Apply solution immediately",
        "Identify the problem and gather information",
        "Reboot everything",
        "Escalate to management"
      ],
      "answer": 1,
      "explanation": "Troubleshooting begins with identifying problem symptoms, gathering information about when it started, affected systems, and recent changes before jumping to solutions. Objective 6.1"
    },
    {
      "q": "After identifying the problem, the next step is:",
      "options": [
        "Random fixes",
        "Establish a theory of probable cause",
        "Give up",
        "Reboot server"
      ],
      "answer": 1,
      "explanation": "After gathering information, establish theories about the cause based on symptoms, starting with most likely/simplest explanations before complex ones. Objective 6.1"
    },
    {
      "q": "Before implementing a solution, you should:",
      "options": [
        "Just do it",
        "Test the theory and establish an action plan",
        "Delete everything",
        "Ignore the plan"
      ],
      "answer": 1,
      "explanation": "Test theories in non-production when possible, develop action plan with steps and rollback procedures before implementing in production. Objective 6.1"
    },
    {
      "q": "After implementing a fix, you should:",
      "options": [
        "Move on immediately",
        "Verify functionality and prevent recurrence",
        "Delete logs",
        "No follow-up needed"
      ],
      "answer": 1,
      "explanation": "Verify the fix resolves the issue, ensure no side effects, document the solution, and implement preventive measures to avoid recurrence. Objective 6.1"
    },
    {
      "q": "Documentation in troubleshooting should include:",
      "options": [
        "Nothing",
        "Problem, cause, solution, and prevention steps",
        "Only time spent",
        "Random notes"
      ],
      "answer": 1,
      "explanation": "Document problem symptoms, root cause, solution implemented, verification results, and preventive measures for knowledge sharing and future reference. Objective 6.1"
    },
    {
      "q": "When should you escalate an issue?",
      "options": [
        "Immediately always",
        "When beyond your expertise or requires higher authority",
        "Never escalate",
        "After weeks of trying"
      ],
      "answer": 1,
      "explanation": "Escalate when problem exceeds your skill/authority, requires vendor support, impacts business significantly, or after reasonable troubleshooting attempts. Objective 6.1"
    },
    {
      "q": "Recent changes are important because:",
      "options": [
        "Not relevant",
        "They often correlate with new problems",
        "Random information",
        "Only for documentation"
      ],
      "answer": 1,
      "explanation": "Recent changes (deployments, configurations, updates) frequently cause issues; identifying timing correlation helps pinpoint root cause quickly. Objective 6.1"
    },
    {
      "q": "Isolating the problem involves:",
      "options": [
        "Testing everything",
        "Narrowing scope to identify affected components",
        "Random testing",
        "No isolation needed"
      ],
      "answer": 1,
      "explanation": "Isolation determines which components are affected vs working, reducing scope and focusing troubleshooting efforts on relevant systems. Objective 6.1"
    },
    {
      "q": "The divide-and-conquer approach:",
      "options": [
        "Tests randomly",
        "Systematically eliminates half of possibilities each test",
        "Tests everything",
        "No strategy"
      ],
      "answer": 1,
      "explanation": "Divide-and-conquer tests middle of system to eliminate half possibilities each iteration, efficiently narrowing down problem location. Objective 6.1"
    },
    {
      "q": "Multiple simultaneous changes during troubleshooting:",
      "options": [
        "Speed up resolution",
        "Make it unclear which change fixed the issue",
        "Always best",
        "No impact"
      ],
      "answer": 1,
      "explanation": "Change one variable at a time so you know exactly what fixed the issue, enabling proper documentation and understanding of root cause. Objective 6.1"
    },
    {
      "q": "Reproducing the problem helps:",
      "options": [
        "Waste time",
        "Validate theories and verify solutions",
        "Create more issues",
        "No benefit"
      ],
      "answer": 1,
      "explanation": "Reproducing issues validates understanding, tests theories, and confirms solutions actually fix the problem rather than coincidental timing. Objective 6.1"
    },
    {
      "q": "When initial theory is disproven, you should:",
      "options": [
        "Give up",
        "Develop new theory based on new information",
        "Implement anyway",
        "Escalate immediately"
      ],
      "answer": 1,
      "explanation": "If theory is disproven, gather additional information, reassess symptoms, and develop new theory based on expanded understanding. Objective 6.1"
    },
    {
      "q": "Baseline configurations help troubleshooting by:",
      "options": [
        "No help",
        "Providing comparison point to identify deviations",
        "Slowing process",
        "Only documentation"
      ],
      "answer": 1,
      "explanation": "Baselines show known-good state; comparing current to baseline quickly identifies configuration drift or changes causing issues. Objective 6.1"
    },
    {
      "q": "Post-implementation review should:",
      "options": [
        "Skip it",
        "Analyze what happened and improve processes",
        "Blame individuals",
        "Ignore lessons"
      ],
      "answer": 1,
      "explanation": "Post-mortems identify root cause, improve processes, document lessons learned, and implement preventive measures without blame. Objective 6.1"
    },
    {
      "q": "Troubleshooting in production requires:",
      "options": [
        "No caution",
        "Extra care, change control, and rollback plans",
        "Random changes",
        "No planning"
      ],
      "answer": 1,
      "explanation": "Production troubleshooting requires change approval, communication, rollback plans, and careful testing to avoid making problems worse. Objective 6.1"
    },
    {
      "q": "If ping fails but telnet to port 80 succeeds, the issue is likely:",
      "options": [
        "Total network failure",
        "ICMP blocked but TCP working",
        "DNS failure",
        "Everything broken"
      ],
      "answer": 1,
      "explanation": "Successful TCP connection (telnet) but failed ping indicates ICMP protocol is blocked by firewall while TCP traffic passes normally. Objective 6.2"
    },
    {
      "q": "DNS resolution failure results in:",
      "options": [
        "Successful connections",
        "Inability to resolve names to IP addresses",
        "Faster connections",
        "No impact"
      ],
      "answer": 1,
      "explanation": "DNS issues prevent hostname resolution but direct IP connections may work, indicating name resolution rather than network connectivity problem. Objective 6.2"
    },
    {
      "q": "To test DNS specifically, use:",
      "options": [
        "ping only",
        "nslookup or dig commands",
        "telnet",
        "ssh"
      ],
      "answer": 1,
      "explanation": "nslookup and dig query DNS servers directly, showing resolution results, response times, and authoritative servers for DNS troubleshooting. Objective 6.2"
    },
    {
      "q": "Intermittent connectivity often indicates:",
      "options": [
        "Total failure",
        "Network congestion, failing hardware, or load balancer issues",
        "Everything perfect",
        "DNS problems"
      ],
      "answer": 1,
      "explanation": "Intermittent issues suggest capacity problems, degrading hardware, packet loss, or load balancing problems rather than complete failures. Objective 6.2"
    },
    {
      "q": "Traceroute shows:",
      "options": [
        "DNS records",
        "Network path and latency to each hop",
        "Open ports",
        "Disk usage"
      ],
      "answer": 1,
      "explanation": "Traceroute displays each router hop between source and destination with response times, identifying where delays or failures occur. Objective 6.2"
    },
    {
      "q": "Security group misconfiguration typically causes:",
      "options": [
        "Slow performance",
        "Blocked connections even with network connectivity",
        "No impact",
        "DNS issues"
      ],
      "answer": 1,
      "explanation": "Security groups block specific ports/protocols at instance level; incorrect rules prevent connections even when network path is valid. Objective 6.2"
    },
    {
      "q": "Network ACL issues differ from security groups by:",
      "options": [
        "No difference",
        "ACLs are stateless and affect entire subnet",
        "Only protocol",
        "No impact"
      ],
      "answer": 1,
      "explanation": "Network ACLs operate at subnet level with stateless rules requiring explicit inbound and outbound rules, unlike stateful security groups. Objective 6.2"
    },
    {
      "q": "If connection times out rather than being refused:",
      "options": [
        "Port is open",
        "Firewall is dropping packets or service not listening",
        "DNS issue",
        "Perfect connection"
      ],
      "answer": 1,
      "explanation": "Timeout suggests packets aren't reaching destination (firewall drop) or no service listening; refused means connection reached but was rejected. Objective 6.2"
    },
    {
      "q": "Connection refused error indicates:",
      "options": [
        "Firewall block",
        "Connection reached destination but port is closed",
        "DNS failure",
        "Network down"
      ],
      "answer": 1,
      "explanation": "Connection refused means packets reached host but no service listening on that port, indicating service or configuration issue. Objective 6.2"
    },
    {
      "q": "Routing table issues cause:",
      "options": [
        "Fast connections",
        "Packets sent to wrong destination or dropped",
        "No impact",
        "DNS problems"
      ],
      "answer": 1,
      "explanation": "Incorrect routing tables misdirect traffic to wrong paths or drop packets when no route exists to destination network. Objective 6.2"
    },
    {
      "q": "Subnet mask misconfiguration results in:",
      "options": [
        "Perfect networking",
        "Incorrect network/host boundaries and routing",
        "Faster speeds",
        "No issues"
      ],
      "answer": 1,
      "explanation": "Wrong subnet masks cause systems to misidentify local vs remote hosts, sending traffic incorrectly to router or attempting direct connections. Objective 6.2"
    },
    {
      "q": "To verify listening ports on a server, use:",
      "options": [
        "ping",
        "netstat or ss commands",
        "traceroute",
        "nslookup"
      ],
      "answer": 1,
      "explanation": "netstat -an or ss -tuln show listening ports, active connections, and bound addresses for service verification and troubleshooting. Objective 6.2"
    },
    {
      "q": "MTU mismatch can cause:",
      "options": [
        "No issues",
        "Packet fragmentation or connection failures",
        "Faster speeds",
        "DNS problems"
      ],
      "answer": 1,
      "explanation": "MTU mismatches cause fragmentation or black hole scenarios where large packets are dropped, affecting specific applications differently. Objective 6.2"
    },
    {
      "q": "Asymmetric routing may cause:",
      "options": [
        "Better performance",
        "Stateful firewall drops or inspection issues",
        "No impact",
        "Faster connections"
      ],
      "answer": 1,
      "explanation": "Asymmetric routing (forward and return paths differ) causes problems with stateful firewalls expecting both directions through same path. Objective 6.2"
    },
    {
      "q": "VPN connectivity issues often involve:",
      "options": [
        "Only speed",
        "Authentication, encryption, routing, or firewall rules",
        "No common issues",
        "DNS only"
      ],
      "answer": 1,
      "explanation": "VPN problems stem from authentication failures, encryption mismatches, incorrect routing tables, or firewall blocking VPN protocols/ports. Objective 6.2"
    },
    {
      "q": "Load balancer health check failures result in:",
      "options": [
        "Better distribution",
        "Instances removed from rotation",
        "No impact",
        "Faster responses"
      ],
      "answer": 1,
      "explanation": "Failed health checks cause load balancers to stop routing traffic to unhealthy instances, potentially causing capacity issues if widespread. Objective 6.2"
    },
    {
      "q": "Peering connection issues between VPCs can involve:",
      "options": [
        "No issues",
        "Route table configurations or overlapping CIDR blocks",
        "Only speed",
        "DNS only"
      ],
      "answer": 1,
      "explanation": "VPC peering requires non-overlapping CIDR blocks and route table entries in both VPCs pointing to peering connection. Objective 6.2"
    },
    {
      "q": "NAT gateway problems affect:",
      "options": [
        "Internal communication",
        "Outbound internet connectivity from private subnets",
        "Nothing",
        "Inbound only"
      ],
      "answer": 1,
      "explanation": "NAT gateway failures prevent private subnet resources from initiating outbound internet connections while not affecting inbound or internal traffic. Objective 6.2"
    },
    {
      "q": "Internet gateway issues impact:",
      "options": [
        "Internal only",
        "Public internet connectivity to/from VPC",
        "Private subnets",
        "No connectivity"
      ],
      "answer": 1,
      "explanation": "Internet gateway problems affect all internet-bound traffic; resources can't reach internet and internet can't reach public IPs in VPC. Objective 6.2"
    },
    {
      "q": "Bandwidth saturation causes:",
      "options": [
        "Better performance",
        "Packet loss, high latency, and slow transfers",
        "No impact",
        "Faster speeds"
      ],
      "answer": 1,
      "explanation": "Saturated bandwidth causes queuing delays, packet drops, and degraded performance for all traffic competing for limited capacity. Objective 6.2"
    },
    {
      "q": "High CPU utilization may indicate:",
      "options": [
        "Perfect health",
        "Insufficient capacity, inefficient code, or runaway processes",
        "Low usage",
        "Nothing"
      ],
      "answer": 1,
      "explanation": "Sustained high CPU suggests undersized instances, inefficient algorithms, memory leaks causing excessive GC, or runaway processes consuming resources. Objective 6.3"
    },
    {
      "q": "Memory pressure symptoms include:",
      "options": [
        "Fast performance",
        "High swap usage, OOM errors, and application crashes",
        "No impact",
        "Better caching"
      ],
      "answer": 1,
      "explanation": "Memory exhaustion causes swapping (severe slowdown), out-of-memory kills, application crashes, and system instability. Objective 6.3"
    },
    {
      "q": "Disk I/O bottlenecks manifest as:",
      "options": [
        "CPU issues",
        "High latency, queue depths, and slow response times",
        "Network problems",
        "No symptoms"
      ],
      "answer": 1,
      "explanation": "Storage bottlenecks show high IOPS utilization, queue depths, elevated latency, and slow application response times for disk operations. Objective 6.3"
    },
    {
      "q": "Network latency issues affect:",
      "options": [
        "Only local operations",
        "Distributed applications and user experience",
        "Disk only",
        "Nothing"
      ],
      "answer": 1,
      "explanation": "High latency increases response times, particularly impacting chatty applications, microservices, and geographically distributed systems. Objective 6.3"
    },
    {
      "q": "Database query performance issues often result from:",
      "options": [
        "Too much memory",
        "Missing indexes, poor query design, or lock contention",
        "Perfect optimization",
        "No issues"
      ],
      "answer": 1,
      "explanation": "Slow queries stem from missing indexes, inefficient query patterns, full table scans, locking, or outdated statistics. Objective 6.3"
    },
    {
      "q": "Application response time degradation could indicate:",
      "options": [
        "Everything perfect",
        "Resource constraints, code issues, or dependency problems",
        "Better performance",
        "No issues"
      ],
      "answer": 1,
      "explanation": "Degraded response times suggest resource saturation, inefficient code, external dependency slowness, or increasing data volumes. Objective 6.3"
    },
    {
      "q": "Memory leaks gradually cause:",
      "options": [
        "Better performance",
        "Increasing memory usage until exhaustion and crashes",
        "Freed memory",
        "No impact"
      ],
      "answer": 1,
      "explanation": "Memory leaks progressively consume memory as applications fail to release allocated memory, eventually causing OOM errors and crashes. Objective 6.3"
    },
    {
      "q": "Caching can improve performance by:",
      "options": [
        "Slowing requests",
        "Reducing database queries and external API calls",
        "Increasing latency",
        "No benefit"
      ],
      "answer": 1,
      "explanation": "Caching stores frequently accessed data in fast storage (Redis, Memcached), reducing expensive database/API calls and improving response times. Objective 6.3"
    },
    {
      "q": "N+1 query problem causes:",
      "options": [
        "Better performance",
        "Excessive database queries degrading performance",
        "Fewer queries",
        "No impact"
      ],
      "answer": 1,
      "explanation": "N+1 queries execute one query for list then separate queries for each item, causing hundreds of queries where one would suffice. Objective 6.3"
    },
    {
      "q": "Connection pool exhaustion results in:",
      "options": [
        "Faster connections",
        "Applications unable to get database connections",
        "More connections",
        "No impact"
      ],
      "answer": 1,
      "explanation": "Exhausted connection pools cause applications to wait or fail when requesting database connections, degrading performance or causing errors. Objective 6.3"
    },
    {
      "q": "Proper instance sizing requires considering:",
      "options": [
        "Random selection",
        "CPU, memory, network, storage needs, and growth",
        "Smallest always",
        "Largest always"
      ],
      "answer": 1,
      "explanation": "Right-sizing analyzes workload requirements across all dimensions (CPU, RAM, network, IOPS) plus growth projections for optimal cost-performance. Objective 6.3"
    },
    {
      "q": "Auto-scaling helps performance by:",
      "options": [
        "Reducing capacity",
        "Adding resources during demand spikes",
        "Fixed capacity only",
        "No impact"
      ],
      "answer": 1,
      "explanation": "Auto-scaling dynamically adds capacity during high demand and removes it during low demand, maintaining performance while optimizing costs. Objective 6.3"
    },
    {
      "q": "Load balancer algorithms distribute traffic based on:",
      "options": [
        "Random only",
        "Round-robin, least connections, or response time",
        "No distribution",
        "Single server"
      ],
      "answer": 1,
      "explanation": "Algorithms like round-robin, least connections, IP hash, or least response time distribute requests optimizing for different scenarios. Objective 6.3"
    },
    {
      "q": "CDN usage improves performance by:",
      "options": [
        "Centralizing content",
        "Caching content closer to users geographically",
        "Slowing delivery",
        "No benefit"
      ],
      "answer": 1,
      "explanation": "CDNs cache static content at edge locations worldwide, reducing latency by serving users from geographically nearby servers. Objective 6.3"
    },
    {
      "q": "Database read replicas improve:",
      "options": [
        "Write performance",
        "Read scalability by distributing queries",
        "Nothing",
        "Write capacity only"
      ],
      "answer": 1,
      "explanation": "Read replicas offload read queries from primary database, improving read scalability and performance while primary handles writes. Objective 6.3"
    },
    {
      "q": "Index fragmentation causes:",
      "options": [
        "Better performance",
        "Degraded query performance over time",
        "Faster queries",
        "No impact"
      ],
      "answer": 1,
      "explanation": "Fragmented indexes require more I/O operations to traverse, degrading query performance; regular maintenance rebuilds indexes for optimal structure. Objective 6.3"
    },
    {
      "q": "API rate limiting prevents:",
      "options": [
        "All requests",
        "Single clients from overwhelming service",
        "Performance issues",
        "No purpose"
      ],
      "answer": 1,
      "explanation": "Rate limiting protects services from abuse or unintentional overload by restricting request rates per client, maintaining performance for all. Objective 6.3"
    },
    {
      "q": "Monitoring 95th percentile latency shows:",
      "options": [
        "Average only",
        "Performance experienced by most users excluding outliers",
        "Worst case",
        "Best case"
      ],
      "answer": 1,
      "explanation": "P95 latency indicates 95% of requests complete within this time, better representing typical user experience than average (affected by outliers). Objective 6.3"
    },
    {
      "q": "Thread pool sizing affects:",
      "options": [
        "Nothing",
        "Concurrent request handling capacity",
        "Disk space",
        "Network only"
      ],
      "answer": 1,
      "explanation": "Thread pool size determines concurrent processing capacity; too small limits throughput, too large causes overhead and resource contention. Objective 6.3"
    },
    {
      "q": "Async processing improves performance by:",
      "options": [
        "Slowing responses",
        "Not blocking on long-running operations",
        "Synchronous only",
        "No benefit"
      ],
      "answer": 1,
      "explanation": "Asynchronous processing queues long operations (email, reports) and returns immediately, improving response times and resource utilization. Objective 6.3"
    },
    {
      "q": "Database connection timeout issues suggest:",
      "options": [
        "Perfect performance",
        "Database overload or network problems",
        "Fast queries",
        "Nothing"
      ],
      "answer": 1,
      "explanation": "Connection timeouts indicate database can't accept connections (overloaded, max connections reached) or network connectivity issues. Objective 6.3"
    },
    {
      "q": "Static content compression reduces:",
      "options": [
        "Transfer speed",
        "Bandwidth usage and transfer time",
        "Performance",
        "File quality"
      ],
      "answer": 1,
      "explanation": "Gzip/Brotli compression reduces file sizes significantly, decreasing bandwidth consumption and accelerating page load times. Objective 6.3"
    },
    {
      "q": "Session affinity (sticky sessions) may be needed when:",
      "options": [
        "Stateless apps",
        "Applications store session data locally",
        "No sessions",
        "Distributed cache"
      ],
      "answer": 1,
      "explanation": "Sticky sessions route users to same instance when applications store session data locally rather than in shared store. Objective 6.3"
    },
    {
      "q": "Microservices performance issues often involve:",
      "options": [
        "Single point",
        "Service-to-service communication overhead and latency",
        "No communication",
        "Perfect performance"
      ],
      "answer": 1,
      "explanation": "Microservices introduce network latency for inter-service calls; proper service mesh, caching, and async patterns mitigate this. Objective 6.3"
    },
    {
      "q": "Container resource limits prevent:",
      "options": [
        "All usage",
        "Single container consuming all host resources",
        "Performance",
        "Nothing"
      ],
      "answer": 1,
      "explanation": "CPU and memory limits prevent noisy neighbor problems where one container starves others of resources on shared host. Objective 6.3"
    },
    {
      "q": "Unauthorized access attempts should trigger:",
      "options": [
        "No action",
        "Security alerts and investigation",
        "Ignore completely",
        "Disable monitoring"
      ],
      "answer": 1,
      "explanation": "Failed authentication attempts, especially multiple rapid attempts, indicate potential brute force attacks requiring investigation and response. Objective 6.4"
    },
    {
      "q": "Compromised credentials typically lead to:",
      "options": [
        "Nothing",
        "Unauthorized access and potential data breaches",
        "Better security",
        "No risk"
      ],
      "answer": 1,
      "explanation": "Stolen credentials enable attackers to access systems legitimately, bypass security controls, and exfiltrate data or deploy malware. Objective 6.4"
    },
    {
      "q": "Certificate validation errors indicate:",
      "options": [
        "Perfect security",
        "Expired, invalid, or untrusted certificates",
        "No issues",
        "Better encryption"
      ],
      "answer": 1,
      "explanation": "Certificate errors suggest expiration, self-signed certs, hostname mismatch, or untrusted CA, preventing secure encrypted connections. Objective 6.4"
    },
    {
      "q": "Unusual outbound traffic may indicate:",
      "options": [
        "Normal operations",
        "Data exfiltration or command-and-control communication",
        "Better performance",
        "Nothing"
      ],
      "answer": 1,
      "explanation": "Unexpected outbound connections, especially to unusual destinations or ports, suggest compromised systems communicating with attackers. Objective 6.4"
    },
    {
      "q": "IAM permission issues cause:",
      "options": [
        "No impact",
        "Access denied errors for legitimate operations",
        "Better security always",
        "Performance issues"
      ],
      "answer": 1,
      "explanation": "Overly restrictive IAM policies prevent authorized actions; too permissive policies create security risks - proper balance required. Objective 6.4"
    },
    {
      "q": "Encryption in transit failures result in:",
      "options": [
        "Better performance",
        "Unencrypted data transmission exposing sensitive information",
        "Faster speeds",
        "No issues"
      ],
      "answer": 1,
      "explanation": "Missing TLS/SSL encryption exposes data to interception on network, violating compliance and enabling man-in-middle attacks. Objective 6.4"
    },
    {
      "q": "Security group rules should follow:",
      "options": [
        "Allow all traffic",
        "Principle of least privilege",
        "Block everything",
        "Random rules"
      ],
      "answer": 1,
      "explanation": "Security groups should allow only necessary traffic to/from specific sources on required ports, minimizing attack surface. Objective 6.4"
    },
    {
      "q": "Public S3 buckets with sensitive data represent:",
      "options": [
        "Best practice",
        "Critical security misconfiguration and data exposure",
        "Performance optimization",
        "No issue"
      ],
      "answer": 1,
      "explanation": "Publicly accessible buckets with sensitive data cause data breaches; proper bucket policies and ACLs are essential for data protection. Objective 6.4"
    },
    {
      "q": "Failed MFA challenges indicate:",
      "options": [
        "No issue",
        "Potential unauthorized access attempts",
        "User error only",
        "Better security"
      ],
      "answer": 1,
      "explanation": "Multiple failed MFA attempts suggest attackers have passwords but not second factor, warranting investigation and potential account lockout. Objective 6.4"
    },
    {
      "q": "Privilege escalation attacks attempt to:",
      "options": [
        "Reduce access",
        "Gain higher-level permissions than authorized",
        "Improve security",
        "Nothing"
      ],
      "answer": 1,
      "explanation": "Privilege escalation exploits vulnerabilities or misconfigurations to gain administrative access from regular user accounts. Objective 6.4"
    },
    {
      "q": "API authentication failures could result from:",
      "options": [
        "Perfect security",
        "Invalid keys, expired tokens, or incorrect permissions",
        "No authentication",
        "Better performance"
      ],
      "answer": 1,
      "explanation": "API authentication fails due to invalid/expired keys, incorrect token format, missing permissions, or revoked credentials. Objective 6.4"
    },
    {
      "q": "Ransomware attacks typically:",
      "options": [
        "Improve security",
        "Encrypt data and demand payment for decryption",
        "Delete nothing",
        "No impact"
      ],
      "answer": 1,
      "explanation": "Ransomware encrypts victim data making it inaccessible, demanding ransom payment; requires robust backups and security controls for prevention. Objective 6.4"
    },
    {
      "q": "SQL injection vulnerabilities allow attackers to:",
      "options": [
        "Nothing",
        "Execute arbitrary database queries",
        "Improve performance",
        "Enhance security"
      ],
      "answer": 1,
      "explanation": "SQL injection exploits inadequate input validation, enabling attackers to execute malicious queries, access data, or modify databases. Objective 6.4"
    },
    {
      "q": "Cross-site scripting (XSS) enables:",
      "options": [
        "Better security",
        "Injecting malicious scripts into web pages",
        "Performance gains",
        "Nothing"
      ],
      "answer": 1,
      "explanation": "XSS injects malicious JavaScript into pages viewed by other users, stealing cookies, credentials, or performing actions as victim. Objective 6.4"
    },
    {
      "q": "Security audit logs should be:",
      "options": [
        "Deleted immediately",
        "Protected from modification and retained appropriately",
        "Public",
        "Ignored"
      ],
      "answer": 1,
      "explanation": "Audit logs require protection against tampering, appropriate retention periods, and monitoring to support investigations and compliance. Objective 6.4"
    },
    {
      "q": "Insider threats are difficult because:",
      "options": [
        "They don't exist",
        "Authorized users with legitimate access misuse privileges",
        "Easy to detect",
        "No risk"
      ],
      "answer": 1,
      "explanation": "Insider threats exploit legitimate access making detection harder; require monitoring user behavior, access patterns, and data exfiltration. Objective 6.4"
    },
    {
      "q": "Zero-day vulnerabilities are dangerous because:",
      "options": [
        "Already patched",
        "No patch available and actively exploited",
        "Well-known",
        "Low risk"
      ],
      "answer": 1,
      "explanation": "Zero-days have no vendor patches available yet; organizations must use compensating controls (WAF, IPS, segmentation) until patches release. Objective 6.4"
    },
    {
      "q": "Security incident response should include:",
      "options": [
        "Ignore incidents",
        "Containment, eradication, recovery, and lessons learned",
        "Delete everything",
        "No response"
      ],
      "answer": 1,
      "explanation": "Incident response contains threat spread, eradicates attacker presence, recovers systems, and documents lessons for improvement. Objective 6.4"
    },
    {
      "q": "Security group rules showing 0.0.0.0/0 should be:",
      "options": [
        "Always used",
        "Carefully reviewed as they allow all sources",
        "Ignored",
        "Preferred"
      ],
      "answer": 1,
      "explanation": "0.0.0.0/0 allows traffic from anywhere on internet; should be restricted to specific sources except for intended public services. Objective 6.4"
    },
    {
      "q": "Failed deployments often result from:",
      "options": [
        "Perfect code",
        "Dependency conflicts, configuration errors, or resource constraints",
        "No issues",
        "Better performance"
      ],
      "answer": 1,
      "explanation": "Deployment failures stem from missing dependencies, configuration mismatches between environments, insufficient resources, or breaking changes. Objective 6.5"
    },
    {
      "q": "Version mismatch issues occur when:",
      "options": [
        "Versions match",
        "Incompatible component versions are deployed together",
        "Everything updated",
        "No versions"
      ],
      "answer": 1,
      "explanation": "Incompatible library, API, or service versions cause integration failures; version pinning and testing prevent mismatches. Objective 6.5"
    },
    {
      "q": "Configuration drift between environments causes:",
      "options": [
        "Identical behavior",
        "Works in test but fails in production scenarios",
        "Better reliability",
        "No issues"
      ],
      "answer": 1,
      "explanation": "Environment differences (configs, dependencies, resources) cause code working in dev/test to fail in production unexpectedly. Objective 6.5"
    },
    {
      "q": "Rollback procedures should be:",
      "options": [
        "Never planned",
        "Tested and documented before deployment",
        "Improvised",
        "Ignored"
      ],
      "answer": 1,
      "explanation": "Pre-tested rollback procedures enable quick recovery from failed deployments, minimizing downtime and user impact. Objective 6.5"
    },
    {
      "q": "Deployment health checks verify:",
      "options": [
        "Nothing",
        "Application functionality after deployment",
        "Only startup",
        "Disk space"
      ],
      "answer": 1,
      "explanation": "Post-deployment health checks validate application responds correctly, dependencies work, and no regressions before routing traffic. Objective 6.5"
    },
    {
      "q": "Container image issues may involve:",
      "options": [
        "Perfect images",
        "Wrong base image, missing dependencies, or outdated versions",
        "No problems",
        "Better performance"
      ],
      "answer": 1,
      "explanation": "Container problems include wrong base OS, missing libraries, incorrect versions, or vulnerabilities in base images. Objective 6.5"
    },
    {
      "q": "Infrastructure provisioning failures could result from:",
      "options": [
        "Perfect templates",
        "Resource limits, quotas, or syntax errors in IaC",
        "No issues",
        "Better capacity"
      ],
      "answer": 1,
      "explanation": "IaC failures stem from quota limits, insufficient permissions, syntax errors, or dependency issues in templates. Objective 6.5"
    },
    {
      "q": "Database migration issues during deployment may cause:",
      "options": [
        "No impact",
        "Schema incompatibilities or data corruption",
        "Better performance",
        "Faster queries"
      ],
      "answer": 1,
      "explanation": "Migration problems include schema changes incompatible with code, failed migrations leaving inconsistent state, or data loss. Objective 6.5"
    },
    {
      "q": "Deployment in wrong order can cause:",
      "options": [
        "No issues",
        "Dependency failures when consumers deploy before providers",
        "Better results",
        "Performance gains"
      ],
      "answer": 1,
      "explanation": "Deploying services in wrong order causes failures when consumers expect new API that providers haven't deployed yet. Objective 6.5"
    },
    {
      "q": "Failed smoke tests after deployment indicate:",
      "options": [
        "Success",
        "Critical functionality broken by deployment",
        "Performance gains",
        "Nothing"
      ],
      "answer": 1,
      "explanation": "Failed smoke tests show deployment broke basic functionality, requiring immediate rollback or hotfix to restore service. Objective 6.5"
    },
    {
      "q": "Resource quota limits cause:",
      "options": [
        "No issues",
        "Inability to provision additional resources",
        "Better performance",
        "Unlimited capacity"
      ],
      "answer": 1,
      "explanation": "Cloud quotas limit resource creation (VMs, IPs, storage); hitting limits prevents scaling, requiring quota increase requests. Objective 6.6"
    },
    {
      "q": "Unexpected cloud costs often result from:",
      "options": [
        "Perfect optimization",
        "Untagged resources, data egress, or forgotten resources",
        "No impact",
        "Free services"
      ],
      "answer": 1,
      "explanation": "Cost surprises come from orphaned resources, data transfer charges, oversized instances, or resources left running unnecessarily. Objective 6.6"
    },
    {
      "q": "API rate limiting errors indicate:",
      "options": [
        "No usage",
        "Exceeding allowed request rates",
        "Better performance",
        "Unlimited access"
      ],
      "answer": 1,
      "explanation": "Rate limit errors show application exceeding API call quotas, requiring implementation of backoff, caching, or quota increase. Objective 6.6"
    },
    {
      "q": "Service availability issues may stem from:",
      "options": [
        "Perfect design",
        "Single availability zone deployment or lack of redundancy",
        "Better reliability",
        "No impact"
      ],
      "answer": 1,
      "explanation": "Availability problems result from single AZ/region deployment, lack of redundancy, or not utilizing cloud high-availability features. Objective 6.6"
    },
    {
      "q": "Multi-region deployment issues include:",
      "options": [
        "No challenges",
        "Data replication lag, latency, and consistency challenges",
        "Perfect synchronization",
        "No differences"
      ],
      "answer": 1,
      "explanation": "Multi-region architectures face replication delays, cross-region latency, data consistency complexities, and increased costs. Objective 6.6"
    },
    {
      "q": "Vendor lock-in concerns involve:",
      "options": [
        "Easy migration",
        "Difficulty moving to other providers due to proprietary services",
        "No issues",
        "Better portability"
      ],
      "answer": 1,
      "explanation": "Using proprietary services creates dependencies making migration costly/difficult; portable solutions using standards reduce lock-in. Objective 6.6"
    },
    {
      "q": "Cloud service outages impact:",
      "options": [
        "Nothing",
        "All resources depending on affected service",
        "Single resource",
        "No impact"
      ],
      "answer": 1,
      "explanation": "Cloud provider outages affect all dependent services in region/zone; multi-region and multi-cloud strategies mitigate this risk. Objective 6.6"
    },
    {
      "q": "Insufficient monitoring leads to:",
      "options": [
        "Better visibility",
        "Delayed problem detection and resolution",
        "Perfect awareness",
        "No issues"
      ],
      "answer": 1,
      "explanation": "Inadequate monitoring causes problems to go undetected, delaying response and potentially impacting users before awareness. Objective 6.6"
    },
    {
      "q": "Shadow IT in cloud creates:",
      "options": [
        "Better control",
        "Unmanaged resources, security risks, and cost issues",
        "No problems",
        "Perfect governance"
      ],
      "answer": 1,
      "explanation": "Unmanaged cloud usage creates security vulnerabilities, compliance issues, cost surprises, and lack of visibility. Objective 6.6"
    },
    {
      "q": "Cloud skills gap results in:",
      "options": [
        "Perfect operations",
        "Misconfigurations, inefficient designs, and security issues",
        "Better architecture",
        "No impact"
      ],
      "answer": 1,
      "explanation": "Insufficient cloud expertise causes suboptimal architectures, security misconfigurations, cost inefficiencies, and operational difficulties. Objective 6.6"
    }
  ]
}